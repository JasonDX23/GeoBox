Repository: cgre-aachen/open_ar_sandbox.git
Files analyzed: 142

Estimated tokens: 198.0k

Directory structure:
└── cgre-aachen-open_ar_sandbox.git/
    ├── README.md
    ├── index.md
    ├── LICENSE
    ├── requirements.txt
    ├── sandbox_environment.yml
    ├── sandbox_server.py
    ├── setup.py
    ├── start_server.cmd
    ├── docs/
    │   ├── make.bat
    │   ├── Makefile
    │   └── source/
    │       ├── conf.py
    │       ├── index.rst
    │       └── getting_started/
    │           ├── about.rst
    │           ├── download sample data.rst
    │           ├── external packages.rst
    │           ├── features.rst
    │           ├── installation.rst
    │           ├── interest.rst
    │           ├── license.rst
    │           ├── modules.rst
    │           ├── project development.rst
    │           └── requirements.rst
    ├── notebooks/
    │   ├── calibration_files/
    │   │   ├── fw_projector_calibration.json
    │   │   ├── fw_sensor_calibration.json
    │   │   ├── my_projector_calibration.json
    │   │   └── my_sensor_calibration.json
    │   ├── prototypes/
    │   │   ├── kinectv2_linux.ipynb
    │   │   ├── prototype_test_lk.ipynb
    │   │   ├── gemgis_sandbox/
    │   │   │   └── Gempy Model.ipynb
    │   │   ├── Gempy_workspace/
    │   │   │   ├── Gempy_models_sandbox_visualization.ipynb
    │   │   │   ├── Boreholes/
    │   │   │   └── Cross_sections/
    │   │   └── threading/
    │   └── tutorials/
    │       ├── Download_datasets.ipynb
    │       ├── Run_Sandbox_allFunctionalities.ipynb
    │       ├── Template_Notebook.ipynb
    │       ├── 00_Calibration/
    │       │   ├── 1_calib_projector.ipynb
    │       │   ├── 2_calib_sensor.ipynb
    │       │   └── 3_calib_arucos.ipynb
    │       ├── 01_MainThread/
    │       │   ├── Generate_ArUco_markers.ipynb
    │       │   └── Main_Thread.ipynb
    │       ├── 02_TopoModule/
    │       │   └── Topography.ipynb
    │       ├── 03_SearchMethodsModule/
    │       ├── 04_GempyModule/
    │       │   ├── Example_Models/
    │       │   │   ├── CombinedModel_Fold_Unconformity_Fault.ipynb
    │       │   │   ├── Dummy-sensor-gempy-fast.ipynb
    │       │   │   ├── Dummy-sensor-gempy-simple-models.ipynb
    │       │   │   ├── Graben_model.ipynb
    │       │   │   ├── Prototype_Aruco_borehole_cross-section.ipynb
    │       │   │   ├── simple_models.ipynb
    │       │   │   ├── BuFaTa/
    │       │   │   │   ├── BuFaTa Model.ipynb
    │       │   │   │   ├── BuFaTa Model_original.ipynb
    │       │   │   │   ├── interfaces_BuFaTa
    │       │   │   │   ├── orientations_BuFaTa
    │       │   │   │   └── raster1.tif
    │       │   │   └── complex_model/
    │       │   │       ├── complex_model.ipynb
    │       │   │       └── geological_model.PNG
    │       │   └── Model_Construction/
    │       │       ├── Bennisson_model/
    │       │       │   └── gemgis_Bennisson_Model.ipynb
    │       │       └── Complex_model/
    │       │           ├── geological_model.PNG
    │       │           ├── Map_to_model_full_model.ipynb
    │       │           └── Map_to_model_stepwise_model.ipynb
    │       ├── 05_GradientModule/
    │       │   └── test_field_manipulation.ipynb
    │       ├── 06_LoadSaveTopoModule/
    │       ├── 07_LandslideSimulation/
    │       │   └── Load_and_Run_Landslides_Simulation.ipynb
    │       ├── 08_PrototypingModule/
    │       │   └── simpel setup.ipynb
    │       ├── 09_LandscapeGeneration/
    │       │   └── deep_learning_landscapes.ipynb
    │       ├── 10_SeismicModule/
    │       │   ├── seismic_sandbox.ipynb
    │       │   └── steps_seismic_in_windows_EXPERIMENTAL.txt
    │       ├── 11_GeoelectricsModule/
    │       │   └── Geoelectrics.ipynb
    │       ├── 12_PynoddyModule/
    │       │   └── kinematic_modeling.ipynb
    │       └── 13_DummySensor/
    │           └── Dummy-sensor-topography-example.ipynb
    ├── sandbox/
    │   ├── __init__.py
    │   ├── main_thread.py
    │   ├── sandbox_api.py
    │   ├── markers/
    │   │   ├── __init__.py
    │   │   ├── aruco.py
    │   │   ├── aruco_linux.py
    │   │   ├── aruco_windows.py
    │   │   ├── dummy_aruco.py
    │   │   ├── lidar_aruco.py
    │   │   └── markers_plotting.py
    │   ├── modules/
    │   │   ├── __init__.py
    │   │   ├── gradients.py
    │   │   ├── landslides.py
    │   │   ├── landslides_raw_data.py
    │   │   ├── load_save_topography.py
    │   │   ├── prototyping.py
    │   │   ├── search_methods.py
    │   │   ├── template.py
    │   │   ├── topography.py
    │   │   ├── block_module/
    │   │   │   ├── __init__.py
    │   │   │   ├── block_module.py
    │   │   │   └── rms_grid.py
    │   │   ├── devito/
    │   │   │   ├── __init__.py
    │   │   │   ├── model.py
    │   │   │   ├── seismic_sandbox.py
    │   │   │   └── source.py
    │   │   ├── gempy/
    │   │   │   ├── __init__.py
    │   │   │   ├── example_models.py
    │   │   │   ├── gempy_module.py
    │   │   │   ├── plot.py
    │   │   │   └── utils.py
    │   │   ├── gimli/
    │   │   │   ├── __init__.py
    │   │   │   └── geoelectrics.py
    │   │   ├── img/
    │   │   ├── pynoddy/
    │   │   │   ├── __init__.py
    │   │   │   └── pynoddy_module.py
    │   │   └── pytorch/
    │   │       ├── __init__.py
    │   │       └── landscape_generation.py
    │   ├── projector/
    │   │   ├── __init__.py
    │   │   ├── cmap.py
    │   │   ├── contourlines.py
    │   │   ├── projector.py
    │   │   └── shading.py
    │   ├── sensor/
    │   │   ├── __init__.py
    │   │   ├── calibration_sensor.py
    │   │   ├── dummy.py
    │   │   ├── kinectV1.py
    │   │   ├── kinectV2.py
    │   │   ├── lidar_l515.py
    │   │   └── sensor_api.py
    │   └── utils/
    │       ├── __init__.py
    │       ├── download_sample_datasets.py
    │       └── logger.py
    └── tests/
        ├── __init__.py
        ├── conftest.py
        ├── test_download_sample_data.py
        ├── test_main_thread.py
        ├── test_projector.py
        ├── test_modules/
        │   ├── __init__.py
        │   ├── gempy_models_script.py
        │   ├── test_cmap.py
        │   ├── test_contour.py
        │   ├── test_gempy.py
        │   ├── test_geolectrics.py
        │   ├── test_gradients.py
        │   ├── test_landscapes.py
        │   ├── test_landslides.py
        │   ├── test_load_save_topo.py
        │   ├── test_pynoddy.py
        │   ├── test_seismic.py
        │   └── test_topography.py
        └── test_sensor_markers/
            ├── __init__.py
            ├── test_aruco.py
            ├── test_aruco_linux.py
            ├── test_aruco_windows.py
            ├── test_calib_sensor.py
            ├── test_dummy.py
            └── test_sensor.py


================================================
FILE: README.md
================================================
# Open AR-Sandbox

* Check the complete and up-to-date documentation on [read the docs](https://open-ar-sandbox.readthedocs.io/en/latest/)

* Quick installation note

There seems to be a problem with bokeh/ panel and Python at the moment. These versions seem to work:

```pip install panel==0.14.4 bokeh==2.4.3 jupyter-bokeh==2.0.4```



Welcome to the# Open AR-Sandbox repository. If you do not know what this is all about, have a look at this video:

[![The CGRE Sandbox in action](https://img.youtube.com/vi/oE3Atw-YvSA/0.jpg)](https://www.youtube.com/watch?v=oE3Atw-YvSA)

[![What is an AR-sandbox?](https://img.youtube.com/vi/RIvYO1lx6vs/0.jpg)](https://www.youtube.com/watch?v=RIvYO1lx6vs)

![Python 3](https://img.shields.io/badge/Python-3-blue.svg)
[![License: LGPL v3](https://img.shields.io/badge/License-LGPL%20v3-blue.svg)](https://www.gnu.org/licenses/lgpl-3.0)

Table of Contents
--------
* [Introduction](README.md#introduction)
* [Features](README.md#features)
* [License, use and attributions](README.md#license-use-and-attribution)
* [Requirements](README.md#requirements)
* [Installation](README.md#installation)
    * [Standard packages](README.md#standard-packages)
    * [Download sample data](README.md#download-sample-data)
    * [Kinect Installation](README.md#kinect-installation)
        * [Windows](README.md#for-windows)
            * [KinectV2 - PyKinect2](README.md#kinect-v2---pykinect2)
        * [Linux](README.md#for-linux)
            * [KinectV1 - libkinect](README.md#kinect-v1---libfreenect)
            * [KinectV2 - freenect2](README.md#kinect-v2---freenect2)
   * [LiDAR L515 Installation](README.md#lidar-l515-installation)
      * [Installing in Windows](README.md#installing-in-windows)
      * [Installing in Linux](README.md#installing-in-linux)
      * [Running with Python](README.md#running-with-python)
* [External packages](README.md#external-packages)
    * [Gempy](README.md#gempy)
    * [Devito](README.md#devito)
    * [PyGimli](README.md#pygimli)
    * [PyTorch](README.md#pytorch)
    * [Pynoddy](README.md#pynoddy)
* [Project Development](README.md#project-development)
* [Interested in obtaining a fully operational system?](README.md#obtaining-a-full-system)
    

:warning: **Warning!** It is unfortunate that we have to state this here, but: downloading the software and presenting it somewhere as your 
own work is serious **scientific fraud**! And if you develop content further, then please push these developments
back to this repostory - in the very interest of scientific development (and also a requirement of the license).
For more details, please consult the information below and the license.


Introduction
-----------
Augmented Reality Sandboxes (AR-sandboxes) are a great tool for science outreach and teaching due to their intuitive and interaction-enhancing operation. Recently AR Sandboxes are becoming increasingly popular as interactive exhibition pieces, teaching aids and toys.

AR-sandboxes consist of a box of sand that can be freely sculpted by hand. The topography of the sand is constantly scanned with a depth camera and a computed image is projected back onto the sand surface, augmenting the sandbox with digital information.

However, most of these common AR Sandboxes are limited to the visualization of topography with contour lines and colors, as well as water simulations on the digital terrain surface. The potential for AR Sandboxes for geoscience education , and especially for teaching strutural geology, remains largely untapped.

For this reason, we have developed Open AR-Sandbox, an augmented reality sandbox designed specifically for the use in geoscience education. In addition to the visualization of topography it can display geologic subsurface information such as the outcropping lithology, creating a dynamic and interactive geological map. The relations of subsurface structures, topography and outcrop can be explored in a playful and comprehensible way.

Features
-------
* compatible with most AR-sandbox builds
* subroutine for calibration and alignment of depth image, sand surface and projection 
* versatile model creation with the powerful GemPy library
* open-source under LGPL v3.0 license
* fully customizable color map, contours and fault line visualization
* We recently added computer vision algorithms to the sandbox that open up a whole new field of possibilities! By placing printed markers into the sandbox, thew user can trigger actions or define points, lines and areas in the sandbox without using the computer

Some of the modules already implemented include:
* [MarkerDetection](notebooks/tutorials/00_Calibration): Place virtual boreholes in the model, Define a cross section with multiple markers, Set the start position for simulations (landslides, earthquakes, etc.) check the arucos marker detection for more information (https://docs.opencv.org/trunk/d5/dae/tutorial_aruco_detection.html)
* [TopoModule](notebooks/tutorials/02_TopoModule/): Normalize the depth image to display a topography map with fully customizable contour lines and variable heights.
* [SearchMethodsModule](notebooks/tutorials/03_SearchMethodsModule): Takes the depth image and performs Monte-Carlo simulation algorithms to construct the probability distribution based on the structure of the current DEM in an interactive way. (https://chi-feng.github.io/mcmc-demo/app.html)
* [GemPyModule](notebooks/tutorials/04_GempyModule): Use the full advantage of the powerful [GemPy](https://github.com/cgre-aachen/gempy) package to construct geological models and visualize them on the sandbox in real-time
* [GradientModule](notebooks/tutorials/05_GradientModule): Takes the gradient information from the depth image and highlight slopes in x and y direction, calculation of laplacian, interactive hill shading, visualization of a vector field, and streamline plot.   
* [LoadSaveTopoModule](notebooks/tutorials/06_LoadSaveTopoModule): Takes the depth image and allows it to be saved as a DEM to reconstruct topographies previously constructed.
* [LandslideSimulation](notebooks/tutorials/07_LandslideSimulation): With precomputed landslides simulations, recreate a topography and trigger a landslide to visualize its flow, direction, and velocity in real-time, or frame by frame.
* [PrototypingModule](notebooks/tutorials/08_PrototypingModule): Create your own module with the help of this module to link the live threading of the sandbox with your ideas
* [LandscapeModule](notebooks/tutorials/09_LandscapeGeneration): Landscape generations using machine learning codes powered by [CycleGAN](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) 
* [SeismicModule](notebooks/tutorials/10_SeismicModule): module for seismic wave modelling in the sandbox. This uses the power of [Devito](https://github.com/devitocodes/devito)
* [GeoelectricsModule](notebooks/tutorials/11_GeoelectricsModule): module for visualization of geoelectrical fields using aruco markers as electrodes. This use power of [PyGimli](https://www.pygimli.org/)
* [PynoddyModule](notebooks/tutorials/12_PynoddyModule): module for to visualize kinematic geological modelling simulations. This module is powered by [Pynoddy](https://github.com/cgre-aachen/pynoddy)

Check the video below for some of the features in action:
[![Open AR Sandbox Features](https://img.youtube.com/vi/t0fyPVMIH4g/0.jpg)](https://www.youtube.com/watch?v=t0fyPVMIH4g)

The Open AR-Sandbox software as well as GemPy are under continuous development and including more modules for major outreach. Some of the features we are currently working on include: 

* More Tutorials, examples, Tests and Documentation to help you develop your own modules
* GemPy optimization for (much!) higher framerates
* on-the-fly modification of the geological model (layer dip, thickness fault throw, etc.)
* Integration of more depth sensors (support to all kinect sensors)
* Improve compatibility with Linux and MacOS
* ...

License, use and attribution
----------------------------


If you use Open AR-Sandbox in a scientific abstract or publication, please
include appropriate recognition of the original work. For the time being,
please cite our [publication](https://pubs.geoscienceworld.org/gsa/geosphere/article/doi/10.1130/GES02455.1/611689/Open-AR-Sandbox-A-haptic-interface-for-geoscience) in the journal Geosphere:

Florian Wellmann, Simon Virgo, Daniel Escallon, Miguel de la Varga, Alexander Jüstel, Florian M. Wagner, Julia Kowalski, Hu Zhao, Robin Fehling, Qian Chen; Open AR-Sandbox: A haptic interface for geoscience education and outreach. Geosphere 2022; doi: https://doi.org/10.1130/GES02455.1

Directly in BibTeX-format:

```
@article{10.1130/GES02455.1,
    author = {Wellmann, Florian and Virgo, Simon and Escallon, Daniel and de la Varga, Miguel and Jüstel, Alexander and Wagner, Florian M. and Kowalski, Julia and Zhao, Hu and Fehling, Robin and Chen, Qian},
    title = "{Open AR-Sandbox: A haptic interface for geoscience education and outreach}",
    journal = {Geosphere},
    year = {2022},
    month = {02},
    issn = {1553-040X},
    doi = {10.1130/GES02455.1},
    url = {https://doi.org/10.1130/GES02455.1},
    eprint = {https://pubs.geoscienceworld.org/gsa/geosphere/article-pdf/doi/10.1130/GES02455.1/5541527/ges02455.pdf},
}
```


Feel free to download and use the Open AR-Sandbox software! We do not provide any
warranty and any guarantee for the use. We also do not provide professional
support, but we aim to answer questions posted as Issues on the github page as
quickly as possible.

Open AR-Sandbox is published under an **GNU Lesser General Public License v3.0**, which
means that you are
free to use it, if you do not do any modifications, in a wide variety of ways
(even commercially). However, if you plan to _modify and redistribute_ the
code, you also _have to make it available under the same license_!

Also, if you do any modifications, especially for scientific and educational use,
then please _provide them back to the main project_ in the form of a pull request,
as common practice in the open-source community. If you have questions on
the procedure, feel free to contact us about it.

These are the main conditions for using this library:
- License and copyright notice
- Disclose source
- State changes
- Same license (library)

For more details on the licsense, please see provided license file.

:warning: **Warning!** It is unfortunate that we have to state this here, but: downloading the software and presenting it somewhere as your 
own work is serious **scientific fraud**! And if you develop content further, then please push these developments
back to this repostory - in the very interest of scientific development (and also a requirement of the license).
For more details, please consult the information below and the license.


Requirements
--------
You will need: 
* Microsoft Kinect (we tested the first and second generation kinect with a usb adapter, but every kinect compatible 
with the pykinect drivers will likely work).
* Projector
* A box of Sand

Mount the kinect and projector facing down vertically in the center above of the box. The optimal distance will depend 
on the size of your sandbox and the optics of the projector, from our experience a distance of 150 cm is well suited 
for a 80 cm x 100 cm box. 
More details on how to set up the kinect and projector can be found in the `1_calib_projector.ipynb` 
and `2_calib_sensor.ipynb` notebooks, and if you want to use the ArUco markers `3_calib_arucos.ipynb`.


Installation 
-----
First of all you will need a healthy Python 3 environment. We recommend using 
[Anaconda](https://www.anaconda.com/distribution/). In addition to some standard Python packages, you will need a 
specific setup dependent on the Kinect version you are using. In the following we provide detailed installation 
instructions.\
Now download or clone this repository [open_AR_Sandbox](https://github.com/cgre-aachen/open_AR_Sandbox) from github.

1. First clone the repository:
```
git clone https://github.com/cgre-aachen/open_AR_Sandbox.git
```
2. Enter the new downloaded project folder:
```
cd open_AR_Sandbox
```
3. Create a new anaconda environment
```
conda create -n sandbox-env python=3.8
```
4. Now when you want to use the sandbox and the packages we are about to installl you will have to activate the 
environment before starting anything
```
conda activate sandbox-env
```
### Standard packages

To install all the standard packages please use the  `requirements.txt` file:

```
pip install -r requirements.txt
```

[RECOMMENDED] You can also have a local installation of the sandbox by using the File "setup.py" by doing:

```
pip install -e . 
```

[ALTERNATIVELY] You can use our `sandbox-environment.yml` file to instantly install all the dependencies with the 
extensions. Beware that you  still need to install the kinect sensors by yourself according to your operative system.
```
conda env create -f sandbox_environment.yml
```

### Download sample data

You have the option to download some publicly shared files from our Open AR-Sandbox project shared folder. 
You will need to do this if you want to run the tests, use the landslides simulations and/or get the trained models for 
the use of the Landscape generation module.

In the terminal type:

```
python3 sandbox/utils/download_sample_datasets.py
```

and follow the instruction on the terminal to download the specific files you need. We use 
[Pooch](https://github.com/fatiando/pooch) to help us fetch our data files and store them locally in your computer 
to their respective folders. Running this code a second time will not trigger a download since the file already exists.

You can also follow the Jupyter Notebook ['Download_datasets.ipynb'](notebooks/tutorials/) and follow the commands. 

### Kinect Installation 
 
### For Windows

#### Kinect v1 - Future

There is still no support for kinect V1... 

#### Kinect V2 - PyKinect2

(Tested on Windows 10). First, **install the current** 
[Kinect SDK](https://www.microsoft.com/en-us/download/confirmation.aspx?id=44561) **including drivers**. 
You can use the software bundle to test the connection to your
 kinect, before you continue.

To make Python and the Kinect SDK communicate, install the related [PyKinect2](https://github.com/Kinect/PyKinect2) 
wrappers which can be easily installed via:

```pip install pykinect2```

Unfortunately, the configuration of PyKinect2 needs to be adjusted to work on a 64 bit System.  Therefore, edit the
 _Lib/site-packages/pykinect2/PyKinectV2.py_ file, go to line **2216** and comment it:

```python
# assert sizeof(tagSTATSTG) == 72, sizeof(tagSTATSTG)
```

Add the following lines below:

```python
import numpy.distutils.system_info as sysinfo
required_size = 64 + sysinfo.platform_bits / 4
assert sizeof(tagSTATSTG) == required_size, sizeof(tagSTATSTG)
```

### For Linux

#### Kinect v1 - libfreenect

To make Open AR-Sandbox talk to the first generation kinect you will need the
[Libfreenect Drivers](https://github.com/OpenKinect/libfreenect) with
[Python Wrappers](https://openkinect.org/wiki/Python_Wrapper). 
The installation is kind of straight forward for Linux and MacOS but 
challenging for Microsoft (in fact: if you pull it off, let us know how you did it!)
The steps can be summarized as follows (refer to any problems regarding installation in to
[link](https://github.com/OpenKinect/libfreenect))
To build libfreenect, you'll need

- [libusb](http://libusb.info) >= 1.0.18 (Windows needs >= 1.0.22)
- [CMake](http://cmake.org) >= 3.12.4 (you can visit 
[this](https://www.claudiokuenzler.com/blog/796/install-upgrade-cmake-3.12.1-ubuntu-14.04-trusty-alternatives)
page for detailed instructions for the installation)

Once these are installed we can follow the next commands
```
sudo apt-get install git cmake build-essential libusb-1.0-0-dev
sudo apt-get install freeglut3-dev libxmu-dev libxi-dev
git clone https://github.com/OpenKinect/libfreenect
cd libfreenect
mkdir build
cd build
cmake -L .. # -L lists all the project options
cmake .. -DBUILD_PYTHON3=ON
make 


cd ../wrappers/python
python setup.py install
# now you can see if the installation worked running an example
python demo_cv2_async.py
```

#### Kinect v2 - freenect2
or pylibfreenect2 \
For this we are going to use a python interface for the library 
[libfreenect2](https://github.com/OpenKinect/libfreenect2)
called [freenect2](https://github.com/rjw57/freenect2-python). 
* First we need to install the [freenect2](https://github.com/rjw57/freenect2-python) as described in the installation 
guide. 
The steps can be summarized as follows (refer to any problems regarding installation in to 
[link](https://rjw57.github.io/freenect2-python/))
```
git clone https://github.com/OpenKinect/libfreenect2.git
cd libfreenect2
```
```
sudo apt-get install build-essential cmake pkg-config
sudo apt-get install libusb-1.0-0-dev libturbojpeg0-dev libglfw3-dev
```
* With all the dependencies installed now we can make and install 
```
mkdir build && cd build
cmake .. -DENABLE_CXX11=ON -DENABLE_OPENCL=ON -DENABLE_OPENGL=ON -DBUILD_OPENNI2_DRIVER=ON -DCMAKE_INSTALL_PREFIX=$HOME/freenect2 -DCMAKE_VERBOSE_MAKEFILE=ON
make
make install
```
* Set up udev rules for device access: 
```
sudo cp ../platform/linux/udev/90-kinect2.rules /etc/udev/rules.d/
```
Now unplug and replug the Kinect sensor.
* Test if the kinect is correctly installed, by running:
```
./bin/Protonect
```
* You should be able to see the kinect image working. If not, check  [libfreenect2](https://github.com/OpenKinect/libfreenect2) 
installation guide for more detailed instructions of installation

* If everything is working until now, we can install the python wrapper. For this first we need to indicate where the 
`freenect2` folder can be found.
```
export PKG_CONFIG_PATH=$HOME/freenect2/lib/pkgconfig
```
NOTE: if you installed the `freenect2` in other location, specify variables with the corresponding path
* now we can use `pip install` , or any other method described in the [freenect2](https://github.com/rjw57/freenect2-python) 
installation guide. 
```
pip install freenect2
```
IMPORTANT: To this point will work in any python that starts with the terminal. Nevertheless, if we start python from 
another source, the error 
`ImportError: libfreenect2.so.0.2: cannot open shared object file: No such file or directory` will appear every time we 
import the package. To fix this problem we will need
to export the variables again or if you want a more permanent solution, open the `.bashrc` file and paste the following
 at the end of the file:
```
# set PATH to freenect2 to be imported in python
export PKG_CONFIG_PATH=$HOME/freenect2/lib/pkgconfig
```
* With this it will always work for any python open from the terminal. Including jupyter notebooks
* But now if we want to run this package in Pycharm or symilar, we can directly copy the 3 files 
(`libfreenect2.2.s0...`) from the `freenect2/lib` folder into the 
`lib` folder of your environment. Ej:
 * if you are using an anaconda environment, open the folder:
```
<your_path>/anaconda3/envs/<sandbox-env>/lib
```
* And in this folder paste the previous copied files (3 files!!!). Keep in mind that you need to 
replace the <...> with your specific path.
* If you dont want the manual work then run directly (remember to change the paths according to your needs):
```
sudo cp $HOME/freenect2/lib/libfreenect2{.so,.so.0.2,.so.0.2.0} $HOME/anaconda3/envs/sandbox-env/lib/
```


### LiDAR L515 Installation 

#### Installing in Windows

First, go to the latest release page on [GitHub](https://github.com/IntelRealSense/librealsense/releases/latest) 
and download and execute the file: 

```Intel.RealSense.Viewer.exe```

Follow the instructions for the installation and update the firmware of your sensor.  You should be able to use and see the depth and RGB image.

#### Installing in Linux 

Detailed installation steps can be found in the 
[linux installation guide](https://github.com/IntelRealSense/librealsense/blob/development/doc/distribution_linux.md). 
The steps are as follows:

- Register the server's public key:  
`sudo apt-key adv --keyserver keys.gnupg.net --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE || sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE`
In case the public key still cannot be retrieved, check and specify proxy settings: `export http_proxy="http://<proxy>:<port>"`  
, and rerun the command. See additional methods in the following [link](https://unix.stackexchange.com/questions/361213/unable-to-add-gpg-key-with-apt-key-behind-a-proxy).  

- Add the server to the list of repositories:  
  Ubuntu 16 LTS:  
`sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo xenial main" -u`  
  Ubuntu 18 LTS:  
`sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo bionic main" -u`  
  Ubuntu 20 LTS:  
`sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo focal main" -u`

- Install the libraries:  
  `sudo apt-get install librealsense2-dkms`  
  `sudo apt-get install librealsense2-utils`  
  
Reconnect the Intel RealSense depth camera and run: `realsense-viewer` to verify the installation.

#### Running with python

After the sensor is installed on your pltaform, the Python wrapper can be easily installed via:

```pip install pyrealsense2```

If any problems with the installation reference to 
[Intel RealSense Python Installation](https://github.com/IntelRealSense/librealsense/tree/master/wrappers/python#installation)


External Packages
---------
### GemPy

To use implicit geological models inside the sandbox, go to [GemPy](https://github.com/cgre-aachen/gempy),
clone or download the repository and follow the Gempy Installation instructions. With gempy installed 
you can follow the tutorial [GempyModule](notebooks/tutorials/04_GempyModule/).
```
pip install gempy
```
If using windows you will need to install `Theano` separately as instructed in [here](https://www.gempy.org/installation)
```
conda install mingw libpython m2w64-toolchain
conda install theano
pip install theano --force-reinstall
```

Optional: 
Gempy will print some output each time a frame is calculated, which can fill up the console. to supress this, go to your gempy installation and comment out line 381 in ```
gempy/core/model.py```

```
# print(f'Active grids: {self._grid.grid_types[self._grid.active_grids]}')
```

### Devito

This package uses the power of [Devito](https://github.com/devitocodes/devito) to run wave proppagation simmulations.
More about this can be found in `notebooks/tutorials/10_SeismicModule/`. Follow the Devito installation instructions. 
* This module so far have only support in linux 
```
pip install --user git+https://github.com/devitocodes/devito.git
```

### PyGimli
This library is a powerful tool for Geophysical inversion and Modelling. Some examples can be found in 
`notebooks/tutorials/11_Geophysics/`. 
[PyGimli](https://www.pygimli.org/) can be installed following the installation intructions 
[here](https://www.pygimli.org/installation.html)

We recommend creating a new environment where PyGimli is already installed and over that one install the sandbox 
dependencies.
```
conda create -n sandbox-env -c gimli -c conda-forge pygimli=1.1.0
```
* And now go back to [installation](README.md#installation) and follow all over again the instruction but skipping 
step 2. 

### PyTorch

To use the LandscapeGeneration module we need to install [PyTorch](https://pytorch.org/). This module use the power 
of [CycleGAN](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) 
to take a topography from the sandbox, translate this as a DEM and then display it again on the sandbox as a Landscape 
image. 
To install the dependencies for this module do:
```
#For Windows
pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html
```
```
#For Linux
pip install torch torchvision
```
```
git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix
cd pytorch-CycleGAN-and-pix2pix
pip install -r requirements.txt
```
Once this is installed, copy the trained model in `/notebooks/tutorials/09_LandscapeGeneration/checkpoints` folder, 
and then follow the notebook.
Get in contact with us to provide you with the train model for this module. 

### Pynoddy

To use [Pynoddy](https://github.com/cgre-aachen/pynoddy), please follow the installation instructions. 
We recommend installing Noddy from source files.  

Project Development
-------------------

Open AR-Sandbox is developed at the research unit [Computational Geoscience
and Reservoir Engineering (CGRE)](https://www.cgre.rwth-aachen.de/) at RWTH Aachen University, Germany.

[![CGRE](https://www.cgre.rwth-aachen.de/global/show_picture.asp?id=aaaaaaaaabaxmhn)](https://www.cgre.rwth-aachen.de/)



### Project Lead

[Prof. Florian Wellmann, PhD](https://www.cgre.rwth-aachen.de/cms/CGRE/Das-Lehr-und-Forschungsgebiet/~dnyyj/Prof-Wellmann/lidx/1/)

### Maintainers (also external to CGRE)

* Daniel Escallón 
* Simon Virgo
* Nils Chudalla
* Miguel de la Varga

Obtaining a full system
-----------------------

If you are interested in buying a fully operating set-up including appropriate
hardware, pre-installed software, and set-up and maintenance, please contact
[Terranigma Solutions GmbH](https://www.terranigma-solutions.com/services).



 



================================================
FILE: index.md
================================================
# open_AR_Sandbox
Welcome to the Open_AR_Sandbox repository. If you do not know what this is all about, have a look at this video:

:warning: **Warning!** It is unfortunate that we have to state this here, but: downloading the software and presenting it somewhere as your 
own work is serious **scientific fraud**! And if you develop content further, then please push these developments
back to this repostory - in the very interest of scientific development (and also a requirement of the license).
For more details, please consult the information below and the license.

[![The CGRE Sandbox in action](https://img.youtube.com/vi/oE3Atw-YvSA/0.jpg)](https://www.youtube.com/watch?v=oE3Atw-YvSA)

[![What is AR-Sandbox?](https://img.youtube.com/vi/RIvYO1lx6vs/0.jpg)](https://www.youtube.com/watch?v=RIvYO1lx6vs)

![Python 3](https://img.shields.io/badge/Python-3-blue.svg)
[![License: LGPL v3](https://img.shields.io/badge/License-LGPL%20v3-blue.svg)](https://www.gnu.org/licenses/lgpl-3.0)

Table of Contents
--------
* [Introduction](README.md#introduction)
* [Features](README.md#features)
* [License, use and attributions](README.md#license-use-and-attribution)
* [Requirements](README.md#requirements)
* [Installation](README.md#installation)
    * [Standard packages](README.md#standard-packages)
    * [Kinect Installation](README.md#kinect-installation)
        * [Windows](README.md#for-windows)
            * [KinectV2 - PyKinect2](README.md#kinect-v2---pykinect2)
        * [Linux](README.md#for-linux)
            * [KinectV1 - libkinect](README.md#kinect-v1---libfreenect)
            * [KinectV2 - freenect2](README.md#kinect-v2---freenect2)
   * [LiDAR L515 Installation](README.md#lidar-l515-installation)
      * [Installing in Windows](README.md#installing-in-windows)
      * [Installing in Linux](README.md#installing-in-linux)
      * [Running with Python](README.md#running-with-python)
* [Download sample data](README.md#download-sample-data)
* [External packages](README.md#external-packages)
    * [Gempy](README.md#gempy)
    * [Devito](README.md#devito)
    * [PyGimli](README.md#pygimli)
    * [PyTorch](README.md#pytorch)
* [Project Development](README.md#project-development)
* [Interested in obtaining a fully operational system?](README.md#obtaining-a-full-system)
    

Introduction
-----------
Augmented Reality Sandboxes are a great tool for science outreach and teaching due to their intuitive and interaction-enhancing operation. Recently AR Sandboxes are becoming increasingly popular as interactive exhibition pieces, teaching aids and toys.

AR Sandboxes consist of a box of sand that can be freely sculpted by hand. The topography of the sand is constantly scanned with a depth camera and a computed image is projected back onto the sand surface, augmenting the sandbox with digital information.

However, most of these common AR Sandboxes are limited to the visualization of topography with contour lines and colors, as well as water simulations on the digital terrain surface. The potential for AR Sandboxes for geoscience education , and especially for teaching struc- tural geology, remains largely untapped.

For this reason, we have developed open-AR-Sandbox, an augmented reality sandbox designed specifically for the use in geoscience education. In addition to the visualization of topography it can display geologic subsurface information such as the outcropping lithology, creating a dynamic and interactive geological map. The relations of subsurface structures, topography and outcrop can be explored in a playful and comprehensible way.

Features
-------
* compatible with most AR Sandbox builds
* subroutine for calibration and alignment of depth image, sand surface and projection 
* versatile model creation with the powerful GemPy library
* open-source under LGPL v3.0 license
* fully customizable color map, contours and fault line visualization
* We recently added computer vision algorithms to the sandbox that open up a whole new field of possibilities! By placing printed markers into the sandbox, thew user can trigger actions or define points, lines and areas in the sandbox without using the computer

Some of the modules already implemented include:
* [MarkerDetection](notebooks/tutorials/00_Calibration): Place virtual boreholes in the model, Define a cross section with multiple markers, Set the start position for simulations (landslides, earthquakes, etc.) check the arucos marker detection for more information (https://docs.opencv.org/trunk/d5/dae/tutorial_aruco_detection.html)
* [TopoModule](notebooks/tutorials/02_TopoModule/): Normalize the depth image to display a topography map with fully customizable contour lines and variable heights.
* [SearchMethodsModule](notebooks/tutorials/03_SearchMethodsModule): Takes the depth image and performs Monte-Carlo simulation algorithms to construct the probability distribution based on the structure of the current DEM in an interactive way. (https://chi-feng.github.io/mcmc-demo/app.html)
* [GemPyModule](notebooks/tutorials/04_GempyModule): Use the full advantage of the powerful [GemPy](https://github.com/cgre-aachen/gempy) package to construct geological models and visualize them on the sandbox in real-time
* [GradientModule](notebooks/tutorials/05_GradientModule): Takes the gradient information from the depth image and highlight slopes in x and y direction, calculation of laplacian, interactive hill shading, visualization of a vector field, and streamline plot.   
* [LoadSaveTopoModule](notebooks/tutorials/06_LoadSaveTopoModule): Takes the depth image and allows it to be saved as a DEM to reconstruct topographies previously constructed.
* [LandslideSimulation](notebooks/tutorials/07_LandslideSimulation): With precomputed landslides simulations, recreate a topography and trigger a landslide to visualize its flow, direction, and velocity in real-time, or frame by frame.
* [PrototypingModule](notebooks/tutorials/08_PrototypingModule): Create your own module with the help of this module to link the live threading of the sandbox with your ideas
* [LandscapeModule](notebooks/tutorials/09_LandscapeGeneration): Landscape generations using machine learning codes powered by [CycleGAN](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) 
* [SeismicModule](notebooks/tutorials/10_SeismicModule): module for seismic wave modelling in the sandbox. This uses the power of [Devito](https://github.com/devitocodes/devito)
* [GeoelectricsModule](notebooks/tutorials/11_GeoelectricsModule): module for visualization of geoelectrical fields using aruco markers as electrodes. This use power of [PyGimli](https://www.pygimli.org/)

Check the video below for some of the features in action:
[![Open AR Sandbox Features](https://img.youtube.com/vi/t0fyPVMIH4g/0.jpg)](https://www.youtube.com/watch?v=t0fyPVMIH4g)

The open_AR_Sandbox as well as GemPy are under continuous development and including more modules for major outreach. Some of the features we are currently working on include: 

* More Tutorials, examples, Tests and Documentation to help you develop your own modules
* GemPy optimization for (much!) higher framerates
* on-the-fly modification of the geological model (layer dip, thickness fault throw, etc.)
* Integration of more depth sensors (support to all kinect sensors)
* Improve compatibility with Linux and MacOS
* ...

License, use and attribution
----------------------------

Feel free to download and use the Open_AR_Sandbox software! We do not provide any
warranty and any guarantee for the use. We also do not provide professional
support, but we aim to answer questions posted as Issues on the github page as
quickly as possible.

Open_AR_Sandbox is published under an **GNU Lesser General Public License v3.0**, which
means that you are
free to use it, if you do not do any modifications, in a wide variety of ways
(even commercially). However, if you plan to _modify and redistribute_ the
code, you also _have to make it available under the same license_!

Also, if you do any modifications, especially for scientific and educational use,
then please _provide them back to the main project_ in the form of a pull request,
as common practice in the open-source community. If you have questions on
the procedure, feel free to contact us about it.

These are the main conditions for using this library:
- License and copyright notice
- Disclose source
- State changes
- Same license (library)

For more details on the licsense, please see provided license file.

If you use Open-AR-Sandbox in a scientific abstract or publication, please
include appropriate recognition of the original work. For the time being,
please cite:

Virgo, S., De La Varga Hormazabal, M., & Wellmann, F. (2019).
Open-AR-Sandbox: An open-source Augmented Reality platform for geoscience.
In Geophysical Research Abstracts (Vol. 21).


Requirements
--------
You will need: 
* Microsoft Kinect (we tested the first and second generation kinect with a usb adapter, but every kinect compatible 
with the pykinect drivers will likely work).
* Projector
* A box of Sand

Mount the kinect and projector facing down vertically in the center above of the box. The optimal distance will depend 
on the size of your sandbox and the optics of the projector, from our experience a distance of 150 cm is well suited 
for a 80 cm x 100 cm box. 
More details on how to set up the kinect and projector can be found in the `1_calib_projector.ipynb` 
and `2_calib_sensor.ipynb` notebooks, and if you want to use the ArUco markers `3_calib_arucos.ipynb`.


Installation 
-----
First of all you will need a healthy Python 3 environment. We recommend using 
[Anaconda](https://www.anaconda.com/distribution/). In addition to some standard Python packages, you will need a 
specific setup dependent on the Kinect version you are using. In the following we provide detailed installation 
instructions.\
Now download or clone this repository [open_AR_Sandbox](https://github.com/cgre-aachen/open_AR_Sandbox) from github.

1. First clone the repository:
```
git clone https://github.com/cgre-aachen/open_AR_Sandbox.git
```
2. Create a new anaconda environment
```
conda create -n sandbox-env python=3.7
```
3. Now when you want to use the sandbox and the packages we are about to installl you will have to activate the 
environment before starting anything
```
conda activate sandbox-env
```
### Standard packages

To install all the standard packages please use the  `requirements.txt` file:

```pip install -r requirements.txt```

You can also have a local installation of the sandbox by using the File "setup.py" by doing:

`pip install -e . `

### Kinect Installation 
 
### For Windows

#### Kinect v1 - Future

There is still no support for kinect V1... 

#### Kinect V2 - PyKinect2

(Tested on Windows 10). First, **install the current** 
[Kinect SDK](https://www.microsoft.com/en-us/download/confirmation.aspx?id=44561) **including drivers**. 
You can use the software bundle to test the connection to your
 kinect, before you continue.

To make Python and the Kinect SDK communicate, install the related [PyKinect2](https://github.com/Kinect/PyKinect2) 
wrappers which can be easily installed via:

```pip install pykinect2```

Unfortunately, the configuration of PyKinect2 needs to be adjusted to work on a 64 bit System.  Therefore, edit the
 _Lib/site-packages/pykinect2/PyKinectV2.py_ file, go to line **2216** and comment it:

```python
# assert sizeof(tagSTATSTG) == 72, sizeof(tagSTATSTG)
```

Add the following lines below:

```python
import numpy.distutils.system_info as sysinfo
required_size = 64 + sysinfo.platform_bits / 4
assert sizeof(tagSTATSTG) == required_size, sizeof(tagSTATSTG)
```

### For Linux

#### Kinect v1 - libfreenect

To make open_AR_Sandbox talk to the first generation kinect you will need the
[Libfreenect Drivers](https://github.com/OpenKinect/libfreenect) with
[Python Wrappers](https://openkinect.org/wiki/Python_Wrapper). 
The installation is kind of straight forward for Linux and MacOS but 
challenging for Microsoft (in fact: if you pull it off, let us know how you did it!)
The steps can be summarized as follows (refer to any problems regarding installation in to
[link](https://github.com/OpenKinect/libfreenect))
To build libfreenect, you'll need

- [libusb](http://libusb.info) >= 1.0.18 (Windows needs >= 1.0.22)
- [CMake](http://cmake.org) >= 3.12.4 (you can visit 
[this](https://www.claudiokuenzler.com/blog/796/install-upgrade-cmake-3.12.1-ubuntu-14.04-trusty-alternatives)
page for detailed instructions for the installation)

Once these are installed we can follow the next commands
```
sudo apt-get install git cmake build-essential libusb-1.0-0-dev
sudo apt-get install freeglut3-dev libxmu-dev libxi-dev
git clone https://github.com/OpenKinect/libfreenect
cd libfreenect
mkdir build
cd build
cmake -L .. # -L lists all the project options
cmake .. -DBUILD_PYTHON3=ON
make 


cd ../wrappers/python
python setup.py install
# now you can see if the installation worked running an example
python demo_cv2_async.py
```

#### Kinect v2 - freenect2
or pylibfreenect2 \
For this we are going to use a python interface for the library 
[libfreenect2](https://github.com/OpenKinect/libfreenect2)
called [freenect2](https://github.com/rjw57/freenect2-python). 
* First we need to install the [freenect2](https://github.com/rjw57/freenect2-python) as described in the installation 
guide. 
The steps can be summarized as follows (refer to any problems regarding installation in to 
[link](https://rjw57.github.io/freenect2-python/))
```
git clone https://github.com/OpenKinect/libfreenect2.git
cd libfreenect2
```
```
sudo apt-get install build-essential cmake pkg-config
sudo apt-get install libusb-1.0-0-dev libturbojpeg0-dev libglfw3-dev
```
* With all the dependencies installed now we can make and install 
```
mkdir build && cd build
cmake .. -DENABLE_CXX11=ON -DENABLE_OPENCL=ON -DENABLE_OPENGL=ON -DBUILD_OPENNI2_DRIVER=ON -DCMAKE_INSTALL_PREFIX=$HOME/freenect2 -DCMAKE_VERBOSE_MAKEFILE=ON
make
make install
```
* Set up udev rules for device access: 
```
sudo cp ../platform/linux/udev/90-kinect2.rules /etc/udev/rules.d/
```
Now unplug and replug the Kinect sensor.
* Test if the kinect is correctly installed, by running:
```
./bin/Protonect
```
* You should be able to see the kinect image working. If not, check  [libfreenect2](https://github.com/OpenKinect/libfreenect2) 
installation guide for more detailed instructions of installation

* If everything is working until now, we can install the python wrapper. For this first we need to indicate where the 
`freenect2` folder can be found.
```
export PKG_CONFIG_PATH=$HOME/freenect2/lib/pkgconfig
```
NOTE: if you installed the `freenect2` in other location, specify variables with the corresponding path
* now we can use `pip install` , or any other method described in the [freenect2](https://github.com/rjw57/freenect2-python) 
installation guide. 
```
pip install freenect2
```
IMPORTANT: To this point will work in any python that starts with the terminal. Nevertheless, if we start python from 
another source, the error 
`ImportError: libfreenect2.so.0.2: cannot open shared object file: No such file or directory` will appear every time we 
import the package. To fix this problem we will need
to export the variables again or if you want a more permanent solution, open the `.bashrc` file and paste the following
 at the end of the file:
```
# set PATH to freenect2 to be imported in python
export PKG_CONFIG_PATH=$HOME/freenect2/lib/pkgconfig
```
* With this it will always work for any python open from the terminal. Including jupyter notebooks
* But now if we want to run this package in Pycharm or symilar, we can directly copy the 3 files 
(`libfreenect2.2.s0...`) from the `freenect2/lib` folder into the 
`lib` folder of your environment. Ej:
 * if you are using an anaconda environment, open the folder:
  
```
<your_path>/anaconda3/envs/<sandbox-env>/lib
```

* And in this folder paste the previous copied files (3 files!!!). Keep in mind that you need to 
replace the <...> with your specific path.
* If you dont want the manual work then run directly (remember to change the paths according to your needs):

```
sudo cp $HOME/freenect2/lib/libfreenect2{.so,.so.0.2,.so.0.2.0} $HOME/anaconda3/envs/sandbox-env/lib/
```

### LiDAR L515 Installation 

#### Installing in Windows

First, go to the latest release page on [GitHub](https://github.com/IntelRealSense/librealsense/releases/latest) 
and download and execute the file: 

```Intel.RealSense.Viewer.exe```

Follow the instructions for the installation and update the Firmware of your sensor.  You should be able to use and see the depth and RGB image.

#### Installing in Linux 

Detailed installation steps can be found in the 
[linux installation guide](https://github.com/IntelRealSense/librealsense/blob/development/doc/distribution_linux.md). 
The steps are as follows:

- Register the server's public key:  
`sudo apt-key adv --keyserver keys.gnupg.net --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE || sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE`
In case the public key still cannot be retrieved, check and specify proxy settings: `export http_proxy="http://<proxy>:<port>"`  
, and rerun the command. See additional methods in the following [link](https://unix.stackexchange.com/questions/361213/unable-to-add-gpg-key-with-apt-key-behind-a-proxy).  

- Add the server to the list of repositories:  
  Ubuntu 16 LTS:  
`sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo xenial main" -u`  
  Ubuntu 18 LTS:  
`sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo bionic main" -u`  
  Ubuntu 20 LTS:  
`sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo focal main" -u`

- Install the libraries:  
  `sudo apt-get install librealsense2-dkms`  
  `sudo apt-get install librealsense2-utils`  
  
Reconnect the Intel RealSense depth camera and run: `realsense-viewer` to verify the installation.

#### Running with python

After the sensor is installed on your pltaform, the Python wrapper can be easily installed via:

```pip install pyrealsense2```

If any problems with the installation reference to 
[Intel RealSense Python Installation](https://github.com/IntelRealSense/librealsense/tree/master/wrappers/python#installation)

Download sample data
-------

You have the option to download some publicly shared files from our open_AR_Sandbox shared folder. 
You will need to do this if you want to run the tests, use the landslides simulations and/or get the trained models for 
the the use of the Landscape generation module.

In the terminal type:

```
python3 sandbox/utils/download_sample_datasets.py
```

and follow the instruction on the terminal to download the specific files you need. We use 
[Pooch](https://github.com/fatiando/pooch) to help us fetch our data files and store them locally in your computer 
to their respective folders. Running this code a second time will not trigger a download since the file already exists.

External Packages
---------
### GemPy

To use implicit geological models inside the sandbox, go to [GemPy](https://github.com/cgre-aachen/gempy),
clone or download the repository and follow the Gempy Installation instructions. With gempy installed 
you can follow the tutorial [GempyModule](notebooks/tutorials/04_GempyModule/).
```
pip install gempy
```
If using windows you will need to install `Theano` separately as instructed in [here](https://www.gempy.org/installation)
```
conda install mingw libpython m2w64-toolchain
conda install theano
pip install theano --force-reinstall
```
### Devito

This package uses the power of [Devito](https://github.com/devitocodes/devito) to run wave proppagation simmulations.
More about this can be found in `notebooks/tutorials/10_SeismicModule/`. Follow the Devito installation instructions. 
* This module so far have only support in linux 
```
pip install --user git+https://github.com/devitocodes/devito.git
```

### PyGimli
This library is a powerful tool for Geophysical inversion and Modelling. Some examples can be found in 
`notebooks/tutorials/11_Geophysics/`. 
[PyGimli](https://www.pygimli.org/) can be installed following the installation intructions 
[here](https://www.pygimli.org/installation.html)

We recomend creating a new environment where PyGimli is already installed and over that one install the sandbox 
dependencies.
```
conda create -n sandbox-env -c gimli -c conda-forge pygimli=1.1.0
```
* And now go back to [installation](README.md#installation) and follow all over again the instruction but skipping 
step 2. 

### PyTorch

To use the LandscapeGeneration module we need to install [PyTorch](https://pytorch.org/). This module use the power 
of [CycleGAN](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) 
to take a topography from the sandbox, translate this as a DEM and then display it again on the sandbox as a Landscape 
image. 
To install the dependencies for this module do:
```
#For Windows
pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html
```
```
#For Linux
pip install torch torchvision
```
```
git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix
cd pytorch-CycleGAN-and-pix2pix
pip install -r requirements.txt
```
Once this is installed, copy the trained model in `/notebooks/tutorials/09_LandscapeGeneration/checkpoints` folder, 
and then follow the notebook.
Get in contact with us to provide you with the train model for this module. 


Project Development
-------------------

Open-AR-Sandbox is developed at the research unit [Computational Geoscience
and Reservoir Engineering (CGRE)](https://www.cgre.rwth-aachen.de/) at RWTH Aachen University, Germany.

[![CGRE](https://www.cgre.rwth-aachen.de/global/show_picture.asp?id=aaaaaaaaabaxmhn)](https://www.cgre.rwth-aachen.de/)



### Project Lead

[Prof. Florian Wellmann, PhD](https://www.cgre.rwth-aachen.de/cms/CGRE/Das-Lehr-und-Forschungsgebiet/~dnyyj/Prof-Wellmann/lidx/1/)

### Maintainers (also external to CGRE)

* Daniel Escallón 
* Simon Virgo
* Miguel de la Varga

Obtaining a full system
-----------------------

If you are interested in buying a fully operating set-up including appropriate
hardware, pre-installed software, and set-up and maintenance, please contact
[Terranigma Solutions GmbH](https://www.terranigma-solutions.com/services).





================================================
FILE: LICENSE
================================================
                   GNU LESSER GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.


  This version of the GNU Lesser General Public License incorporates
the terms and conditions of version 3 of the GNU General Public
License, supplemented by the additional permissions listed below.

  0. Additional Definitions.

  As used herein, "this License" refers to version 3 of the GNU Lesser
General Public License, and the "GNU GPL" refers to version 3 of the GNU
General Public License.

  "The Library" refers to a covered work governed by this License,
other than an Application or a Combined Work as defined below.

  An "Application" is any work that makes use of an interface provided
by the Library, but which is not otherwise based on the Library.
Defining a subclass of a class defined by the Library is deemed a mode
of using an interface provided by the Library.

  A "Combined Work" is a work produced by combining or linking an
Application with the Library.  The particular version of the Library
with which the Combined Work was made is also called the "Linked
Version".

  The "Minimal Corresponding Source" for a Combined Work means the
Corresponding Source for the Combined Work, excluding any source code
for portions of the Combined Work that, considered in isolation, are
based on the Application, and not on the Linked Version.

  The "Corresponding Application Code" for a Combined Work means the
object code and/or source code for the Application, including any data
and utility programs needed for reproducing the Combined Work from the
Application, but excluding the System Libraries of the Combined Work.

  1. Exception to Section 3 of the GNU GPL.

  You may convey a covered work under sections 3 and 4 of this License
without being bound by section 3 of the GNU GPL.

  2. Conveying Modified Versions.

  If you modify a copy of the Library, and, in your modifications, a
facility refers to a function or data to be supplied by an Application
that uses the facility (other than as an argument passed when the
facility is invoked), then you may convey a copy of the modified
version:

   a) under this License, provided that you make a good faith effort to
   ensure that, in the event an Application does not supply the
   function or data, the facility still operates, and performs
   whatever part of its purpose remains meaningful, or

   b) under the GNU GPL, with none of the additional permissions of
   this License applicable to that copy.

  3. Object Code Incorporating Material from Library Header Files.

  The object code form of an Application may incorporate material from
a header file that is part of the Library.  You may convey such object
code under terms of your choice, provided that, if the incorporated
material is not limited to numerical parameters, data structure
layouts and accessors, or small macros, inline functions and templates
(ten or fewer lines in length), you do both of the following:

   a) Give prominent notice with each copy of the object code that the
   Library is used in it and that the Library and its use are
   covered by this License.

   b) Accompany the object code with a copy of the GNU GPL and this license
   document.

  4. Combined Works.

  You may convey a Combined Work under terms of your choice that,
taken together, effectively do not restrict modification of the
portions of the Library contained in the Combined Work and reverse
engineering for debugging such modifications, if you also do each of
the following:

   a) Give prominent notice with each copy of the Combined Work that
   the Library is used in it and that the Library and its use are
   covered by this License.

   b) Accompany the Combined Work with a copy of the GNU GPL and this license
   document.

   c) For a Combined Work that displays copyright notices during
   execution, include the copyright notice for the Library among
   these notices, as well as a reference directing the user to the
   copies of the GNU GPL and this license document.

   d) Do one of the following:

       0) Convey the Minimal Corresponding Source under the terms of this
       License, and the Corresponding Application Code in a form
       suitable for, and under terms that permit, the user to
       recombine or relink the Application with a modified version of
       the Linked Version to produce a modified Combined Work, in the
       manner specified by section 6 of the GNU GPL for conveying
       Corresponding Source.

       1) Use a suitable shared library mechanism for linking with the
       Library.  A suitable mechanism is one that (a) uses at run time
       a copy of the Library already present on the user's computer
       system, and (b) will operate properly with a modified version
       of the Library that is interface-compatible with the Linked
       Version.

   e) Provide Installation Information, but only if you would otherwise
   be required to provide such information under section 6 of the
   GNU GPL, and only to the extent that such information is
   necessary to install and execute a modified version of the
   Combined Work produced by recombining or relinking the
   Application with a modified version of the Linked Version. (If
   you use option 4d0, the Installation Information must accompany
   the Minimal Corresponding Source and Corresponding Application
   Code. If you use option 4d1, you must provide the Installation
   Information in the manner specified by section 6 of the GNU GPL
   for conveying Corresponding Source.)

  5. Combined Libraries.

  You may place library facilities that are a work based on the
Library side by side in a single library together with other library
facilities that are not Applications and are not covered by this
License, and convey such a combined library under terms of your
choice, if you do both of the following:

   a) Accompany the combined library with a copy of the same work based
   on the Library, uncombined with any other library facilities,
   conveyed under the terms of this License.

   b) Give prominent notice with the combined library that part of it
   is a work based on the Library, and explaining where to find the
   accompanying uncombined form of the same work.

  6. Revised Versions of the GNU Lesser General Public License.

  The Free Software Foundation may publish revised and/or new versions
of the GNU Lesser General Public License from time to time. Such new
versions will be similar in spirit to the present version, but may
differ in detail to address new problems or concerns.

  Each version is given a distinguishing version number. If the
Library as you received it specifies that a certain numbered version
of the GNU Lesser General Public License "or any later version"
applies to it, you have the option of following the terms and
conditions either of that published version or of any later version
published by the Free Software Foundation. If the Library as you
received it does not specify a version number of the GNU Lesser
General Public License, you may choose any version of the GNU Lesser
General Public License ever published by the Free Software Foundation.

  If the Library as you received it specifies that a proxy can decide
whether future versions of the GNU Lesser General Public License shall
apply, that proxy's public statement of acceptance of any version is
permanent authorization for you to choose that version for the
Library.



================================================
FILE: requirements.txt
================================================
matplotlib>=3.5
numpy
pandas
panel>=0.10.2
scipy
scikit-image
opencv-contrib-python
pytest
jupyter
cython
seaborn
tqdm
pooch
colorama
pysolar
sphinx
nbsphinx
sphinx-rtd-theme
sphinx-markdown-tables
sphinx-copybutton



================================================
FILE: sandbox_environment.yml
================================================
name: sandbox-env
channels:
  - gimli
  - conda-forge
  - defaults
dependencies:
  - _libgcc_mutex=0.1=conda_forge
  - _openmp_mutex=4.5=1_gnu
  - alsa-lib=1.2.3=h516909a_0
  - appdirs=1.4.4=pyh9f0ad1d_0
  - attrs=21.2.0=pyhd8ed1ab_0
  - binutils_impl_linux-64=2.36.1=h193b22a_2
  - binutils_linux-64=2.36=hf3e587d_2
  - boost=1.72.0=py37h48f8a5e_1
  - boost-cpp=1.72.0=h312852a_5
  - brotli=1.0.9=h7f98852_6
  - brotli-bin=1.0.9=h7f98852_6
  - bzip2=1.0.8=h7f98852_4
  - c-ares=1.18.1=h7f98852_0
  - ca-certificates=2021.10.8=ha878542_0
  - cached-property=1.5.2=hd8ed1ab_1
  - cached_property=1.5.2=pyha770c72_1
  - certifi=2021.10.8=py37h89c1867_1
  - cftime=1.5.1.1=py37hb1e94ed_1
  - curl=7.80.0=h2574ce0_0
  - cycler=0.11.0=pyhd8ed1ab_0
  - dbus=1.13.6=h48d8840_2
  - double-conversion=3.1.6=h9c3ff4c_0
  - eigen=3.4.0=h4bd325d_0
  - expat=2.4.1=h9c3ff4c_0
  - ffmpeg=4.3.2=hca11adc_1
  - fontconfig=2.13.1=hba837de_1005
  - fonttools=4.28.3=py37h5e8e339_0
  - freetype=2.10.4=h0708190_1
  - gcc_impl_linux-64=11.2.0=h82a94d6_11
  - gcc_linux-64=11.2.0=h39a9532_2
  - gettext=0.19.8.1=h73d1719_1008
  - gl2ps=1.4.2=h0708190_0
  - glew=2.1.0=h9c3ff4c_2
  - glib=2.70.2=h780b84a_0
  - glib-tools=2.70.2=h780b84a_0
  - gmp=6.2.1=h58526e2_0
  - gnutls=3.6.13=h85f3911_1
  - gst-plugins-base=1.18.5=hf529b03_2
  - gstreamer=1.18.5=h9f60fe5_2
  - gxx_impl_linux-64=11.2.0=h82a94d6_11
  - gxx_linux-64=11.2.0=hacbe6df_2
  - h5py=3.6.0=nompi_py37hd308b1e_100
  - hdf4=4.2.15=h10796ff_3
  - hdf5=1.12.1=nompi_h2750804_103
  - icu=68.2=h9c3ff4c_0
  - imageio=2.13.3=pyh239f2a4_0
  - importlib-metadata=4.8.2=py37h89c1867_0
  - importlib_metadata=4.8.2=hd8ed1ab_0
  - iniconfig=1.1.1=pyh9f0ad1d_0
  - jbig=2.1=h7f98852_2003
  - jpeg=9d=h36c2ea0_0
  - jsoncpp=1.9.4=h4bd325d_3
  - kernel-headers_linux-64=2.6.32=he073ed8_15
  - kiwisolver=1.3.2=py37h2527ec5_1
  - krb5=1.19.2=hcc1bbae_3
  - lame=3.100=h7f98852_1001
  - lcms2=2.12=hddcbb42_0
  - ld_impl_linux-64=2.36.1=hea4e1c9_2
  - lerc=3.0=h9c3ff4c_0
  - libblas=3.9.0=12_linux64_openblas
  - libbrotlicommon=1.0.9=h7f98852_6
  - libbrotlidec=1.0.9=h7f98852_6
  - libbrotlienc=1.0.9=h7f98852_6
  - libcblas=3.9.0=12_linux64_openblas
  - libclang=11.1.0=default_ha53f305_1
  - libcurl=7.80.0=h2574ce0_0
  - libdeflate=1.8=h7f98852_0
  - libedit=3.1.20191231=he28a2e2_2
  - libev=4.33=h516909a_1
  - libevent=2.1.10=h9b69904_4
  - libffi=3.4.2=h7f98852_5
  - libgcc-devel_linux-64=11.2.0=h0952999_11
  - libgcc-ng=11.2.0=h1d223b6_11
  - libgfortran-ng=11.2.0=h69a702a_11
  - libgfortran5=11.2.0=h5c6108e_11
  - libglib=2.70.2=h174f98d_0
  - libglu=9.0.0=he1b5a44_1001
  - libgomp=11.2.0=h1d223b6_11
  - libiconv=1.16=h516909a_0
  - liblapack=3.9.0=12_linux64_openblas
  - libllvm11=11.1.0=hf817b99_2
  - libnetcdf=4.8.1=nompi_hb3fd0d9_101
  - libnghttp2=1.43.0=h812cca2_1
  - libnsl=2.0.0=h7f98852_0
  - libogg=1.3.4=h7f98852_1
  - libopenblas=0.3.18=pthreads_h8fe5266_0
  - libopus=1.3.1=h7f98852_1
  - libpng=1.6.37=h21135ba_2
  - libpq=13.5=hd57d9b9_1
  - libsanitizer=11.2.0=he4da1e4_11
  - libssh2=1.10.0=ha56f1ee_2
  - libstdcxx-devel_linux-64=11.2.0=h0952999_11
  - libstdcxx-ng=11.2.0=he4da1e4_11
  - libtheora=1.1.1=h7f98852_1005
  - libtiff=4.3.0=h6f004c6_2
  - libuuid=2.32.1=h7f98852_1000
  - libvorbis=1.3.7=h9c3ff4c_0
  - libwebp-base=1.2.1=h7f98852_0
  - libxcb=1.13=h7f98852_1004
  - libxkbcommon=1.0.3=he3ba5ed_0
  - libxml2=2.9.12=h72842e0_0
  - libzip=1.8.0=h4de3113_1
  - libzlib=1.2.11=h36c2ea0_1013
  - loguru=0.5.3=py37h89c1867_3
  - lz4-c=1.9.3=h9c3ff4c_1
  - matplotlib=3.5.0=py37h89c1867_0
  - matplotlib-base=3.5.0=py37h1058ff1_0
  - meshio=4.4.6=pyhd8ed1ab_0
  - metis=5.1.0=h58526e2_1006
  - more-itertools=8.12.0=pyhd8ed1ab_0
  - mpfr=4.1.0=h9202a9a_1
  - munkres=1.1.4=pyh9f0ad1d_0
  - mysql-common=8.0.27=ha770c72_2
  - mysql-libs=8.0.27=hfa10184_2
  - ncurses=6.2=h58526e2_4
  - netcdf4=1.5.8=nompi_py37hf784469_101
  - nettle=3.6=he412f7d_0
  - nspr=4.32=h9c3ff4c_1
  - nss=3.73=hb5efdd6_0
  - numpy=1.18.5=py37h8960a57_0
  - olefile=0.46=pyh9f0ad1d_1
  - openblas=0.3.18=pthreads_h4748800_0
  - openh264=2.1.1=h780b84a_0
  - openjpeg=2.4.0=hb52868f_1
  - openssl=1.1.1l=h7f98852_0
  - packaging=21.3=pyhd8ed1ab_0
  - pcre=8.45=h9c3ff4c_0
  - pillow=8.4.0=py37h0f21c89_0
  - pip=21.3.1=pyhd8ed1ab_0
  - pluggy=1.0.0=py37h89c1867_2
  - proj=8.2.0=h277dcde_0
  - pthread-stubs=0.4=h36c2ea0_1001
  - pugixml=1.11.4=h9c3ff4c_0
  - py=1.11.0=pyh6c4a22f_0
  - pygimli=1.1.0=np118py37hf484d3e_1
  - pyparsing=3.0.6=pyhd8ed1ab_0
  - pyqt=5.12.3=py37h89c1867_8
  - pyqt-impl=5.12.3=py37hac37412_8
  - pyqt5-sip=4.19.18=py37hcd2ae1e_8
  - pyqtchart=5.12=py37he336c9b_8
  - pyqtwebengine=5.12.1=py37he336c9b_8
  - pytest=6.2.5=py37h89c1867_1
  - python=3.7.12=hb7a2778_100_cpython
  - python-dateutil=2.8.2=pyhd8ed1ab_0
  - python_abi=3.7=2_cp37m
  - pyvista=0.32.1=pyhd8ed1ab_0
  - qt=5.12.9=hda022c4_4
  - readline=8.1=h46c0cb4_0
  - scipy=1.7.3=py37hf2a6cf1_0
  - scooby=0.5.9=pyhd8ed1ab_0
  - setuptools=59.4.0=py37h89c1867_0
  - six=1.16.0=pyh6c4a22f_0
  - sqlite=3.37.0=h9cd32fc_0
  - suitesparse=5.10.1=h9e50725_1
  - sysroot_linux-64=2.12=he073ed8_15
  - tbb=2021.4.0=h4bd325d_1
  - tbb-devel=2021.4.0=h4bd325d_1
  - tetgen=1.6.0=he1b5a44_0
  - tk=8.6.11=h27826a3_1
  - toml=0.10.2=pyhd8ed1ab_0
  - tornado=6.1=py37h5e8e339_2
  - typing_extensions=4.0.1=pyha770c72_0
  - unicodedata2=13.0.0.post2=py37h5e8e339_4
  - utfcpp=3.2.1=ha770c72_0
  - vtk=9.1.0=qt_py37h5198534_203
  - wheel=0.37.0=pyhd8ed1ab_1
  - x264=1!161.3030=h7f98852_1
  - xorg-kbproto=1.0.7=h7f98852_1002
  - xorg-libice=1.0.10=h7f98852_0
  - xorg-libsm=1.2.3=hd9c2040_1000
  - xorg-libx11=1.7.2=h7f98852_0
  - xorg-libxau=1.0.9=h7f98852_0
  - xorg-libxdmcp=1.1.3=h7f98852_0
  - xorg-libxext=1.3.4=h7f98852_1
  - xorg-libxt=1.2.1=h7f98852_2
  - xorg-xextproto=7.3.0=h7f98852_1002
  - xorg-xproto=7.0.31=h7f98852_1007
  - xz=5.2.5=h516909a_1
  - zipp=3.6.0=pyhd8ed1ab_0
  - zlib=1.2.11=h36c2ea0_1013
  - zstd=1.5.0=ha95c52a_0
  - pip:
    - alabaster==0.7.12
    - argcomplete==1.12.3
    - argon2-cffi==21.3.0
    - argon2-cffi-bindings==21.2.0
    - babel==2.9.1
    - backcall==0.2.0
    - bleach==4.1.0
    - bokeh==2.4.2
    - cffi==1.15.0
    - charset-normalizer==2.0.9
    - colorama==0.4.4
    - cython==0.29.25
    - debugpy==1.5.1
    - decorator==5.1.0
    - defusedxml==0.7.1
    - docutils==0.17.1
    - entrypoints==0.3
    - idna==3.3
    - imagesize==1.3.0
    - importlib-resources==5.4.0
    - ipykernel==6.6.0
    - ipython==7.30.1
    - ipython-genutils==0.2.0
    - ipywidgets==7.6.5
    - jedi==0.18.1
    - jinja2==3.0.3
    - jsonschema==4.2.1
    - jupyter==1.0.0
    - jupyter-client==7.1.0
    - jupyter-console==6.4.0
    - jupyter-core==4.9.1
    - jupyterlab-pygments==0.1.2
    - jupyterlab-widgets==1.0.2
    - markdown==3.3.6
    - markupsafe==2.0.1
    - matplotlib-inline==0.1.3
    - mistune==0.8.4
    - nbclient==0.5.9
    - nbconvert==6.3.0
    - nbformat==5.1.3
    - nbsphinx==0.8.7
    - nest-asyncio==1.5.4
    - networkx==2.6.3
    - notebook==6.4.6
    - opencv-contrib-python==4.5.4.60
    - pandas==1.3.5
    - pandocfilters==1.5.0
    - panel==0.12.6
    - param==1.12.0
    - parso==0.8.3
    - pexpect==4.8.0
    - pickleshare==0.7.5
    - pooch==1.5.2
    - prometheus-client==0.12.0
    - prompt-toolkit==3.0.24
    - ptyprocess==0.7.0
    - pycparser==2.21
    - pyct==0.4.8
    - pygments==2.10.0
    - pyrsistent==0.18.0
    - pysolar==0.10
    - pytz==2021.3
    - pyviz-comms==2.1.0
    - pywavelets==1.2.0
    - pyyaml==6.0
    - pyzmq==22.3.0
    - qtconsole==5.2.1
    - qtpy==1.11.3
    - requests==2.26.0
    - scikit-image==0.19.0
    - seaborn==0.11.2
    - send2trash==1.8.0
    - snowballstemmer==2.2.0
    - sphinx==4.3.1
    - sphinx-copybutton==0.4.0
    - sphinx-markdown-tables==0.0.15
    - sphinx-rtd-theme==1.0.0
    - sphinxcontrib-applehelp==1.0.2
    - sphinxcontrib-devhelp==1.0.2
    - sphinxcontrib-htmlhelp==2.0.0
    - sphinxcontrib-jsmath==1.0.1
    - sphinxcontrib-qthelp==1.0.3
    - sphinxcontrib-serializinghtml==1.1.5
    - terminado==0.12.1
    - testpath==0.5.0
    - tifffile==2021.11.2
    - torch==1.10.0
    - torchvision==0.11.1
    - tqdm==4.62.3
    - traitlets==5.1.1
    - urllib3==1.26.7
    - wcwidth==0.2.5
    - webencodings==0.5.1
    - widgetsnbextension==3.5.2
prefix: /home/daniel/anaconda3/envs/sandbox-env



================================================
FILE: sandbox_server.py
================================================
# sandbox_server.py
from bokeh.plotting import curdoc
from sandbox import _calibration_dir

_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

from sandbox.projector import Projector
from sandbox.sensor import Sensor
from sandbox.markers import MarkerDetection

projector = Projector(calibprojector=_calibprojector, use_panel=True)
sensor = Sensor(calibsensor=_calibsensor, name="kinect_v2")
aruco = MarkerDetection(sensor=sensor)

external_modules = dict(gempy_module=True,
                        gimli_module=True,
                        torch_module=True,
                        devito_module=True)

from sandbox.sandbox_api import Sandbox
module = Sandbox(sensor=sensor,
                 projector=projector,
                 aruco=aruco,
                 kwargs_external_modules=external_modules)

main_widget = module.show_widgets()

current = main_widget.get_root()
curdoc().add_root(current)



================================================
FILE: setup.py
================================================
from setuptools import setup, find_packages
version = '1.0'

with open("README.md", "r") as fh:
    long_description = fh.read()

setup(
    name='arsandbox',
    version=version,
    packages=find_packages(exclude=('test', 'docs')),
    include_package_data=True,
    install_requires=[
        'matplotlib >= 3.5',
        'numpy',
        'pandas',
        'panel >= 0.10.2',
        'scipy',
        'scikit-image',
        'opencv-contrib-python',
        'pytest',
        'jupyter',
        'cython',
        'seaborn',
        'tqdm',
        'pooch',
        'colorama',
        'pysolar',
    	'sphinx',
    	'nbsphinx',
   	'sphinx-rtd-theme',
   	'sphinx-markdown-tables',
   	'sphinx-copybutton',

    ],
    url='https://github.com/cgre-aachen/open_AR_Sandbox',
    license='LGPL v3',
    author='Daniel Escallon, Simon Virgo, Miguel de la Varga',
    author_email='simon@terranigma-solutions.com',
    description='An Open-source, Python-based Augmented reality (AR) sandbox to display many modules.',
    keywords=['AR', 'Augmented reality', 'sandbox', 'geology']
)



================================================
FILE: start_server.cmd
================================================
panel serve sandbox_server.py --show




================================================
FILE: docs/make.bat
================================================
@ECHO OFF

pushd %~dp0

REM Command file for Sphinx documentation

if "%SPHINXBUILD%" == "" (
	set SPHINXBUILD=sphinx-build
)
set SOURCEDIR=source
set BUILDDIR=build

if "%1" == "" goto help

%SPHINXBUILD% >NUL 2>NUL
if errorlevel 9009 (
	echo.
	echo.The 'sphinx-build' command was not found. Make sure you have Sphinx
	echo.installed, then set the SPHINXBUILD environment variable to point
	echo.to the full path of the 'sphinx-build' executable. Alternatively you
	echo.may add the Sphinx directory to PATH.
	echo.
	echo.If you don't have Sphinx installed, grab it from
	echo.http://sphinx-doc.org/
	exit /b 1
)

%SPHINXBUILD% -M %1 %SOURCEDIR% %BUILDDIR% %SPHINXOPTS% %O%
goto end

:help
%SPHINXBUILD% -M help %SOURCEDIR% %BUILDDIR% %SPHINXOPTS% %O%

:end
popd



================================================
FILE: docs/Makefile
================================================
# Minimal makefile for Sphinx documentation
#

# You can set these variables from the command line, and also
# from the environment for the first two.
SPHINXOPTS    ?=
SPHINXBUILD   ?= sphinx-build
SOURCEDIR     = source
BUILDDIR      = build

# Put it first so that "make" without argument is like "make help".
help:
	@$(SPHINXBUILD) -M help "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)

.PHONY: help Makefile

# Catch-all target: route all unknown targets to Sphinx using the new
# "make mode" option.  $(O) is meant as a shortcut for $(SPHINXOPTS).
%: Makefile
	@$(SPHINXBUILD) -M $@ "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)



================================================
FILE: docs/source/conf.py
================================================
# Configuration file for the Sphinx documentation builder.
#
# This file only contains a selection of the most common options. For a full
# list see the documentation:
# https://www.sphinx-doc.org/en/master/usage/configuration.html

# -- Path setup --------------------------------------------------------------

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#
# import os
# import sys
# sys.path.insert(0, os.path.abspath('.'))


# -- Project information -----------------------------------------------------

project = 'open_AR_Sandbox'
copyright = '2021, Professor Florian Wellmann'
author = 'Daniel'

# The full version, including alpha/beta/rc tags
release = '0.0.1'


# -- General configuration ---------------------------------------------------

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = ['nbsphinx',
              'sphinx_rtd_theme',
              'sphinx.ext.autodoc',
              'sphinx.ext.napoleon',
              'sphinx.ext.doctest',
              'sphinx.ext.autosummary',
              'sphinx_markdown_tables',
              'sphinx_copybutton',
              #'sphinx_gallery.gen_gallery',
              'sphinx.ext.extlinks',
              'sphinx.ext.coverage',
              'sphinx.ext.mathjax',
]

github_url = 'https://github.com/cgre-aachen/open_AR_Sandbox'

html_context = {#'source_url_prefix': "https://github.com/cgre-aachen/open_AR_Sandbox",
                'display_github': True, # Add 'Edit on Github' link instead of 'View page source'
                #'last_updated': True,
                #'commit': False,
                #'github_repo': "https://github.com/cgre-aachen/open_AR_Sandbox",
}

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
# This pattern also affects html_static_path and html_extra_path.
exclude_patterns = []


# -- Options for HTML output -------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'sphinx_rtd_theme'

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']



================================================
FILE: docs/source/index.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Wed Apr 14 14:42:50 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Welcome to open_AR_Sandbox's documentation!
===========================================

.. toctree::
   :maxdepth: 3
   :caption: Getting Started
   :glob:

   getting_started/about
   getting_started/features
   getting_started/modules
   getting_started/license
   getting_started/requirements
   getting_started/installation
   getting_started/download sample data
   getting_started/external packages
   getting_started/project development
   getting_started/interest


================================================
FILE: docs/source/getting_started/about.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Tue Apr 14 17:11:54 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

About
=====

Welcome to the `open_AR_Sandbox <https://github.com/cgre-aachen/open_AR_Sandbox>`_ repository. If you do not know what
this is all about, have a look at this video:

⚠️Warning! It is unfortunate that we have to state this here, but:

Downloading the software and presenting it somewhere as your own work is serious scientific fraud! And if you develop
content further, then please push these developments back to this repostory - in the very interest of scientific
development (and also a requirement of the license). For more details, please consult the information below and the
license.

Augmented Reality - Geology Sandbox 2

.. raw:: html

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
        <iframe src="https://www.youtube.com/watch?v=oE3Atw-YvSA" frameborder="0" allowfullscreen style="position: absolute;
         top: 0; left: 0; width: 100%; height: 90%; margin-bottom: 2em;"></iframe>
    </div>

Lunch Lehre am 5. Februar 2020 (unfortunaltely only in German)

.. raw:: html

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
        <iframe src="https://www.youtube.com/watch?v=RIvYO1lx6vs" frameborder="0" allowfullscreen style="position: absolute;
         top: 0; left: 0; width: 100%; height: 90%; margin-bottom: 2em;"></iframe>
    </div>

Augmented Reality (AR) Sandboxes are a great tool for science outreach and teaching due to their intuitive and
interaction-enhancing operation. Recently AR Sandboxes are becoming increasingly popular as interactive exhibition
pieces, teaching aids and toys.

AR Sandboxes consist of a box of sand that can be freely sculpted by hand. The topography of the sand is constantly
scanned with a depth camera and a computed image is projected back onto the sand surface, augmenting the sandbox with
digital information.

However, most of these common AR Sandboxes are limited to the visualization of topography with contour lines and colors,
as well as water simulations on the digital terrain surface. The potential for AR Sandboxes for geoscience education,
and especially for teaching structural geology, remains largely untapped.

For this reason, we have developed `open_AR_Sandbox <https://github.com/cgre-aachen/open_AR_Sandbox>`_, an augmented
reality sandbox designed specifically for the use in geoscience education. In addition to the visualization of
topography it can display geologic subsurface information such as the outcropping lithology, creating a dynamic and
interactive geological map. The relations of subsurface structures, topography and outcrop can be explored in a playful
and comprehensible way.

.. |contributors| image:: https://img.shields.io/github/contributors/cgre-aachen/open_AR_Sandbox.svg?logo=python&logoColor=white
   :target: https://github.com/cgre-aachen/open_AR_Sandbox/graphs/contributors/

.. |stars| image:: https://img.shields.io/github/stars/cgre-aachen/open_AR_Sandbox?style=social&label=Stars
   :target: https://github.com/cgre-aachen/open_AR_Sandbox/
   :alt: GitHub

.. |downloads| image:: https://img.shields.io/pypi/dm/open_AR_Sandbox
   :target: https://github.com/cgre-aachen/open_AR_Sandbox/

.. |license| image:: https://img.shields.io/github/license/cgre-aachen/open_AR_Sandbox
   :target: http://www.gnu.org/licenses/lgpl-3.0.en.html

.. |documentation| image:: https://readthedocs.org/projects/open-AR-Sandbox/badge/?version=latest
   :target: https://open-ar-sandbox.readthedocs.io/en/latest/
   :alt: Documentation Status

.. |github_workflow| image:: https://img.shields.io/github/workflow/status/cgre-aachen/open_AR_Sandbox/open_AR_Sandbox
   :alt: GitHub Workflow Status

.. |open_issues| image:: https://img.shields.io/github/issues-raw/cgre-aachen/open_AR_Sandbox
   :alt: GitHub issues

.. |closed_issues| image:: https://img.shields.io/github/issues-closed-raw/cgre-aachen/open_AR_Sandbox
   :alt: GitHub closed issues

.. |pull_requests| image:: https://img.shields.io/github/issues-pr-raw/cgre-aachen/open_AR_Sandbox
   :alt: GitHub pull requests

.. |closed_pull_requests| image:: https://img.shields.io/github/issues-pr-closed-raw/cgre-aachen/open_AR_Sandbox
   :alt: GitHub closed pull requests

.. |binder| image:: https://mybinder.org/badge_logo.svg
   :target: https://mybinder.org/v2/gh/cgre-aachen/open_AR_Sandbox/master
   :alt: Binder

+----------------------+----------------------------------------+
| Deployment           | |pypi| |downloads|                     |
+----------------------+----------------------------------------+
| GitHub               | |contributors| |stars|                 |
+----------------------+----------------------------------------+
| Binder               | |binder|                               |
+----------------------+----------------------------------------+
| License              | |license|                              |
+----------------------+----------------------------------------+
| Documentation        | |documentation|                        |
+----------------------+----------------------------------------+
| GitHub workflow      | |github_workflow|                      |
+----------------------+----------------------------------------+
| Issue tracking       | |open_issues| |closed_issues|          |
+----------------------+----------------------------------------+
| Pull requests        | |pull_requests| |closed_pull_requests| |
+----------------------+----------------------------------------+





================================================
FILE: docs/source/getting_started/download sample data.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Tue Apr 14 17:11:54 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Download sample data
====================

You have the option to download some publicly shared files from our
`open_AR_Sandbox <https://github.com/cgre-aachen/open_AR_Sandbox>`_ shared folder. You will need to do this if you want
to run the tests, use the landslides simulations and/or get the trained models for the the use of the Landscape
generation module.

In the terminal type::

   python3 sandbox/utils/download_sample_datasets.py

and follow the instruction on the terminal to download the specific files you need. We use Pooch to help us fetch our
data files and store them locally in your computer to their respective folders. Running this code a second time will not
trigger a download since the file already exists.


================================================
FILE: docs/source/getting_started/external packages.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Tue Apr 14 17:11:54 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

External packages
=================

GemPy
~~~~~

To use implicit geological models inside the sandbox, go to `GemPy <https://www.gempy.org/>`_, clone or download the
repository and follow the `GemPy <https://www.gempy.org/>`_ Installation instructions. With
`GemPy <https://www.gempy.org/>`_ installed you can follow the tutorial GempyModule::

   pip install gempy

If using windows you will need to install Theano separately as instructed in here::

   conda install mingw libpython m2w64-toolchain
   conda install theano
   pip install theano --force-reinstall

Devito
~~~~~~

This package uses the power of `Devito <https://www.devitoproject.org/>`_ to run wave proppagation simmulations. More
about this can be found in notebooks/tutorials/10_SeismicModule/. Follow the `Devito <https://www.devitoproject.org/>`_
installation instructions. This module so far have only support in Linux::

   pip install --user git+https://github.com/devitocodes/devito.git

PyGimli
~~~~~~~

This library is a powerful tool for geophysical inversion and modelling. Some examples can be found in
notebooks/tutorials/11_Geophysics/. `PyGimli <https://www.pygimli.org/>`_ can be installed following the installation
intructions here. We recomend creating a new environment where `PyGimli <https://www.pygimli.org/>`_ is already
installed and over that one install the sandbox dependencies::

   conda create -n sandbox-env -c gimli -c conda-forge pygimli=1.1.0

And now go back to installation and follow all over again the instruction but skipping step 2::

   PyTorch

To use the LandscapeGeneration module we need to install PyTorch. This module use the power of CycleGAN to take a
topography from the sandbox, translate this as a DEM and then display it again on the sandbox as a Landscape image.
To install the dependencies for this module do:

- For Windows::

   pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html

- For Linux::

   pip install torch torchvision
   git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix
   cd pytorch-CycleGAN-and-pix2pix
   pip install -r requirements.txt

Once this is installed, copy the trained model in /notebooks/tutorials/09_LandscapeGeneration/checkpoints folder, and
then follow the notebook. Get in contact with us to provide you with the train model for this module.


================================================
FILE: docs/source/getting_started/features.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Tue Apr 14 17:11:54 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Features
========

- Compatible with most AR Sandbox builds
- Subroutine for calibration and alignment of depth image, sand surface and projection
- Versatile model creation with the powerful `GemPy <https://www.gempy.org/>`_ library
- Open-source under `GNU Lesser General Public License v3.0 <https://www.gnu.org/licenses/lgpl-3.0.de.html>`_
- Fully customizable color map, contours and fault line visualization
- Computer vision algorithms that have been added recently to the sandbox open up a whole new field of possibilities!
  By placing printed markers into the sandbox, the user can trigger actions or define points, lines and areas in the
  sandbox without using the computer



================================================
FILE: docs/source/getting_started/installation.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Tue Apr 14 17:11:54 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Installation
============

First of all you will need a healthy `Python 3 <https://www.python.org/>`_ environment. We recommend using
`Anaconda <https://www.anaconda.com/>`_. In addition to some standard `Python 3 <https://www.python.org/>`_ packages,
you will need a specific setup dependent on the Kinect version you are using. In the following we provide detailed
installation instructions.

open_AR_Sandbox package
~~~~~~~~~~~~~~~~~~~~~~~

Download or clone this repository `open_AR_Sandbox <https://github.com/cgre-aachen/open_AR_Sandbox>`_ from GitHub.

First: Clone the repository::

   git clone https://github.com/cgre-aachen/open_AR_Sandbox.git

Second: Create a new anaconda environment::

   conda create -n sandbox-env python

Third: When you want to use the sandbox and the packages we are about to install you will have to activate the
environment before starting anything::

   conda activate sandbox-env


Standard packages
~~~~~~~~~~~~~~~~~

To install all the standard packages please use the requirements.txt file::

   pip install -r requirements.txt

You can also have a local installation of the sandbox by using the File "setup.py" by doing::

   pip install -e


Kinect
~~~~~~

For Windows
^^^^^^^^^^^

- Kinect v1 - Future
There is still no support for Kinect v1!

- Kinect v2 - PyKinect2 (tested on Windows 10)
Install the current Kinect SDK including drivers. You can use the software bundle to test the connection to your kinect,
before you continue.

To make Python and the Kinect SDK communicate, install the related PyKinect2 wrappers which can be easily installed
via::

   pip install pykinect2

Unfortunately, the configuration of PyKinect2 needs to be adjusted to work on a 64 bit System. Therefore, edit the
Lib/site-packages/pykinect2/PyKinectV2.py file, go to line 2216 and comment it::

   # assert sizeof(tagSTATSTG) == 72, sizeof(tagSTATSTG)

Add the following lines below::

   import numpy.distutils.system_info as sysinfo
   required_size = 64 + sysinfo.platform_bits / 4
   assert sizeof(tagSTATSTG) == required_size, sizeof(tagSTATSTG)


For Linux
^^^^^^^^^

- Kinect v1 - libfreenect
To make `open_AR_Sandbox <https://github.com/cgre-aachen/open_AR_Sandbox>`_ talk to the first generation kinect you will
need the Libfreenect Drivers with Python Wrappers. The installation is kind of straight forward for Linux and MacOS but
challenging for Microsoft (in fact: if you pull it off, let us know how you did it!) The steps can be summarized as
follows (refer to any problems regarding installation in to link) To build libfreenect, you'll need

-> libusb >= 1.0.18 (Windows needs >= 1.0.22)
-> CMake >= 3.12.4 (you can visit this page for detailed instructions for the installation)

Once these are installed we can follow the next commands::

   sudo apt-get install git cmake build-essential libusb-1.0-0-dev
   sudo apt-get install freeglut3-dev libxmu-dev libxi-dev
   git clone https://github.com/OpenKinect/libfreenect
   cd libfreenect
   mkdir build
   cd build
   cmake -L .. # -L lists all the project options
   cmake .. -DBUILD_PYTHON3=ON
   make


   cd ../wrappers/python
   python setup.py install
   # now you can see if the installation worked running an example
   python demo_cv2_async.py


- Kinect v2 - freenect2 or pylibfreenect2

For this we are going to use a python interface for the library libfreenect2 called freenect2.

First we need to install the freenect2 as described in the installation guide. The steps can be summarized as follows
(refer to any problems regarding installation in to link)::

   git clone https://github.com/OpenKinect/libfreenect2.git
   cd libfreenect2

   sudo apt-get install build-essential cmake pkg-config
   sudo apt-get install libusb-1.0-0-dev libturbojpeg0-dev libglfw3-dev


With all the dependencies installed now we can make and install::

   mkdir build && cd build
   cmake .. -DENABLE_CXX11=ON -DENABLE_OPENCL=ON -DENABLE_OPENGL=ON -DBUILD_OPENNI2_DRIVER=ON -DCMAKE_INSTALL_PREFIX=$HOME/freenect2 -DCMAKE_VERBOSE_MAKEFILE=ON
   make
   make install


Set up udev rules for device access::

   sudo cp ../platform/linux/udev/90-kinect2.rules /etc/udev/rules.d/

Now unplug and replug the Kinect sensor.

Test if the kinect is correctly installed, by running::

   ./bin/Protonect

You should be able to see the kinect image working. If not, check libfreenect2 installation guide for more detailed
instructions of installation.

If everything is working until now, we can install the python wrapper. For this first we need to indicate where the
freenect2 folder can be found::

   export PKG_CONFIG_PATH=$HOME/freenect2/lib/pkgconfig

NOTE: If you installed the freenect2 in other location, specify variables with the corresponding path

Now we can use pip install, or any other method described in the freenect2 installation guide::

   pip install freenect2

IMPORTANT: To this point will work in any python that starts with the terminal. Nevertheless, if we start python from
another source, the error ImportError: libfreenect2.so.0.2: cannot open shared object file: No such file or directory
will appear every time we import the package. To fix this problem we will need to export the variables again or if you
want a more permanent solution, open the .bashrc file and paste the following at the end of the file::

   # set PATH to freenect2 to be imported in python
   export PKG_CONFIG_PATH=$HOME/freenect2/lib/pkgconfig

With this it will always work for any python open from the terminal. Including jupyter notebooks

But now if we want to run this package in Pycharm or symilar, we can directly copy the 3 files (libfreenect2.2.s0...)
from the freenect2/lib folder into the lib folder of your environment. For instance, if you are using an anaconda
environment, open the folder::

   <your_path>/anaconda3/envs/<sandbox-env>/lib

In this folder paste the previous copied files (3 files!!!). Keep in mind that you need to replace the <...> with your
specific path. If you dont want the manual work then run directly (remember to change the paths according to your
needs)::

   sudo cp $HOME/freenect2/lib/libfreenect2{.so,.so.0.2,.so.0.2.0} $HOME/anaconda3/envs/sandbox-env/lib/

LiDAR L515
~~~~~~~~~~

For Windows
^^^^^^^^^^^
First, go to the latest release page on GitHub and download and execute the file::

   Intel.RealSense.Viewer.exe

Follow the instructions for the installation and update the firmware of your sensor. You should be able to use and see
the depth and RGB image.

For Linux
^^^^^^^^^
Detailed installation steps can be found in the linux installation guide. The steps are as follows:

Register the server's public key::

   sudo apt-key adv --keyserver keys.gnupg.net --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE || sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE

In case the public key still cannot be retrieved, check and specify proxy settings::

   export http_proxy="http://<proxy>:<port>"

and rerun the command. See additional methods in the following link.

Add the server to the list of repositories:

Ubuntu 16 LTS::

   sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo xenial main" -u

Ubuntu 18 LTS::

   sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo bionic main" -u

Ubuntu 20 LTS::

   sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo focal main" -u

Install the libraries::

   sudo apt-get install librealsense2-dkms
   sudo apt-get install librealsense2-utils

Reconnect the Intel RealSense depth camera and run::

   realsense-viewer

to verify the installation.

Running with python
^^^^^^^^^^^^^^^^^^^

After the sensor is installed on your pltaform, the Python wrapper can be easily installed via::

   pip install pyrealsense2

If any problems with the installation reference to Intel RealSense Python Installation


================================================
FILE: docs/source/getting_started/interest.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Tue Apr 14 17:11:54 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Obtaining a full system
=======================

If you are interested in buying a fully operating set-up including appropriate hardware, pre-installed software,
and set-up and maintenance, please contact `Terranigma Solutions GmbH <https://www.terranigma-solutions.com/contact>`_.




================================================
FILE: docs/source/getting_started/license.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Tue Apr 14 17:11:54 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

License, use and attributions
=============================

Feel free to download and use the `open_AR_Sandbox <https://github.com/cgre-aachen/open_AR_Sandbox>`_ software! We do
not provide any warranty and any guarantee for the use. We also do not provide professional support, but we aim to
answer questions posted as Issues on the GitHub page as quickly as possible.

`Open_AR_Sandbox <https://github.com/cgre-aachen/open_AR_Sandbox>`_ is published under an
`GNU Lesser General Public License v3.0 <https://www.gnu.org/licenses/lgpl-3.0.de.html>`_, which means that you are free
to use it, if you do not do any modifications, in a wide variety of ways (even commercially). However, if you plan to
modify and redistribute the code, you also have to make it available under the same license!

Also, if you do any modifications, especially for scientific and educational use, then please provide them back to the
main project in the form of a pull request, as common practice in the open-source community. If you have questions on
the procedure, feel free to contact us about it.

These are the main conditions for using this library:

- License and copyright notice
- Disclose source
- State changes
- Same license (library)
- For more details on the licsense, please see provided license file.

If you use `open_AR_Sandbox <https://github.com/cgre-aachen/open_AR_Sandbox>`_ in a scientific abstract or publication,
please include appropriate recognition of the original work. For the time being, please cite:

.. code::

   @INPROCEEDINGS{2019EGUGA..2114925V,
       author = {{Virgo}, Simon and {De La Varga Hormazabal}, Miguel and {Wellmann}, Florian},
        title = "{Open-AR-Sandbox: An open-source Augmented Reality platform for geoscience}",
    booktitle = {EGU General Assembly Conference Abstracts},
         year = 2019,
       series = {EGU General Assembly Conference Abstracts},
        month = apr,
          eid = {14925},
        pages = {14925},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019EGUGA..2114925V},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
      }


================================================
FILE: docs/source/getting_started/modules.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Tue Apr 14 17:11:54 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Modules
=======

The `open_AR_Sandbox <https://github.com/cgre-aachen/open_AR_Sandbox>`_ as well as `GemPy <https://www.gempy.org/>`_ are
under continuous development and including more modules for major outreach.

Implemented modules
~~~~~~~~~~~~~~~~~~~

- `MarkerDetection <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/00_Calibration>`_:
  Place virtual boreholes in the model, define a cross section with multiple markers, set the start
  position for simulations (landslides, earthquakes, etc.). For more information check
  `ArUco's marker detection <https://docs.opencv.org/trunk/d5/dae/tutorial_aruco_detection.html>`_
- `TopoModule <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/02_TopoModule>`_:
  Normalize the depth image to display a topography map with fully customizable contour lines and variable
  heights
- `SearchMethodsModule <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/03_SearchMethodsModule>`_:
  Takes the depth image and performs Monte-Carlo simulation algorithms to construct the probability distribution based
  on the structure of the current DEM in an interactive way
  (`Hamiltonian Monte Carlo demo <https://chi-feng.github.io/mcmc-demo/app.html>`_)
- `GemPyModule <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/04_GempyModule>`_: Use
  the full advantage of the powerful `GemPy <https://www.gempy.org/>`_ package to construct geological models and
  visualize them on the sandbox in real-time
- `GradientModule <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/05_GradientModule>`_:
  Takes the gradient information from the depth image and highlight slopes in x and y direction, calculation of
  laplacian, interactive hill shading, visualization of a vector field, and streamline plot
- `LoadSaveTopoModule <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/06_LoadSaveTopoModule>`_:
  Takes the depth image and allows it to be saved as a DEM to reconstruct topographies previously constructed
- `LandslideSimulation <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/07_LandslideSimulation>`_:
  With precomputed landslides simulations, recreate a topography and trigger a landslide to visualize its flow,
  direction, and velocity in real-time, or frame by frame
- `PrototypingModule <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/08_PrototypingModule>`_:
  Create your own module with the help of this module to link the live threading of the sandbox with your ideas
- `LandscapeModule <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/09_LandscapeGeneration>`_:
  Landscape generations using machine learning codes powered by `CycleGAN <https://junyanz.github.io/CycleGAN/>`_
- `SeismicModule <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/10_SeismicModule>`_:
  Module for seismic wave modelling in the sandbox. This uses the power of `Devito <https://www.devitoproject.org/>`_
- `GeoelectricsModule <https://github.com/cgre-aachen/open_AR_Sandbox/tree/master/notebooks/tutorials/11_GeoelectricsModule>`_:
  Module for visualization of geoelectrical fields using
  `ArUco <https://docs.opencv.org/trunk/d5/dae/tutorial_aruco_detection.html>`_ markers as electrodes. This use power
  of `PyGimli <https://www.pygimli.org/>`_

Check the video below for some of the features in action:

.. raw:: html

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
        <iframe src="https://www.youtube.com/watch?v=t0fyPVMIH4g" frameborder="0" allowfullscreen style="position: absolute;
         top: 0; left: 0; width: 100%; height: 90%; margin-bottom: 2em;"></iframe>
    </div>

Modules in implementation process
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- More Tutorials, examples, tests and documentation to help you develop your own modules
- `GemPy <https://www.gempy.org/>`_ optimization for (much!) higher frame-rates
- On-the-fly modification of the geological model (layer dip, thickness fault throw, etc.)
- Integration of more depth sensors (support to all kinect sensors)
- Improve compatibility with Linux and MacOS
- ...


================================================
FILE: docs/source/getting_started/project development.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Tue Apr 14 17:11:54 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Project development
===================

`Open_AR_Sandbox <https://github.com/cgre-aachen/open_AR_Sandbox>`_ is being developed at the
`Department for Computational Geoscience and Reservoir Engineering (CGRE) <https://www.cgre.rwth-aachen.de/go/id/qoyf/>`_
at the `RWTH Aachen University <https://www.rwth-aachen.de/cms/~a/root/?lidx=1>`_.

.. image:: https://img.shields.io/github/contributors/cgre-aachen/open_AR_Sandbox.svg?logo=python&logoColor=white
   :target: https://github.com/cgre-aachen/open_AR_Sandbox/graphs/contributors/

Project Lead
~~~~~~~~~~~~
`Prof. Florian Wellmann, Ph. D. <https://www.cgre.rwth-aachen.de/cms/CGRE/Das-Lehr-und-Forschungsgebiet/~dnyyj/Prof-Wellmann/lidx/1/>`_
(`@flohorovic <https://github.com/flohorovicic/>`_)

Maintainers (also external to CGRE)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
- Daniel Escallón Botero, M. Sc. (`@danielsk78 <https://github.com/danielsk78>`_)
- Dr. rer. nat. Simon Virgo (`@SimonVirgo <https://github.com/SimonVirgo>`_)
- Miguel de la Varga Hormazabal, M. Sc. (`@leguark <https://github.com/Leguark>`_)
- Lasse Klein, B. Sc. (`@devlk2 <https://github.com/devlk2>`_)


================================================
FILE: docs/source/getting_started/requirements.rst
================================================
.. AR_Sandbox documentation master file, created by
   sphinx-quickstart on Tue Apr 14 17:11:54 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Requirements
============

You will need:

- Microsoft Kinect (we tested the first and second generation kinect with a usb adapter, but every kinect compatible
  with the pyKinect drivers will likely work).
- Projector
- A box of Sand

Mount the Kinect and projector facing down vertically in the center above of the box. The optimal distance will depend
on the size of your sandbox and the optics of the projector, from our experience a distance of 150 cm is well suited
for a 80 cm x 100 cm box. More details on how to set up the Kinect and projector can be found in the
1_calib_projector.ipynb and 2_calib_sensor.ipynb notebooks, and if you want to use the ArUco markers
3_calib_arucos.ipynb.


================================================
FILE: notebooks/calibration_files/fw_projector_calibration.json
================================================
{"version": "2.0.p", "p_width": 1280, "p_height": 800, "p_frame_top": 30, "p_frame_left": 216, "p_frame_width": 930, "p_frame_height": 710}


================================================
FILE: notebooks/calibration_files/fw_sensor_calibration.json
================================================
{"version": "2.1.s", "s_name": "kinect_v2", "s_top": 161, "s_right": 119, "s_bottom": 49, "s_left": 126, "s_frame_width": 267, "s_frame_height": 214, "s_min": 1373, "s_max": 1633, "box_width": 1000, "box_height": 800}


================================================
FILE: notebooks/calibration_files/my_projector_calibration.json
================================================
{"version": "2.2.p", "p_width": 1280, "p_height": 800, "p_frame_top": 30, "p_frame_left": 216, "p_frame_width": 930, "p_frame_height": 710, "col_top": 0, "col_left": 0, "col_width": 70, "col_height": 500, "pos_colorbar": "vertical", "leg_top": 0, "leg_left": 0, "leg_width": 175, "leg_height": 233}


================================================
FILE: notebooks/calibration_files/my_sensor_calibration.json
================================================
{"version": "2.1.s", "s_name": "kinect_v2", "s_top": 165, "s_right": 130, "s_bottom": 51, "s_left": 120, "s_frame_width": 262, "s_frame_height": 208, "s_min": 1300, "s_max": 1620, "box_width": 1000, "box_height": 800}


================================================
FILE: notebooks/prototypes/kinectv2_linux.ipynb
================================================
# Jupyter notebook converted to Python script.

import freenect2
from freenect2 import Device, FrameType
import numpy as np
import matplotlib.pyplot as plt
%matplotlib qt5
from sandbox.sensor.kinectV2 import KinectV2


%%timeit
device = Device()
frames = {}
with device.running():
    for type_, frame in device:
        frames[type_] = frame
        if FrameType.Color in frames and FrameType.Depth in frames:
            break

# Use the factory calibration to undistort the depth frame and register the RGB
# frame onto it.
rgb, depth = frames[FrameType.Color], frames[FrameType.Depth]
#undistorted, registered, big_depth = device.registration.apply(
#    rgb, depth, with_big_depth=True)

# Combine the depth and RGB data together into a single point cloud.
#with open('output.pcd', 'wb') as fobj:
#    device.registration.write_pcd(fobj, undistorted, registered)

#with open('output_big.pcd', 'wb') as fobj:
#   device.registration.write_big_pcd(fobj, big_depth, rgb)

device = Device()

device.running()

global _FREENECT2_SINGLETON 

_FREENECT2_SINGLETON = None

num_devices = freenect2.lib.freenect2_enumerate_devices(freenect2._get_freenect2())
assert num_devices > 0
    



device.start()

import freenect2
from freenect2 import Device, FrameType
import numpy as np
import matplotlib.pyplot as plt
%matplotlib qt5
from sandbox.sensor.kinectV2 import KinectV2

device = Device()
frames = {}


_count = 0
im=None
fig, ax = plt.subplots()
with device.running():
    
    for type_, frame in device:
        _count += 1
        frames[type_] = frame
        if FrameType.Color in frames and FrameType.Depth in frames:
            rgb, depth = frames[FrameType.Color], frames[FrameType.Depth]
            #if im is None:
            #    im = ax.imshow(depth.to_array())
            #else:
            #    im.set_data(depth.to_array())
            #    ax.draw()
            #print(depth.to_array())
            #ax.imshow(depth.to_array())
            #fig.draw()
        if _count==200:
            break
        

im.set_data(depth.to_array())

frames = {}
with device.running():
    for type_, frame in device:
        frames[type_] = frame
        if FrameType.Color in frames and FrameType.Depth in frames and FrameType.Ir in frames:
            break

ir = frames[FrameType.Ir].to_array()
color = frames[FrameType.Color].to_array()
depth = frames[FrameType.Depth].to_array()

plt.imshow(ir)
plt.show()
plt.imshow(depth)
plt.show()
plt.imshow(color)
plt.show()


kinect = KinectV2()


kinect.get_frame()


frames = kinect.listener.waitForNewFrame(milliseconds=1000)
depth = frames['depth'].asarray()
listener.release(frames)
plt.imshow(depth)
plt.show()

color = kinect.get_color()
print(color.shape)
print(color[0])
plt.imshow(color, origin="lower left")
plt.show()

color = kinect.get_color()
print(color.shape)
print(color[0])
plt.imshow(color, origin="lower left")
plt.show()

kinect.listener.hasNewFrame()

kinect.listener.waitForNewFrame

frames = kinect.listener.waitForNewFrame(milliseconds=50)
if frames:
    print(True)
    kinect.listener.release(frames)
else:
    print(False)


kinect.listener.hasNewFrame()

kinect.listener.waitForNewFrame()









from pylibfreenect2 import Freenect2, SyncMultiFrameListener
from pylibfreenect2 import FrameType, Registration, Frame, FrameMap


import numpy as np
import matplotlib.pyplot as plt



fn = Freenect2()

num_devices = fn.enumerateDevices()
assert num_devices > 0

serial = fn.getDefaultDeviceSerialNumber()

device = fn.openDevice(serial)


listener = SyncMultiFrameListener(
    FrameType.Color | FrameType.Ir | FrameType.Depth)

# Register listeners
device.setColorFrameListener(listener)
device.setIrAndDepthFrameListener(listener)

device.startStreams(rgb=True, depth=True)

# Registration
#registration = Registration(device.getIrCameraParams(),
#                            device.getColorCameraParams())
#undistorted = Frame(512, 424, 4)
#registered = Frame(512, 424, 4)

# optional parameters for registration
#bigdepth = Frame(1920, 1082, 4)
#color_depth_map = np.zeros((424, 512), np.int32)

# test if we can get two frames at least
#frames = listener.waitForNewFrame()
#listener.release(frames)

# frames as a first argment also should work
frames = FrameMap()
listener.waitForNewFrame(frames)

color = frames[FrameType.Color]
ir = frames[FrameType.Ir]
depth = frames[FrameType.Depth]

assert color.width == 1920
assert color.height == 1080
assert color.bytes_per_pixel == 4

assert ir.width == 512
assert ir.height == 424
assert ir.bytes_per_pixel == 4

assert depth.width == 512
assert depth.height == 424
assert depth.bytes_per_pixel == 4

listener.release(frames)

# frames as a first argment also should work
frames = FrameMap()
listener.waitForNewFrame(frames)

#color = frames[FrameType.Color]
#ir = frames[FrameType.Ir]
depth = frames[FrameType.Depth]

#plt.imshow(color.asarray())
#plt.show()
#plt.imshow(ir.asarray())
#plt.show()
plt.imshow(depth.asarray())
plt.show()

listener.release(frames)

frames = FrameMap()
listener.waitForNewFrame(frames)

#color = frames[FrameType.Color]
#ir = frames[FrameType.Ir]
depth = frames[FrameType.Depth]

#plt.imshow(color.asarray())
#plt.show()
#plt.imshow(ir.asarray())
#plt.show()
plt.imshow(depth.asarray())
plt.show()

listener.release(frames)

color.bytes_per_pixel




device.startStreams(rgb=True, depth=True)

device.

frames = FrameMap()
listener.waitForNewFrame(frames)


frames = FrameMap()
listener.waitForNewFrame(frames, milliseconds=100)
depth = frames['depth'].asarray()
listener.release(frames)
plt.imshow(depth)
plt.show()

depth

listener.release(frames)

import numpy as np
import cv2
import sys
from pylibfreenect2 import Freenect2, SyncMultiFrameListener
from pylibfreenect2 import FrameType, Registration, Frame
from pylibfreenect2 import createConsoleLogger, setGlobalLogger
from pylibfreenect2 import LoggerLevel

try:
    from pylibfreenect2 import OpenGLPacketPipeline
    pipeline = OpenGLPacketPipeline()
except:
    try:
        from pylibfreenect2 import OpenCLPacketPipeline
        pipeline = OpenCLPacketPipeline()
    except:
        from pylibfreenect2 import CpuPacketPipeline
        pipeline = CpuPacketPipeline()
print("Packet pipeline:", type(pipeline).__name__)

# Create and set logger
logger = createConsoleLogger(LoggerLevel.Debug)
setGlobalLogger(logger)

fn = Freenect2()
num_devices = fn.enumerateDevices()
if num_devices == 0:
    print("No device connected!")
    sys.exit(1)

serial = fn.getDeviceSerialNumber(0)
device = fn.openDevice(serial, pipeline=pipeline)

listener = SyncMultiFrameListener(
    FrameType.Color | FrameType.Ir | FrameType.Depth)

# Register listeners
device.setColorFrameListener(listener)
device.setIrAndDepthFrameListener(listener)

device.start()

# NOTE: must be called after device.start()
registration = Registration(device.getIrCameraParams(),
                            device.getColorCameraParams())

undistorted = Frame(512, 424, 4)
registered = Frame(512, 424, 4)

# Optinal parameters for registration
# set True if you need
need_bigdepth = False
need_color_depth_map = False

bigdepth = Frame(1920, 1082, 4) if need_bigdepth else None
color_depth_map = np.zeros((424, 512),  np.int32).ravel() \
    if need_color_depth_map else None

while True:
    frames = listener.waitForNewFrame()

    color = frames["color"]
    ir = frames["ir"]
    depth = frames["depth"]

    registration.apply(color, depth, undistorted, registered,
                       bigdepth=bigdepth,
                       color_depth_map=color_depth_map)

    # NOTE for visualization:
    # cv2.imshow without OpenGL backend seems to be quite slow to draw all
    # things below. Try commenting out some imshow if you don't have a fast
    # visualization backend.
    cv2.imshow("ir", ir.asarray() / 65535.)
    cv2.imshow("depth", depth.asarray() / 4500.)
    cv2.imshow("color", cv2.resize(color.asarray(),
                                   (int(1920 / 3), int(1080 / 3))))
    cv2.imshow("registered", registered.asarray(np.uint8))

    if need_bigdepth:
        cv2.imshow("bigdepth", cv2.resize(bigdepth.asarray(np.float32),
                                          (int(1920 / 3), int(1082 / 3))))
    if need_color_depth_map:
        cv2.imshow("color_depth_map", color_depth_map.reshape(424, 512))

    listener.release(frames)

    key = cv2.waitKey(delay=1)
    if key == ord('q'):
        break

device.stop()
device.close()

sys.exit(0)

# An example using startStreams
import numpy as np
from pylibfreenect2 import Freenect2, SyncMultiFrameListener
from pylibfreenect2 import FrameType, Registration, Frame

try:
    from pylibfreenect2 import OpenGLPacketPipeline
    pipeline = OpenGLPacketPipeline()
except:
    try:
        from pylibfreenect2 import OpenCLPacketPipeline
        pipeline = OpenCLPacketPipeline()
    except:
        from pylibfreenect2 import CpuPacketPipeline
        pipeline = CpuPacketPipeline()
print("Packet pipeline:", type(pipeline).__name__)

#enable_rgb = False
#enable_depth = True

fn = Freenect2()
num_devices = fn.enumerateDevices()
assert num_devices > 0

serial = fn.getDeviceSerialNumber(0)
device = fn.openDevice(serial, pipeline=pipeline)

listener = SyncMultiFrameListener(
    FrameType.Color | FrameType.Ir | FrameType.Depth)

# Register listeners
device.setColorFrameListener(listener)
device.setIrAndDepthFrameListener(listener)

device.start()

registration = Registration(device.getIrCameraParams(), device.getColorCameraParams())

undistorted = Frame(512, 424, 4)
registered = Frame(512, 424, 4)

def _frames(typ="all"):
    frames = listener.waitForNewFrame(milliseconds=1000)
    if frames:
        if typ=='depth':
            depth = frames[FrameType.Depth]
            listener.release(frames)
            return depth.asarray()
        elif typ=='ir':
            ir = frames[FrameType.Ir]
            listener.release(frames)
            return ir.asarray()
        if typ=='color':
            color = frames[FrameType.Color]
            listener.release(frames)
            return color.asarray()
        if typ=='all':
            color = frames[FrameType.Color]
            ir = frames[FrameType.Ir]
            depth = frames[FrameType.Depth]
            registration.apply(color, depth, undistorted, registered)
            registration.undistortDepth(depth, undistorted)
            listener.release(frames)
            return depth.asarray(), color.asarray(), ir.asarray()
    
    #ir = frames[FrameType.Ir]
    #depth = frames[FrameType.Depth]

    #registration.apply(color, depth, undistorted, registered)
    #registration.undistortDepth(depth, undistorted)

    #assert color.width == 1920
    #assert color.height == 1080
    #assert color.bytes_per_pixel == 4

    #assert ir.width == 512
    #assert ir.height == 424
    #assert ir.bytes_per_pixel == 4

    #assert depth.width == 512
    #assert depth.height == 424
    #assert depth.bytes_per_pixel == 4

        listener.release(frames)
    else:
        raise FileNotFoundError

print(_frames(typ='depth').shape)
print(_frames(typ='ir').shape)
print(_frames(typ='color').shape)

import matplotlib.pyplot as plt
from sandbox.sensor.kinectV2 import KinectV2


kinect = KinectV2()

kinect.get_linux_frame(typ="depth")

kinect.device.start()

kinect.listener.hasNewFrame()

kinect.device.stop()

kinect.listener.release(frames)




================================================
FILE: notebooks/prototypes/prototype_test_lk.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/prototypes/gemgis_sandbox/Gempy Model.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/prototypes/Gempy_workspace/Gempy_models_sandbox_visualization.ipynb
================================================
# Jupyter notebook converted to Python script.

import os,sys
sys.path.append('../..')
sys.path.append('../../../gempy/')
import gempy as gp
import time

#os.environ["THEANO_FLAGS"] = "mode=FAST_RUN,device=cuda"
os.environ["THEANO_FLAGS"] = "mode=FAST_RUN"
import sandbox.sandbox as sb


#import gempy_sandbox a   s gpsb
import numpy as np
#from PIL import Image, ImageDraw
import pickle

calibrationdata = sb.CalibrationData(file='my_calibration.json')
sensor = sb.KinectV2(calibrationdata)
projector = sb.Projector(calibrationdata)

tempfile = 'temp.pickle.pickle'
last_time_modified = os.path.getmtime(tempfile)
geo_model=gp.load_model_pickle(tempfile)

def update_model(tempfile):
    print('updating model')
    gpsb.stop()
    geo_model = gp.load_model_pickle(tempfile)
    gpsb.geo_model = geo_model
    gpsb.setup()
    gpsb.run()
    

gpsb=sb.GemPyModule(geo_model, calibrationdata, sensor, projector)

gpsb.setup()

gpsb.run()


update_model(tempfile)

gpsb.stop()

gpsb.






================================================
FILE: notebooks/tutorials/Download_datasets.ipynb
================================================
# Jupyter notebook converted to Python script.

import os,sys
sys.path.append('../../')

"""
# Download datasets using Pooch

You can choose which dataset to download. Simply execute the relevant cells below. The data is stored in the respecctive notebook folders (see output below).
"""

from sandbox.utils.download_sample_datasets import *

"""
## Geomodel datasets

GemPy datasets for geomodeling examples (geological map in the sandbox, notebooks in `notebooks/tutorials/04_GempyModule/Example_Models`)
"""

print('Available gempy data: {}'.format((gempy_example_models, gempy_example_models2)))

download_example_gempy_model()
# Output:
#   Available gempy data: (['model1_orientations.csv', 'model1_surface_points.csv', 'model2_orientations.csv', 'model2_surface_points.csv', 'model3_orientations.csv', 'model3_surface_points.csv', 'model4_orientations.csv', 'model4_surface_points.csv', 'model5_orientations.csv', 'model5_surface_points.csv', 'model6_orientations.csv', 'model6_surface_points.csv', 'model7_orientations.csv', 'model7_surface_points.csv'], ['foliations7.csv', 'interfaces7.csv'])

#   [32msandbox.utils.download_sample_datasets: INFO[0m | Pooch created for url: https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/

#   [32msandbox.utils.download_sample_datasets: INFO[0m | Pooch created for url: https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/lisa_models/

#   Downloading file 'model1_orientations.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model1_orientations.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|#######################################| 84.0/84.0 [00:00<00:00, 83.8kB/s]

#   Downloading file 'model1_surface_points.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model1_surface_points.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|#######################################| 90.0/90.0 [00:00<00:00, 90.4kB/s]

#   Downloading file 'model2_orientations.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model2_orientations.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|#######################################| 85.0/85.0 [00:00<00:00, 85.2kB/s]

#   Downloading file 'model2_surface_points.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model2_surface_points.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|##########################################| 158/158 [00:00<00:00, 159kB/s]

#   Downloading file 'model3_orientations.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model3_orientations.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|#######################################| 98.0/98.0 [00:00<00:00, 49.2kB/s]

#   Downloading file 'model3_surface_points.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model3_surface_points.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|##########################################| 334/334 [00:00<00:00, 168kB/s]

#   Downloading file 'model4_orientations.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model4_orientations.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|##########################################| 110/110 [00:00<00:00, 110kB/s]

#   Downloading file 'model4_surface_points.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model4_surface_points.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|##########################################| 107/107 [00:00<00:00, 107kB/s]

#   Downloading file 'model5_orientations.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model5_orientations.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|#########################################| 110/110 [00:00<00:00, 54.8kB/s]

#   Downloading file 'model5_surface_points.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model5_surface_points.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|#########################################| 134/134 [00:00<00:00, 67.5kB/s]

#   Downloading file 'model6_orientations.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model6_orientations.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|#########################################| 111/111 [00:00<00:00, 55.4kB/s]

#   Downloading file 'model6_surface_points.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model6_surface_points.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|##########################################| 164/164 [00:00<00:00, 164kB/s]

#   Downloading file 'model7_orientations.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model7_orientations.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|#########################################| 125/125 [00:00<00:00, 41.5kB/s]

#   Downloading file 'model7_surface_points.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/model7_surface_points.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|##########################################| 390/390 [00:00<00:00, 389kB/s]

#   Downloading file 'foliations7.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/lisa_models/foliations7.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|##########################################| 496/496 [00:00<00:00, 488kB/s]

#   Downloading file 'interfaces7.csv' from 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/lisa_models/interfaces7.csv' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Example_Models\data_examples'.

#   100%|##########################################| 402/402 [00:00<00:00, 133kB/s]
#   [32msandbox.utils.download_sample_datasets: INFO[0m | Data for gempy example models downloaded

#   


"""
## Functionality test data

To test ArUco Markers and frames (not necessarily required, if everything is working):
"""

print('Available test data: {}'.format(tests))

download_test_data()

"""
## Topography data

Sample digital elevation model, for example to:
- use the sandbox module without an actual physical sandbox ("offline" mode)
- reconstruct pre-saved elevation fields (e.g., Bennison models)
- run landslide simulations.

### Base topography data

"""

print('Available topography data: {}'.format(topomodule_files))

download_topography_data()
# Output:
#   Available topography data: ['1.npz', '2.npz', '3.npz', '4.npz', 'DEM1.npz', 'DEM10.npz', 'DEM11.npz', 'DEM2.npz', 'DEM3.npz', 'DEM4.npz', 'DEM5.npz', 'DEM6.npz', 'DEM7.npz', 'DEM8.npz', 'DEM9.npz', 'Landslide_test_1.npz', 'bennisson_raster_DEM_04.npy', 'savedTopography.npz', 'test.npz']

#   [32msandbox.utils.download_sample_datasets: INFO[0m | Pooch created for url: https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FTopoModule%2Fsaved_DEMs&files=

#   [32msandbox.utils.download_sample_datasets: INFO[0m | Data for topography downloaded


"""
### Landslide data sets

Includes digital elevation models and simulation results (Notebook `notebooks/tutorials/07_LandslideSimulation/Load_and_Run_Landslides_Simulation.ipynb`)
"""

print('Available landslide data: {}'.format(landslides_dems))

download_landslides_data()

"""
### Benisson Model data set
"""

print('Available benisson model: {}'.format(gempy_benisson))

download_benisson_model()
# Output:
#   Available benisson model: ['Benisson_04_elev_contours.dbf', 'Benisson_04_elev_contours.prj', 'Benisson_04_elev_contours.shp', 'Benisson_04_elev_contours.shx', 'Benisson_Map_04.png', 'extent.dbf', 'extent.prj', 'extent.shp', 'extent.shx', 'interfaces_point.dbf', 'interfaces_point.prj', 'interfaces_point.shp', 'interfaces_point.shx', 'orientation.dbf', 'orientation.prj', 'orientation.shp', 'orientation.shx']

#   [32msandbox.utils.download_sample_datasets: INFO[0m | Pooch created for url: https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=

#   Downloading file 'Benisson_04_elev_contours.dbf' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=Benisson_04_elev_contours.dbf' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 408/408 [00:00<00:00, 403kB/s]

#   Downloading file 'Benisson_04_elev_contours.prj' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=Benisson_04_elev_contours.prj' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 143/143 [00:00<00:00, 143kB/s]

#   Downloading file 'Benisson_04_elev_contours.shp' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=Benisson_04_elev_contours.shp' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|#####################################| 3.73k/3.73k [00:00<00:00, 3.73MB/s]

#   Downloading file 'Benisson_04_elev_contours.shx' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=Benisson_04_elev_contours.shx' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|#########################################| 180/180 [00:00<00:00, 90.1kB/s]

#   Downloading file 'Benisson_Map_04.png' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=Benisson_Map_04.png' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|#####################################| 1.20M/1.20M [00:00<00:00, 1.20GB/s]

#   Downloading file 'extent.dbf' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=extent.dbf' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|#######################################| 77.0/77.0 [00:00<00:00, 77.4kB/s]

#   Downloading file 'extent.prj' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=extent.prj' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 145/145 [00:00<00:00, 146kB/s]

#   Downloading file 'extent.shp' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=extent.shp' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 236/236 [00:00<00:00, 117kB/s]

#   Downloading file 'extent.shx' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=extent.shx' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 108/108 [00:00<00:00, 106kB/s]

#   Downloading file 'interfaces_point.dbf' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=interfaces_point.dbf' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|#####################################| 1.46k/1.46k [00:00<00:00, 1.46MB/s]

#   Downloading file 'interfaces_point.prj' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=interfaces_point.prj' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 145/145 [00:00<00:00, 145kB/s]

#   Downloading file 'interfaces_point.shp' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=interfaces_point.shp' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 520/520 [00:00<00:00, 258kB/s]

#   Downloading file 'interfaces_point.shx' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=interfaces_point.shx' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 220/220 [00:00<00:00, 220kB/s]

#   Downloading file 'orientation.dbf' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=orientation.dbf' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 332/332 [00:00<00:00, 111kB/s]

#   Downloading file 'orientation.prj' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=orientation.prj' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|#########################################| 145/145 [00:00<00:00, 73.6kB/s]

#   Downloading file 'orientation.shp' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=orientation.shp' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 276/276 [00:00<00:00, 276kB/s]

#   Downloading file 'orientation.shx' from 'https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files=orientation.shx' to 'c:\users\cgre_pro-user\git\open_ar_sandbox\notebooks\tutorials\04_GempyModule\Model_Construction\Bennisson_model\data'.

#   100%|##########################################| 116/116 [00:00<00:00, 116kB/s]
#   [32msandbox.utils.download_sample_datasets: INFO[0m | Data for benisson model downloaded

#   


"""
## Landscape generation

Models for landscape generation using deep learning (Notebook `notebook/stutorials/09_LandscapeGeneration/deep_learning_landscapes.ipynb`)
"""

print('Available Landscape trained models: {}'.format(landscape_models))

download_landscape_name(name_model=landscape_models[0])

"""
You can also download all the models without specifiying the name.
"""

download_landscape_all()



================================================
FILE: notebooks/tutorials/Run_Sandbox_allFunctionalities.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Import the Sandbox 

"""

"""
<div class="alert alert-block alert-warning">
    <b> Acces to all modules: </b> This Notebook allow to change between modules using only widgets from the bokeh panel
</div>
"""

#Only use if sandbox is not installed
import os,sys
sys.path.append('../../')

"""
## Start the Panel

The panel will start with a simple line, opening a bokeh server for the projector and the widgets. Position the window in the projector image and use the widgets to change between modules. Each module will open its respective widgets in a new bokeh server allowing an easy interaction and control over all the features.

Please always pass a correct calibration file:
"""

"""
## Calibration
In case that the frame of the sandbox is not calibrated, for a fast calibration you can use the following line of code and follow the bokeh instructions. In case of a more detailed explanation on how to do the calibration please go to the tutorials
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

"""
#### Projector calibration:
"""

from sandbox.sandbox_api import calibrate_projector
cal_projector = calibrate_projector()

"""
Once you have the new calibration file for the projector, we can start the sensor calibration. 
In the following we assume you have used the predifined name and folder location for the calibration file. In case you have another one, specify the new path.   
"""

"""
#### Sensor calibration:
"""

from sandbox.sandbox_api import calibrate_sensor
cal_sensor = calibrate_sensor(calibprojector=_calibprojector, name="kinect_v2")

"""
Now we are ready to continue with the tutorial.
"""

"""
## Start the sandbox server with the predefined modules - (NO EXTRA MODULES)
"""

"""
To open the sandbox server and start using all its function (Excluding external module: check further to know how to load the external modules), we will only need the calibration file for the projector and the sensor.
"""

"""

To open the sandbox server and start using all its function (Excluding external module: check further to know how to load the external modules), we will only need the calibration file for the projector and the sensor.
"""

"""
1. On the left side, you will see the buttons with the name of all the internal modules. They are all ready to be used and waiting to be added to the running thread. 

2. You will just need to click the green button, and a new tab navigation tab will appear with the module widgets and will also be added to the main thread. 

3. You can load several modules at the same time, and use all their functionalities combined, just be carefull that the order of the modules matter. 

4. By default the CmapModule and ContourLinesModule will always run at the end of the thread, you don't need to worry about them.

5. To manage the order, to remove and/or add other modules, use manager module wigdets: The left chart are the available modules and on the right are the running modules. You may add or delete modules using the arrows to change the location of the module between charts. 

6. Finally, if the image that you are getting in the sandbox is saturated of lines or images (maybe from modules you alreay deleted but the image is not yet remove), just click the button for clearing the axes and this will clean the image for you. 

"""

from sandbox.sandbox_api import start_server

# This will open automatically the panel server and the widgets in a new navigation tab. 

# If Error 505 appers, just run the cell again, and the error ill dissapear. 

# We are currently working on some warnings that will appear, 
# for the moment they are not important to you if the thread don't stop

# We assume you went through the tutorials of all the modules and are familiar with the widgets of each.

Sb_server = start_server(calibprojector = _calibprojector,
                         calibsensor= _calibsensor,
                         sensor_name='dummy',
                         aruco_marker=True
                         )

"""
## Sandbox server with external modules
"""

"""
Which external packages do you want to load?
"""

import os
#Run this cell only if you want to run gempy in cuda mode (requires cuda and a dedicated cpu).
#Initial compilation will take a bit longer but the model will run much faster 
os.environ["THEANO_FLAGS"] = "mode=FAST_RUN,device=cuda"

external_modules = dict(gempy_module = False,
                        gimli_module = False,
                        torch_module = False,
                        devito_module = True
                       )

"""
we can pass the information for every module using dictionaries
"""

gempy_kwargs = {}
if external_modules["gempy_module"]:
    gempy_kwargs = dict(geo_model = None,
                       load_examples = True,
                       name_example = ['Horizontal_layers', 
                                       'Recumbent_fold', 
                                       'Anticline',
                                       'Pinchout', 
                                       'Fault', 
                                       'Unconformity']
                       )

"""
And the same way as we loaded the internal modules, we can add the new external modules with their respective widgets. The usage will be the same as before
"""

from sandbox.sandbox_api import start_server

Sb_server = start_server(calibprojector = _calibprojector,
                         calibsensor= _calibsensor,
                         sensor_name='dummy',
                         aruco_marker=True,
                         kwargs_external_modules=external_modules,
                         kwargs_gempy_module=gempy_kwargs,
                         )











Sb_server.Main_Thread.stop()



================================================
FILE: notebooks/tutorials/Template_Notebook.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/00_Calibration/1_calib_projector.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/00_Calibration/2_calib_sensor.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Sandbox Sensor calibration
In this tutorial we will learn the basic steps to set up the sensor for the _open AR Sandbox_. 
This not only involves tweaking of calibration parameters, but also the adjustment of your hardware component.

Let's start with importing the main module:
"""

#Only useful when sandbox is not installed
import os,sys
sys.path.append('../../../')
#
from sandbox import _calibration_dir
from sandbox.sensor import Sensor, CalibSensor


"""
### Before starting:

<div class="alert alert-block alert-warning">
    <b> Projector calibration file: </b> We will use the calibration file generated from the previous tutorial (Sandbox Projector calibration). If you have not calibrated yet the projector, please stop here and go back to the 1_calib_projector.ipynb jupyter notebook to calibrate the projector. If this is already done you can continue. 
</div>

* **Sensor**: Provides us with a frame of distance data between the sensor and the sand surface.

You can use different sensors, **KinectV1, KinectV2, LiDAR L515 or a DummySensor** to simulate a topography and/or run other Modules. For the calibration process, this is realized in the CalibSensor class. 

"""

# Supported sensor types:
    # "kinect_v1"
    # "kinect_v2"
    # "lidar"
    # "dummy"

    
    
sensor_type = "kinect_v2"





"""
## Sensor calibration

Your projector dashboard is calibrated and looks alright? Now, we need to calibrate the sensor so it exactly fits the projected main frame. First, we load the calibration file of the projector since this module needs to project the sensor image in the projector defined area. This will open a panel server with the sensor image updating, creating a simple topographic view with some color coded areas that guide you in finding the correct calibration parameters.
"""

calib_proj = _calibration_dir + 'my_projector_calibration.json'
module = CalibSensor(calibprojector = calib_proj, name = sensor_type)

"""
The sensor calibration is a bit more advanced than the projector positioning. In addition to the horizontal adjustment you also need to define vertical limits of the values, the sensor supplies. For example, this prevents unwanted model recalculations, when you move your hands above the projection area.

**Adjust your hardware**

If you call the calibrate_sensor() function you will see a current snapshot of a depth representation of your sandbox. It is easy to determine the sandboxe's edges and objects next to the sandbox, like the monitor or a chair. Position the Kinect sensor physically, so that the sensor is parallel to the sandbox surface and the outlines of the sandbox are parallel to the edges appears anymore. Each time, you have adjusted the hardware, take a new snapshot and check the visualization inside the calibration interface. Before a snapshot is taken, the software waits three seconds, allowing you to remove your hands or other objects between the sensor and the scanned surface.

**Horizontal calibration**

Afterwards, roughly adjust the first four margin sliders (blue) of the interface until the blue margin patches inside the snapshot cover the areas outisde the sandbox. Again, use the four corner poles as orientation. Those blue areas later will be cropped off by the software to focus on the area of interest.

Now, you can adjust the four margins more precisely following the life representation inside the sandbox. Place a recognizable object like a cube or a cylinder inside the sandbox to check for possible offsets. Do that in the center of the surface, as well as close to the the edges of the sandbox.

**Vertical calibration**

The vertical value range that should be registered by the sensor, can be adjusted with the red and yellow sliders. The values represent the vertical distance away from the sensor in mm. Always make sure, the yellow slider is left of the red one to avoid confusion.

Hold one hand right above the sandboxe's walls and move the yellow slider to the right until your hand is illuminated in yellow.

To calibrate the vertical maximum of the range, dig a hole inside the sand until you reach the bottom of the sandbox. Now, move the red slider until only the bottom plate is colored red. Move the slider a little bit further to the right to increase the distance slightly below the sandbox. You can always follow this process inside the interface to also get a feedback on the distances of surrounding objects behind the blue margin patches.
"""

widget = module.calibrate_sensor()
widget

"""
You have successfully calibrated your sandbox, and therefore, are ready to go.
"""

"""
## Save calibration
"""

"""
As in the projector calibration, we will save the sensor calibration in a JSON file for future reference. 
"""

module.sensor.save_json(file=_calibration_dir+ 'my_sensor_calibration.json')

"""
## Check the sensor is correctly calibrated
"""

"""
The next time you start the software, simply pass the file's location and name as an argument to the Sensor instance:
"""

sensor = Sensor(calibsensor=_calibration_dir+ 'my_sensor_calibration.json', name = sensor_type)

import matplotlib.pyplot as plt
plt.imshow(sensor.get_frame(), origin="lower")
plt.colorbar()
plt.show()
print(sensor.extent)



================================================
FILE: notebooks/tutorials/00_Calibration/3_calib_arucos.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Sandbox Markers calibration
In this tutorial we will learn the basic steps to set up the ArUco markers and how to use them for the _open AR Sandbox_. 
This not only involves tweaking of calibration parameters, but also how to use this information.

Let's start with importing the main module:
"""

#Only use if sandbox is not installed
import os,sys
sys.path.append('../../')

"""
### Before starting:
<div class="alert alert-block alert-warning">
    <b> Projector calibration file: </b> We will use the calibration file generated from the previous tutorial (Sandbox Projector calibration). If you have not calibrated yet the projector, please stop here and go back to the 1_calib_projector.ipynb jupyter notebook to calibrate the projector. If this is already done you can continue.
    
    
<b> Sensor calibration file: </b> The same applies for the sensor calibration file from the previous tutorial (Sanbox Sensor calibration). If you have not calibrated yet the sensor, please stop here and go back to the 2_calib_sensor.ipynb jupyter notebook to calibrate the Sensor. If this is already done you can continue. 
</div>

* **Marker**: (This module is optional) This will allow to use the the ArUco markers in the AR-Sandbox
"""

"""
### Marker Detection **(optional)** 

The aruco markers is a class from the OpenCv package, for pose estimation with many computer vision applications. (Follow the link to read more about Aruco marker detection https://docs.opencv.org/trunk/d5/dae/tutorial_aruco_detection.html)

The basics of the Aruco marker class for sandbox purposes are described below:
* Each marker represents a point in space captured by the camera of the kinect and projected in real time.
* This position can be used to introduce point information to the model.
* This position may represent, e.g. wellbore location in the model, the extremes to create a 2d cross section of the 3d model, seed point for simulations etc...  

_Moreover, the aruco markers are used to perform the automatic calibration of the sandbox by fitting the projected image inside the sandbox and by croping the depth frame to the information inside the sandbox._ (Feature disabled for the moment) 

So first, we start the class that will receive the information of the sensor kinect. For this, start the Sensor class. 

<div class="alert alert-block alert-warning">
    <b> Only suport KinectV2 or LiDAR L515</b> If you are using KinectV1 or DummySensor, you can use the Dummy aruco marker class. Go to the bottom of this notebook 
</div>
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor
from sandbox.sensor import Sensor
sensor = Sensor(calibsensor=_calibsensor, name="lidar")

#Initialize the aruco detection
from sandbox.markers import ArucoMarkers
aruco = ArucoMarkers(sensor=sensor)

"""
### * Place as many Arucos you want inside the sandbox, the more the better for the calibration - Skip this step for the moment, future 
"""

# Detect arucos
#--- Show the pandas dataframe
# 

"""
You will see the the DataFrame containing all the relevant information of the aruco. Its coordinates in the depth space (pixel precise), color space (pixel precise), and camera space (milimeter precise). If not all (or None) of the arucos are detected, consider improving the light setting so the arucos can be detected by the camera. If this does not fix the problem, then put the Sensor closer to the sandbox and run the calibration of the Sensor again.  

Now we can plot the coordinates in both spaces.   
"""

# Show plots
#---- both depth space and color space


"""
If you are happy with the mapping of the markers from the color space to the depth space you can skip the calibration. If you see that the markers are displaced we can change that. 
"""

# Here put the calibration of the markers 
# is just changing the constant and then save this constant to the calibration file for future occations. 

"""
Check the new figure. If you are happy with the result you can continue, otherwise repeat the previous until you are happy with the result.
"""

"""
## Initialize Sensor and Projector
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor
from sandbox.sensor import Sensor
sensor = Sensor(calibsensor=_calibsensor, name="lidar")

# Import projector
from sandbox.projector import Projector
projector = Projector(calibprojector=_calibprojector)


"""
## Initialize marker detection
"""

#Initialize the aruco detection
from sandbox.markers import MarkerDetection
aruco = MarkerDetection(sensor=sensor)

"""
## Initialize main thread for live update
"""

from sandbox.main_thread import MainThread
main = MainThread(sensor=sensor, projector=projector, aruco=aruco)


# Start the thread 
main.run()

"""
### Control the features of the main thread
"""

main.widget_plot_module()

# stop thread of sandbox





main.stop()

"""
## Use ArUco markers without ArUcos - Dummy markers
"""

"""
You can add manually arucos to your Sandbox by creating a dummy directory with id and coordinates in the coordinates of the sensor. For example:
"""

#{id:[coordinate in x, coordinate in y]}
aruco_dict = {1:[50,  30 ],
              2:[100, 150],
             29:[40,  100],
             13:[120, 80 ],
             }
# This corresponds to 4 dummy markers

aruco.set_aruco_position(dict_position=aruco_dict, frame=sensor.get_frame())

# Now you can check if they were succesfullly added. 
aruco.df_aruco_position

"""
## Use ArUco dummy Class - For KinectV1 and DummySensor
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor - Any sensor ["kinect_v1","kinect_v2", "dummy"]
from sandbox.sensor import Sensor
sensor = Sensor(calibsensor=_calibsensor, name="dummy")

# Import projector
from sandbox.projector import Projector
projector = Projector(calibprojector=_calibprojector)


#Initialize the aruco detection
from sandbox.markers import MarkerDetection # Fix here!!!!
dummy_sensor = Sensor(calibsensor=_calibsensor, name="dummy")
aruco = MarkerDetection(sensor=dummy_sensor)

#{id:[coordinate in x, coordinate in y]}
aruco_dict = {1:[50,  30 ],
              2:[100, 150],
             29:[40,  100],
             13:[120, 80 ],
             }
# This corresponds to 4 dummy markers

aruco.set_aruco_position(dict_position=aruco_dict, frame=sensor.get_frame())

# Now you can check if they were succesfullly added. 
aruco.df_aruco_position



================================================
FILE: notebooks/tutorials/01_MainThread/Generate_ArUco_markers.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Generate ArUco Markers

Notebook to generate ArUco markers
"""

#Only use if sandbox is not installed
import os,sys
sys.path.append('../../../')

from sandbox.markers import ArucoMarkers
from sandbox.sensor import Sensor

sens = Sensor(name='dummy')
A1 = ArucoMarkers(sensor=sens)
# Output:
#   [32msandbox.sensor.dummy: INFO[0m | DummySensor initialized.

#   [32msandbox.markers.aruco: INFO[0m | Using dummy arucos. Create your own aruco positions using .set_aruco_position() function

#   [32msandbox.markers.aruco: INFO[0m | using dummy aruco module

#   [32msandbox.markers.aruco: INFO[0m | Aruco module loaded


A1.create_aruco_marker(show=True)
# Output:
#   /home/daniel/GitProjets/open_AR_Sandbox/sandbox/markers/aruco.py:405: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.

#     fig.show()

#   array([[0, 0, 0, ..., 0, 0, 0],

#          [0, 0, 0, ..., 0, 0, 0],

#          [0, 0, 0, ..., 0, 0, 0],

#          ...,

#          [0, 0, 0, ..., 0, 0, 0],

#          [0, 0, 0, ..., 0, 0, 0],

#          [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)
#   <Figure size 432x288 with 1 Axes>

"""
## Save to file (as eps for high quality)

One marker:
"""

A1.create_aruco_marker(save=True,
                       fig_filename="aruco.eps")
# Output:
#   array([[0, 0, 0, ..., 0, 0, 0],

#          [0, 0, 0, ..., 0, 0, 0],

#          [0, 0, 0, ..., 0, 0, 0],

#          ...,

#          [0, 0, 0, ..., 0, 0, 0],

#          [0, 0, 0, ..., 0, 0, 0],

#          [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)

"""
Multiple markers:
"""

n = 10
for i in range(n):
    A1.create_aruco_marker(id = i,
                           save=True,
                       fig_filename="aruco_%02d.pdf" % i)



================================================
FILE: notebooks/tutorials/01_MainThread/Main_Thread.ipynb
================================================
# Jupyter notebook converted to Python script.

#Only use if sandbox is not installed
import os,sys
sys.path.append('../../../')

"""
## Initialize Sensor and Projector
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor
from sandbox.sensor import Sensor
sensor = Sensor(calibsensor=_calibsensor, name="kinect_v2")

# Import projector
from sandbox.projector import Projector
projector = Projector(calibprojector=_calibprojector)


"""
## Initialize marker detection
"""

#Initialize the aruco detection
from sandbox.markers import MarkerDetection
aruco = MarkerDetection(sensor=sensor)

"""
## Initialize main thread for live update
"""

from sandbox.main_thread import MainThread
main = MainThread(sensor=sensor, projector=projector, aruco= aruco if 'aruco' in globals() else None)

# Start the thread 
main.run()

"""
### Control the features of the main thread
"""

main.widget_plot_module()

"""
# Upload an external DEM to the main thread or fix a frame
"""

from sandbox import _test_data 
import numpy as np
import matplotlib.pyplot as plt
main.stop()

print(sensor.extent)

"""
## <b>From a saved topography from the Sandbox (extension .npz)</b>


This will modify the extends of the frame to the sensor extents according to the calibration file 
"""

#Original File
file = np.load(_test_data['topo'] + "DEM2.npz")
frame_arr = file['arr_0']
print("shape of array:", frame_arr.shape)


fig, ax = plt.subplots()
col = ax.imshow(frame_arr, cmap = "gist_earth", origin="lower")
fig.colorbar(col, ax = ax)

# To the sandbox
#Set the frame static - If frame doesn't change run the function again 
main.load_frame(from_file = _test_data['topo'] + "DEM2.npz")
main.run()

"""
## <b>From a saved DEM saved as a numpy array (extension .npy)</b>


This will modify the extends of the DEM to the sensor extents according to the calibration file.  
"""

main.stop()

#Original File
frame_DEM = np.load(_test_data['topo'] + "bennisson_raster_DEM_04.npy")

print("shape of array:", frame_DEM.shape)


fig, ax = plt.subplots()
col = ax.imshow(frame_DEM, cmap = "gist_earth", origin="lower")
fig.colorbar(col, ax = ax)


# To the sandbox
#Set the frame static - If frame doesn't change run the function again 
main.load_frame(from_file = _test_data['topo'] + "bennisson_raster_DEM_04.npy")
main.run()

"""
## <b>From a numpy array that you can modify</b>


This will directly load a numpy array that you can create and modify on the go. Just be carefull with the extent of the loaded frame.
"""

main.stop()

#Use any  random topography
rand_arr = np.ones((sensor.extent[3], sensor.extent[1]))
rand_arr[:20] = 2
rand_arr[:,:20] = 4
rand_arr[100:140,100:120] = 5

fig, ax = plt.subplots()
col = ax.imshow(rand_arr, cmap = "gist_earth", origin="lower")
fig.colorbar(col, ax = ax)


main.load_frame(rand_arr)
main.run()

# or get the topography and load it yourself
main.stop()

file=np.load( _test_data['topo'] + "DEM4.npz")
frame_topo =file["arr_0"]
frame_topo = frame_topo - frame_topo.min() # modify as here

print("shape of array:", frame_topo.shape)

fig, ax = plt.subplots()
col = ax.imshow(frame_topo, cmap = "gist_earth", origin="lower")
fig.colorbar(col, ax = ax)

"""
## Is possible to normalize this frame to the sanbox extents using the sandbox function (or any other extent)

"""

new_frame = main.normalize_topography(dem=frame_topo, target_extent=sensor.extent)

print("previous shape of array: ", frame_topo.shape, "new shape array: ", new_frame.shape)

fig, ax = plt.subplots()
col = ax.imshow(new_frame, cmap = "gist_earth", origin="lower")
fig.colorbar(col, ax = ax)

#This is also use to set a static frame from the sensor - Again run twice if not chnaging
main.load_frame(frame=new_frame)
main.run()

"""
## Go back to normal
"""

#if want to stop this completely use frame=None
main.load_frame(frame = None, from_file= None)

"""
## Fixing a sandbox frame
"""

sensor_frame = sensor.get_frame()
main.load_frame(frame = sensor_frame)

#### Stop the thread














main.stop()

sensor.Sensor._stop()



================================================
FILE: notebooks/tutorials/02_TopoModule/Topography.ipynb
================================================
# Jupyter notebook converted to Python script.

#Only use if sandbox is not installed
import os,sys
sys.path.append('../../../')

"""
## Initialize Sensor and Projector
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor
from sandbox.sensor import Sensor
sensor = Sensor(calibsensor=_calibsensor, name="kinect_v2")

# Import projector
from sandbox.projector import Projector
projector = Projector(calibprojector=_calibprojector)


"""
## Initialize marker detection
"""

#Initialize the aruco detection
from sandbox.markers import MarkerDetection
aruco = MarkerDetection(sensor=sensor)

"""
## Initialize main thread for live update
"""

from sandbox.main_thread import MainThread
main = MainThread(sensor=sensor, projector=projector, aruco= aruco if 'aruco' in globals() else None)


# Start the thread 
main.run()

"""
### Control the features of the main thread
"""

main.widget_plot_module()

"""
## Import the desired module
"""

# Import the modules to use
from sandbox.modules import TopoModule

TopoModule = TopoModule(extent=sensor.extent)

"""
## Add the module to the main thread
"""

main.add_module(name ='Topo', module=TopoModule)

#main.remove_module('Topo')

"""
## Use widgets to modify the parameters
"""

#Topography Widgets
TopoModule.show_widgets()

#### Stop the thread














main.stop()

#main.run()




================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/CombinedModel_Fold_Unconformity_Fault.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/Dummy-sensor-gempy-fast.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/Dummy-sensor-gempy-simple-models.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/Graben_model.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/Prototype_Aruco_borehole_cross-section.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Use Arucos to create boreholes and cross-sections 
"""

import os
#Run this cell only if you want to run gempy in cuda mode (requires cuda and a dedicated cpu).
#Initial compilation will take a bit longer but the model will run much faster 
os.environ["THEANO_FLAGS"] = "mode=FAST_RUN,device=cuda"

#import gempy
import gempy as gp

"""
## Initialize Sensor and Projector
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor
from sandbox.sensor import Sensor
sensor = Sensor(calibsensor=_calibsensor, name="kinect_v2")

# Import projector
from sandbox.projector import Projector
projector = Projector(calibprojector=_calibprojector)


"""
## Initialize marker detection
"""

#Initialize the aruco detection
from sandbox.markers import MarkerDetection
aruco = MarkerDetection(sensor=sensor)

"""
## Initialize main thread for live update
"""

from sandbox.main_thread import MainThread
main = MainThread(sensor=sensor, projector=projector, aruco=aruco)

# Start the thread 
main.run()

main.widget_plot_module()

"""
## Initialize the gempy module 
"""

main.stop()
from sandbox.modules.gempy import GemPyModule
gpsb= GemPyModule(geo_model = None, 
                  extent = sensor.extent, 
                  box=sensor.physical_dimensions, 
                  load_examples = True,
                  name_example = ['Horizontal_layers'])


"""
## Add the module to the main thread
"""

main.add_module(name='gempy', module=gpsb)
main.run()

#Turn on Hill Shading
gpsb.show_hillshades = True
gpsb.show_lith = True
gpsb.show_boundary = True
gpsb.show_contour = False
gpsb.show_only_faults = False
gpsb.show_fill_contour = False


"""
## Add cross section
"""

# Set section dictionary
gpsb.set_section_dict((10,10), (800,800), "Section1") 

# show section traces
gpsb.show_section_traces() 

# Possible cross sections to show
gpsb.model_sections_dict.keys()

# If no filling run again
_ = gpsb.show_cross_section("Section1")

"""
## Cross section with aruco markers
"""

"""
There can only be 2 aruco markers displayed in the model
"""

if len(gpsb.modelspace_arucos) == 2 and 'Aruco_section' in gpsb.model_sections_dict.keys():
    _ = gpsb.show_cross_section("Aruco_section")
else:
    print('Only 2 aruco markers can be present to work')

"""
## Show boreholes
This still gives some trouble when faults are in the model
"""

# Place synthetic boreholes
main.stop()
gpsb.set_borehole_dict((10, 20), "borehole1")
gpsb.set_borehole_dict((200, 500), "borehole2")
gpsb.set_borehole_dict((500, 500), "borehole3")
gpsb.set_borehole_dict((900, 500), "borehole4")
gpsb.set_borehole_dict((100, 100), "borehole5")
gpsb.set_borehole_dict((600, 700), "borehole6")
gpsb.set_borehole_dict((200, 150), "borehole7")
gpsb.set_borehole_dict((150, 200), "borehole8")
gpsb._get_polygon_data()
if len(gpsb.borehole_tube) > 0:
    p = gpsb.plot_boreholes(notebook=False, background=False)
    p.show()
main.run()

"""
## Show boreholes with arucos
"""

#Place as many aruco markers as you want in the model
lis = list(gpsb.borehole_dict.keys())
for name in lis:
    if 'aruco' not in name:
        gpsb.remove_borehole_dict(name)
main.stop()
gpsb._get_polygon_data()
if len(gpsb.borehole_tube) > 0:
    p = gpsb.plot_boreholes(notebook=False, background=False)
    p.show()
else:
    print('No aruco boreholes to show. Make sure the arucos are detected')

main.run()

"""
# Other additional nice features
"""

# Pyvista 3d model
main.stop()
gpsb.plot_3d_model()
main.run()



================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/simple_models.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/BuFaTa/BuFaTa Model.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/BuFaTa/BuFaTa Model_original.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
Gempy Model Notebook BuFaTa
"""

import sys
#sys.path.append('../../../gemgis')
#import gemgis as gg
#import geopandas as gpd
#import rasterio
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from mpl_toolkits.axes_grid1 import make_axes_locatable
import pandas as pd

import gempy as gp
# Output:
#   WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`

#   C:\Users\vonha\miniconda3\envs\gemgis_env\lib\site-packages\theano\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory

#     warnings.warn("DeprecationWarning: there is no c++ compiler."

#   WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.

#   WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.


# load input data
orientations = pd.read_csv("orientations_BuFaTa").drop(['Unnamed: 0'],axis=1)
orientations

# Output:
#      index           X           Y           Z formation   dip  azimuth  \

#   0      0   96.471041  451.563621  441.094095       Ton  30.5    180.0   

#   1      1  172.761009  661.876505  556.867380       Ton  30.5    180.0   

#   2      2  383.073893  957.757866  722.911087       Ton  30.5    180.0   

#   3      3  592.355831  722.702290  601.566862       Ton  30.5    180.0   

#   4      4  766.585622  348.469070  378.006473       Ton  30.5    180.0   

#   5      5  843.906535  167.022661  277.636299       Ton  30.5    180.0   

#   6      6  941.846359  428.882820  425.846281       Ton  30.5    180.0   

#   7      7   22.142208  299.552757  387.829132       Ton  30.5    180.0   

#   

#      polarity  

#   0         1  

#   1         1  

#   2         1  

#   3         1  

#   4         1  

#   5         1  

#   6         1  

#   7         1  

interfaces = pd.read_csv("interfaces_BuFaTa").drop(['Unnamed: 0'],axis=1)
interfaces
# Output:
#        index           X            Y           Z formation

#   0        0    0.256327   264.862147  387.256441     Sand1

#   1        0   10.593468   276.733708  387.136342     Sand1

#   2        0   17.134940   289.089822  387.379871     Sand1

#   3        0   19.150128   293.313485  387.523852     Sand1

#   4        0   27.795117   310.571693  388.501235     Sand1

#   ..     ...         ...          ...         ...       ...

#   126      2  636.023304   859.787827  616.676190       Ton

#   127      2  608.850959   912.396263  647.803661       Ton

#   128      2  560.109925   990.617267  696.266604       Ton

#   129      2  526.375318  1045.388234  716.806593       Ton

#   130      2  512.239649  1067.950829  721.252513       Ton

#   

#   [131 rows x 5 columns]

# create model
geo_model = gp.create_model("BuFaTa_Example")
geo_model
# Output:
#   BuFaTa_Example  2020-11-11 15:48

# init model
gp.init_data(geo_model, [0, 972, 0, 1069, 300, 800], [50, 50, 50],
             surface_points_df = interfaces,
             orientations_df = orientations,
             default_values=True)
# Output:
#   Active grids: ['regular']

#   BuFaTa_Example  2020-11-11 15:48

geo_model.surfaces
# Output:
#     surface          series  order_surfaces    color  id

#   0   Sand1  Default series               1  #015482   1

#   1     Ton  Default series               2  #9f0052   2

gp.map_stack_to_surfaces(geo_model,
                         {"Default_Series": ('Sand1','Ton')},
                         remove_unused_series=True)
geo_model.add_surfaces('basement')
# Output:
#       surface          series  order_surfaces    color  id

#   0     Sand1  Default_Series               1  #015482   1

#   1       Ton  Default_Series               2  #9f0052   2

#   2  basement  Default_Series               3  #ffbe00   3

#geo_model.surfaces.colors.change_colors(geo_data.surface_colors)

geo_model.set_topography(
    source='gdal', filepath='raster1.tif')
# Output:
#   Cropped raster to geo_model.grid.extent.

#   depending on the size of the raster, this can take a while...

#   storing converted file...

#   Active grids: ['regular' 'topography']

#   Grid Object. Values: 

#   array([[   9.72      ,   10.69      ,  305.        ],

#          [   9.72      ,   10.69      ,  315.        ],

#          [   9.72      ,   10.69      ,  325.        ],

#          ...,

#          [ 970.056     , 1059.28181818,  622.0892334 ],

#          [ 970.056     , 1063.16909091,  622.06713867],

#          [ 970.056     , 1067.05636364,  622.05786133]])

gp.set_interpolator(geo_model,
                    compile_theano=True,
                    theano_optimizer='fast_compile',
                    verbose=[],
                    update_kriging = False
                    )
# Output:
#   Compiling theano function...

#   Level of Optimization:  fast_compile

#   Device:  cpu

#   Precision:  float64

#   Number of faults:  0

#   Compilation Done!

#   Kriging values: 

#                      values

#   range             1528.9

#   $C_o$            55655.8

#   drift equations      [3]

#   <gempy.core.interpolator.InterpolatorModel at 0x1b650338f70>

sol = gp.compute_model(geo_model, compute_mesh=True)

#geo_model.surfaces.df

gp.plot_2d(geo_model, direction='x', show_topography=True)
# Output:
#   C:\Users\vonha\miniconda3\envs\gemgis_env\lib\site-packages\gempy\plot\plot_api.py:261: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.

#     p.fig.show()

#   <gempy.plot.visualization_2d.Plot2D at 0x1b651096400>
#   <Figure size 748.8x514.8 with 1 Axes>

gp.plot_2d(geo_model, direction='x', show_topography=True, cell_number=25)
# Output:
#   C:\Users\vonha\miniconda3\envs\gemgis_env\lib\site-packages\gempy\plot\plot_api.py:261: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.

#     p.fig.show()

#   <gempy.plot.visualization_2d.Plot2D at 0x1b65196eeb0>
#   <Figure size 748.8x514.8 with 1 Axes>

gp.plot_2d(geo_model, direction='y', show_topography=True)
# Output:
#   C:\Users\vonha\miniconda3\envs\gemgis_env\lib\site-packages\gempy\plot\plot_api.py:261: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.

#     p.fig.show()

#   <gempy.plot.visualization_2d.Plot2D at 0x1b651950b20>
#   <Figure size 748.8x514.8 with 1 Axes>

gpv = gp.plot_3d(geo_model, image=False, show_topography=True,
                 plotter_type='basic', notebook=True, show_lith=True)
# Output:
#   <PIL.Image.Image image mode=RGB size=1024x768 at 0x1B6525CDDC0>

gp.plot_3d(geo_model, show_boundaries=False, show_topography=True, show_data=False)
# Output:
#   <gempy.plot.vista.GemPyToVista at 0x1b652f4dfa0>



================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/BuFaTa/interfaces_BuFaTa
================================================
,index,X,Y,Z,formation
0,0,0.256327195431048,264.86214748436396,387.2564410436068,Sand1
1,0,10.59346813871597,276.73370778641777,387.13634245183243,Sand1
2,0,17.134940141888464,289.089821570188,387.3798706933237,Sand1
3,0,19.150128045807676,293.313485355882,387.5238515309088,Sand1
4,0,27.79511673965105,310.571692592952,388.50123495489527,Sand1
5,0,34.41734765644295,324.13919008101345,389.88497269319816,Sand1
6,0,40.7165429187572,338.5142767052691,391.7603111511834,Sand1
7,0,49.27698776241503,352.56632767504703,395.1117703639829,Sand1
8,0,55.33390628387104,364.1148523226231,398.67517684799134,Sand1
9,0,60.98703023722999,376.30944827915454,402.6646699615473,Sand1
10,0,61.93436666575576,381.4593263680641,404.03899949545695,Sand1
11,0,74.31225098443318,404.8981037004269,415.04122417500247,Sand1
12,0,89.49492674488292,440.43202569296886,433.1805324891463,Sand1
13,0,100.8011746516008,465.62880674222583,447.3807609581047,Sand1
14,0,109.35786007581868,480.9455679783049,457.5208298085165,Sand1
15,0,122.12152784712598,511.49986967805273,474.2372811887566,Sand1
16,0,134.7199183717545,543.1573638168628,490.05000706340104,Sand1
17,0,146.02616627847237,575.1378936101505,506.1492393150997,Sand1
18,0,154.748128949369,602.2728885862734,519.8931680983885,Sand1
19,0,157.81229899479604,615.9994296460927,526.4670145770536,Sand1
20,0,170.2538403642964,655.5737715750863,551.4964670352073,Sand1
21,0,179.944909998626,686.9082300594188,572.075917472723,Sand1
22,0,191.31802803451436,719.0939805375339,596.4524453757214,Sand1
23,0,200.61919188519585,750.2232183370392,609.3777335441179,Sand1
24,0,210.95633282848075,774.7739280773408,618.6365472091318,Sand1
25,0,224.82375707423273,798.4767847239435,631.7543348936957,Sand1
26,0,240.67561304042493,822.9062405945112,647.596365289188,Sand1
27,0,255.21221749191938,846.1648077169024,664.0991005820908,Sand1
28,0,264.903287126249,861.9935547863074,674.6964025225556,Sand1
29,0,272.76272323875287,874.2512796291529,684.1362770574041,Sand1
30,0,291.3922107934166,899.788726360193,702.1451206779758,Sand1
31,0,308.8361361352099,915.9405090840756,710.2052883803151,Sand1
32,0,323.27905317555906,927.3449733382452,714.94407432692,Sand1
33,0,341.462737237453,937.9069335885562,718.4669763245737,Sand1
34,0,355.03023472551445,947.2749675684081,720.8933748804561,Sand1
35,0,366.0632917955071,952.6031383066481,721.9774915961378,Sand1
36,0,384.7495149374586,957.2890728572154,722.7534957947348,Sand1
37,0,394.44058457178824,955.9969302393048,722.2393823309446,Sand1
38,0,407.8165849065408,950.0257745343622,720.93928902742,Sand1
39,0,423.1907578202995,941.4603257878103,718.4275993711084,Sand1
40,0,441.2807544710481,929.1849709176595,714.6193140073319,Sand1
41,0,456.27102382551817,917.5509910035582,710.4730724786738,Sand1
42,0,474.5534268822465,900.757833323626,704.0026066502598,Sand1
43,0,490.05913829717383,879.4374801281008,693.6318432970888,Sand1
44,0,503.94967143971303,861.3474834773522,682.6191952879173,Sand1
45,0,515.0349178336396,847.9621691518354,673.1071834101623,Sand1
46,0,530.7616307613583,821.9371336310784,658.098119731889,Sand1
47,0,545.6212708673304,798.3555308542095,644.3629944784465,Sand1
48,0,559.8348396643472,775.7430350407737,631.3010993441718,Sand1
49,0,575.3452301051327,753.6306550861667,618.0459917221156,Sand1
50,0,592.1384051121127,724.0573303243491,601.9258620888534,Sand1
51,0,604.0907243277858,703.706084092257,587.253154455655,Sand1
52,0,617.9812574703249,678.1862673885223,570.791459116032,Sand1
53,0,629.6105410315205,658.804128119863,557.7624174042278,Sand1
54,0,638.748378903369,641.7730673689532,547.9141808002481,Sand1
55,0,651.2539298815232,612.9330651840361,533.4401286710007,Sand1
56,0,660.6219638613752,594.1969972243322,524.5408401519725,Sand1
57,0,669.3439265322719,575.4609292646282,515.6495026168589,Sand1
58,0,674.8314717153735,563.4212086914579,510.40361565939696,Sand1
59,0,685.4957092561546,542.18825685343,499.56224880647807,Sand1
60,0,698.7401710897384,515.053261877307,484.36492011875197,Sand1
61,0,710.6924903054116,486.9491599377511,466.2632700316087,Sand1
62,0,720.0605242852636,462.39845019744945,449.5034199014823,Sand1
63,0,727.4903443382495,442.3702396198349,436.1266515592672,Sand1
64,0,734.1108384779523,426.30545600584105,424.6408681831987,Sand1
65,0,745.9033766434759,391.3306062123655,404.32990638458784,Sand1
66,0,759.1478384770597,360.3191833825108,385.87055134671454,Sand1
67,0,767.5467654934788,341.5831154228068,375.22346522794544,Sand1
68,0,771.7403495533283,327.3346871500575,367.9610883399364,Sand1
69,0,779.1760490546743,305.080086466832,355.48266020954685,Sand1
70,0,785.3137264897498,279.23723410861965,340.72286176316567,Sand1
71,0,795.967569012817,245.88999194581893,319.13880268960315,Sand1
72,0,805.9880083763195,216.89135279443246,300.0543185400322,Sand1
73,0,812.4487214658725,198.47832048920617,291.11350824216913,Sand1
74,0,818.648370208934,185.5796796743258,285.36905923916663,Sand1
75,0,826.9853259173669,173.92761074890447,280.4023789572484,Sand1
76,0,841.329171405051,164.96076949603759,276.8606290291559,Sand1
77,0,857.0276417837888,173.60457509442682,280.30505046596886,Sand1
78,0,867.1028091279114,188.15704344661185,287.09833029629465,Sand1
79,0,874.1485314711044,203.323855306371,295.2835105777404,Sand1
80,0,886.7469219957329,240.14991991682354,332.6923730814722,Sand1
81,0,893.8537063942413,268.25402185637944,355.3589900402059,Sand1
82,0,900.3144194837944,285.69794719817276,367.71467403064435,Sand1
83,0,903.701374694373,295.89084912816793,373.1330462019297,Sand1
84,0,909.6824534636465,319.6166909183264,383.18050479776394,Sand1
85,0,916.4662022076773,337.70668756907503,390.47519935859793,Sand1
86,0,920.1965028370037,355.17021589074665,395.120107398503,Sand1
87,0,929.3876283867835,383.2547148504243,403.8964393807148,Sand1
88,0,936.1713771308141,409.09756720863663,415.823737722395,Sand1
89,0,945.539411110666,440.75506134744666,431.39615209699997,Sand1
90,0,950.0939225955215,453.11003923761575,438.8746223475355,Sand1
91,0,955.5535163994733,474.35076941312263,449.8858892655362,Sand1
92,0,962.6603007979818,497.60933653551376,463.1954089631016,Sand1
93,0,966.0735779836949,510.32751498236564,470.8803538709167,Sand1
94,0,970.5451269713545,529.8471006128257,481.42755003911657,Sand1
95,1,0.1881868620686138,495.787213546976,406.9510041976154,Ton
96,1,8.840672956663411,504.1418419288791,412.1247686500119,Ton
97,1,41.09257661030145,546.423052386348,437.3291778509842,Ton
98,1,71.7283490004425,604.1435562935771,465.42787461906545,Ton
99,1,87.60971085508348,626.535894696806,478.563496627686,Ton
100,1,116.35988410359462,686.6205264296495,508.3002966301822,Ton
101,1,140.8016980977082,751.568764068338,548.5045502174379,Ton
102,1,181.61308630808054,848.1383536684762,607.0556371306402,Ton
103,1,223.27733881086107,950.5412472888196,674.4622442279132,Ton
104,1,238.4673614961476,988.0127920572999,694.1796798842839,Ton
105,1,253.1747585693791,1022.7074329128286,707.3700868645249,Ton
106,1,265.6023564722704,1045.513138554322,713.3158649094391,Ton
107,1,277.809700000426,1067.486356905002,716.8160345191504,Ton
108,2,970.6766251230017,833.052616499831,586.971399552448,Ton
109,2,959.3724321757514,800.0232029873156,561.5855139072744,Ton
110,2,941.2919969974961,754.801239252839,531.8146458215217,Ton
111,2,925.3512303815758,711.3618892206762,513.7101533117823,Ton
112,2,908.0193245862978,675.9805395602916,502.76825559763654,Ton
113,2,898.5466471498011,648.474213176897,495.7660827473431,Ton
114,2,882.8225435370409,621.7105496080459,485.059569410266,Ton
115,2,869.6801729001976,594.8650467133475,473.30489313499413,Ton
116,2,852.4571920161416,577.4546649446074,463.34575966273565,Ton
117,2,831.5351890703644,569.0914089904873,457.9495200561038,Ton
118,2,810.139521279569,572.9321657819203,459.83954367831365,Ton
119,2,790.2973687137878,583.524646115289,466.88094348819664,Ton
120,2,772.6673853601612,603.6205529572973,477.25649583939384,Ton
121,2,757.3071124285267,626.8243574896944,487.22402419796106,Ton
122,2,740.0407842579184,658.5366142184982,499.8250020815431,Ton
123,2,723.285910634351,693.8358155691311,515.2001312353267,Ton
124,2,700.6304344116447,739.6185634923892,540.2479712586871,Ton
125,2,677.9243082421169,782.4971293357705,567.7727478777219,Ton
126,2,636.0233035161142,859.787826958076,616.6761903652387,Ton
127,2,608.8509591448512,912.3962634589865,647.8036609927173,Ton
128,2,560.1099247138658,990.6172670215257,696.2666044468152,Ton
129,2,526.3753184316984,1045.3882341089457,716.8065929605166,Ton
130,2,512.239649401046,1067.9508285278182,721.2525132211506,Ton



================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/BuFaTa/orientations_BuFaTa
================================================
,index,X,Y,Z,formation,dip,azimuth,polarity
0,0,96.47104121438838,451.5636209742439,441.094094568376,Ton,30.5,180.0,1
1,1,172.76100887405482,661.8765047927839,556.8673800124213,Ton,30.5,180.0,1
2,2,383.0738926925949,957.7578658512201,722.9110870035399,Ton,30.5,180.0,1
3,3,592.3558310022205,722.7022898187342,601.5668615757718,Ton,30.5,180.0,1
4,4,766.5856220087561,348.46907008280266,378.00647318972665,Ton,30.5,180.0,1
5,5,843.906535177337,167.02266051386619,277.6362992553112,Ton,30.5,180.0,1
6,6,941.8463585242062,428.88281977812676,425.84628112520215,Ton,30.5,180.0,1
7,7,22.14220797837953,299.5527565162123,387.82913171806445,Ton,30.5,180.0,1



================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/BuFaTa/raster1.tif
================================================
[Non-text file]


================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/complex_model/complex_model.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/04_GempyModule/Example_Models/complex_model/geological_model.PNG
================================================
[Non-text file]


================================================
FILE: notebooks/tutorials/04_GempyModule/Model_Construction/Bennisson_model/gemgis_Bennisson_Model.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/04_GempyModule/Model_Construction/Complex_model/geological_model.PNG
================================================
[Non-text file]


================================================
FILE: notebooks/tutorials/04_GempyModule/Model_Construction/Complex_model/Map_to_model_full_model.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/04_GempyModule/Model_Construction/Complex_model/Map_to_model_stepwise_model.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/05_GradientModule/test_field_manipulation.ipynb
================================================
# Jupyter notebook converted to Python script.

#Only use if sandbox is not installed
import os,sys
sys.path.append('../../../')
#import warnings
#warnings.filterwarnings('ignore')


"""
## Initialize Sensor and Projector
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor
from sandbox.sensor import Sensor
sensor = Sensor(calibsensor=_calibsensor, name="kinect_v2")

# Import projector
from sandbox.projector import Projector
projector = Projector(calibprojector=_calibprojector)


"""
## Initialize marker detection
"""

#Initialize the aruco detection
from sandbox.markers import MarkerDetection
aruco = MarkerDetection(sensor=sensor)

"""
## Initialize main thread for live update
"""

from sandbox.main_thread import MainThread
main = MainThread(sensor=sensor, projector=projector, aruco=aruco)

# Start the thread 
main.run()

main.widget_plot_module()

"""
## Import the desired Module
"""

# Import the modules to use
from sandbox.modules import GradientModule

Gradients = GradientModule(extent=sensor.extent)

main.add_module(name='GradientsModule', module=Gradients)


Gradients.show_widgets()

#Stop main thread






main.stop()




================================================
FILE: notebooks/tutorials/07_LandslideSimulation/Load_and_Run_Landslides_Simulation.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/08_PrototypingModule/simpel setup.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
### import the libraries
"""

#Only use if sandbox is not installed
import os,sys
sys.path.append('../../../')
import matplotlib.pyplot as plt

"""
### Setup the projector and Sensor and load a calibration
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor
from sandbox.sensor import Sensor
sensor = Sensor(calibsensor=_calibsensor, name="kinect_v2")


# Import projector
from sandbox.projector import Projector
projector = Projector(calibprojector=_calibprojector)


#Initialize the aruco detection
from sandbox.markers import MarkerDetection
aruco = MarkerDetection(sensor=sensor)

from sandbox.main_thread import MainThread
main = MainThread(sensor=sensor, projector=projector, aruco = aruco)


# Start the thread 
main.run()

main.widget_plot_module()

"""
### start prototyping 
"""

depth = sensor.get_frame()


plt.pcolormesh(depth)

"""
###  start the runtime loop
"""

main.run()










module.stop()



================================================
FILE: notebooks/tutorials/09_LandscapeGeneration/deep_learning_landscapes.ipynb
================================================
# Jupyter notebook converted to Python script.

#Only use if sandbox is not installed
import os,sys
sys.path.append('../../../')

"""
## Before starting be sure you have some models in the checkpoints folder 
"""

from sandbox import _test_data
if len(os.listdir(_test_data["landscape_generation"] + "checkpoints")) == 0:
    from warnings import warn 
    warn('No models to run! You need to download the files using Pooch' 
         '(Check README file "Downloading sample datasets")')
    
    from sandbox.utils.download_sample_datasets import (landscape_models, 
                                                        download_landscape_name)
    
    while True:
        if input("Do you want to download an specific Trained model? [y/n]") == "y":
            print("Available models: %s" % landscape_models)
            model = input("Name of model to download:")
            download_landscape_name(model)
        else:
            break
else:
    print("Available models to run: \n{}".format(os.listdir(_test_data["landscape_generation"] + "checkpoints")))

"""
## Initialize Sensor and Projector
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor
from sandbox.sensor import Sensor
sensor = Sensor(calibsensor=_calibsensor, name="dummy")

# Import projector
from sandbox.projector import Projector
projector = Projector(calibprojector=_calibprojector)


"""
## Initialize marker detection
"""

from sandbox.markers import MarkerDetection
aruco = MarkerDetection(sensor = sensor)

"""
## Initialize main thread for live update
"""

from sandbox.main_thread import MainThread
main = MainThread(sensor=sensor, projector=projector, aruco=aruco)


main.run()





"""
### Control the features of the main thread
"""

main.widget_plot_module()

"""
## Set the path of: pytorch-CycleGAN-and-pix2pix 
"""

from sandbox import _package_dir
package_dir=os.path.abspath(_package_dir+"/../../pytorch-CycleGAN-and-pix2pix")

"""
## Import the desired module
"""

from sandbox.modules.pytorch import LandscapeGeneration
landscape = LandscapeGeneration(extent=sensor.extent, package_dir=package_dir)

import os
from sandbox import _test_data
os.listdir(_test_data["landscape_generation"] + "checkpoints")

"""
## Add the module to the main thread
"""

main.add_module('landscape', landscape)

"""
### Be sure that the model you want to use is saved in the checkpoint folder
"""

assert len(landscape.name_trained_models)>0
landscape.name_model = landscape.name_trained_models[0]

#Now you can select which model you want to select, by default it will use the model that ppears first in the list
print("Possible models: ", landscape.name_trained_models, "\n Model to use:", landscape.name_model)

"""
### Use the widgets from the LoadSaveTopoModule to set the area for the landscape generation
"""

"""
Use the tab "Box widgets" to modify the extent of the box and capture a new frame using the snapshot button
"""


landscape.LoadArea.show_widgets()

"""
It is also possible to this manually by:
"""

save_topo = landscape.LoadArea.extractTopo()
assert landscape.LoadArea.absolute_topo is not None

"""
### Now with the saved topography, we first need to modify and save the image to be used by pytorch-CycleGAN-and-pix2pix
"""

DEM = landscape.get_image_modify()

landscape.save_image(DEM, name = 'landscape_image.png')

"""
### If the previous was succesfull and you can see the doubled image, you can continue by running the command line using the follow line: 
"""

landscape.run_cmd()#package_dir=package_dir)

"""
This basically will construct the line you need to run in your terminal or cmd for pytorch-CycleGAN-and-pix2pix to run correctly in your system. If the line is not working, you can run this manually in your system. Just copy paste the previous
"""

"""
### When this is done, you can load and display the generated image by:
"""

landscape.read_result(name = 'landscape_image.png')

import matplotlib.pyplot as plt
main.stop()
fig, ax = plt.subplots(1,2, figsize=(15,15))
ax[0].imshow(landscape.DEM, origin="lower", cmap = "gist_earth")
ax[0].set_title("Real DEM Image")
ax[0].set_axis_off()

ax[1].imshow(landscape.img,  extent=landscape.LoadArea.to_box_extent)
ax[1].set_title("Generated Landscape Image")
ax[1].set_axis_off()
plt.show()
main.run()

"""
### And if you want to visualize this image on the sandbox change this flag to True: 
"""

landscape.show_landscape=True










"""
## All the previous work also with widgets following the instructions and previous procedure
"""

landscape.show_widgets()













main.stop()



================================================
FILE: notebooks/tutorials/10_SeismicModule/seismic_sandbox.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/10_SeismicModule/steps_seismic_in_windows_EXPERIMENTAL.txt
================================================
Open Ubuntu app in Windows and run: EXPERIMENTAL AND NOT WORKING AT THE MOMENT

1). open the repo

>>> cd /home/sandbox/Git_projects/open_AR_Sandbox

2). activate environment 

>>> conda activate sandbox

3). checkout for latest commit 

git stash save
git fetch origin
git checkout origin/seismic

4) set the direction for the kinect sensor o work - See installation guide

>>> export PKG_CONFIG_PATH=$HOME/freenect2/lib/pkgconfig

3). open notebook 

>> jupyter notebook --no-browser

The no browser flag will still run Jupyter on port 8888, but it won't pop it open automatically. it's necessary since you don't have a browser in your subsystem. In the terminal, it will give you a link to paste into your browse



================================================
FILE: notebooks/tutorials/11_GeoelectricsModule/Geoelectrics.ipynb
================================================
# Jupyter notebook converted to Python script.

#Only use if sandbox is not installed
import os,sys
sys.path.append('../../../')
#import warnings
#warnings.filterwarnings("ignore")

"""
## Initialize Sensor and Projector
"""

#save the paths to the calibration files 
from sandbox import _calibration_dir
_calibprojector = _calibration_dir + "my_projector_calibration.json"
_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor
from sandbox.sensor import Sensor
sensor = Sensor(calibsensor=_calibsensor, name="dummy",
               gauss_filter = False)

# Import projector
from sandbox.projector import Projector
projector = Projector(calibprojector=_calibprojector)


"""
## Initialize marker detection
"""

#Initialize the aruco detection
from sandbox.markers import MarkerDetection
aruco = MarkerDetection(sensor=sensor)

"""
## Initialize main thread for live update
"""

from sandbox.main_thread import MainThread
main = MainThread(sensor=sensor, projector=projector, aruco=aruco)


# Start the thread 
main.run()

"""
### Control the features of the main thread
"""

main.widget_plot_module()

"""
## Import the desired module
"""

# Import the modules to use and initialize them
from sandbox.modules.gimli import GeoelectricsModule

geoelec = GeoelectricsModule()

"""
## Add the module to the main thread
"""

main.add_module(name ='GeoelectricModule', module=geoelec)

main.run()

"""
## Steps to run the simulation
"""

main.stop()

"""
### 1) create a mesh from the sandbox topography 
"""

#Get current frame
frame = sensor.get_frame()
extent = sensor.extent

# Normalize the frame and get some real resistivity values 
frame2, extent2 = geoelec.scale_linear(frame, extent, vmin=5, vmax=1e5)
step = 7.5 # This is to generate a coarser mesh, for faster runtime simulation
mesh, data = geoelec.create_mesh(frame2, step)
print(mesh)

# We can visualize the original fine mesh and the coarser mesh that will be
# used in the simulations, and a small comparison between both resolutions
fig = geoelec.show_mesh()

"""
### 2) Position the 4 arucos and assign the id to the type of electrode
"""

"""
If no arucos available, you can manually set some dummy arucos in the model by doing:
"""

aruco.set_aruco_position(dict_position={}) #be sure the dict is empty
# {id:[x_coordinate, y_coordinate]}
dict_position = {3: [50, 100],
                 2: [100, 100],
                 5: [150, 100],
                 6: [200, 100]}
aruco.set_aruco_position(dict_position=dict_position, frame=sensor.get_frame())
aruco.update()
#Run cell again if arucos are still not visible
main.run()
main.stop()

# The id of the aruco will appear next to the place it is detected, or as a list doing:
df = geoelec.df_markers
assert len(df)==4
df
# The id is the index of the dataframe

# 0 : electrode a
# 1 : electrode b
# 2 : electrode m
# 3 : electrode n
#Assign the aruco id to the electrode id
geoelec.set_id_aruco({3: 0,
                      6: 1,
                      2: 2,
                      5: 3})
assert geoelec.id is not None
geoelec.id

geoelec.set_aruco_electrodes(df)
assert geoelec.electrode is not None
geoelec.electrode
# Remember, this will be the positions for the electrodes
# row 0 : electrode a
# row 1 : electrode b
# row 2 : electrode m
# row 3 : electrode n

"""
### 3) create data container ERT
"""

# This will describe the type of measurement performed and create the geometric factors
import numpy as np
measurements = np.array([[0, 1, 2, 3],])
scheme_type = "abmn"  #Dipole-Dipole
    
scheme = geoelec.create_data_containerERT(measurements, scheme_type)
print(scheme)

"""
### 4) calculate current flow based on the aruco positions
"""

sim, pot = geoelec.calculate_current_flow(time=True)

fig = geoelec.show_streams(quiver=False)

"""
### 5) perform a sensitivity analysis
"""

geoelec.calculate_sensitivity(time=True)

fig = geoelec.show_sensitivity()

"""
### To display the results in the thread of the sandbox use:
"""

main.run()

geoelec.p_stream = True  # plot the stream lines
geoelec.view = "potential"  # to show the geoelectric field

geoelec.p_stream = True  # plot the stream lines
geoelec.view = "sensitivity"  # to show the sensitivity analysis

geoelec.p_stream = False  # plot the stream lines
geoelec.p_quiver = True  # plot the vector field of the geoelectric field
geoelec.view = "mesh"  # to show the geoelectric field

# or is also possible to use the widgets

geoelec.widgets_controller()

main.stop()

"""
## All the previous can be summarized using the widgets
"""

main.run()


aruco.set_aruco_position(dict_position={}) #be sure the dict is empty
# {id:[x_coordinate, y_coordinate]}
dict_position = {0: [50, 150],
                 1: [100, 100],
                 2: [150, 100],
                 3: [200, 100]}
aruco.set_aruco_position(dict_position=dict_position, frame=sensor.get_frame())
aruco.update()

geoelec.show_widgets()

"""
Note: You can use the same procedure in real time. This will work as long as the 4 arucos are detected. If you want to stop the simulation just remove or hide one of the arucos
"""

# stop thread of sandbox





main.stop()Skip to left side bar
>
/
/tutorials/11_GeoelectricsModule/
Name
Last Modified

#Only use if sandbox is not installed

import os,sys

sys.path.append('../../../')

#import warnings

#warnings.filterwarnings("ignore")

Initialize Sensor and Projector

#save the paths to the calibration files 

from sandbox import _calibration_dir

_calibprojector = _calibration_dir + "my_projector_calibration.json"

_calibsensor = _calibration_dir + "my_sensor_calibration.json"

#Import Sensor

from sandbox.sensor import Sensor

sensor = Sensor(calibsensor=_calibsensor, name="dummy",

               gauss_filter = False)

# Import projector

from sandbox.projector import Projector

projector = Projector(calibprojector=_calibprojector)

​

Initialize marker detection

#Initialize the aruco detection

from sandbox.markers import MarkerDetection

aruco = MarkerDetection(sensor=sensor)

Initialize main thread for live update

from sandbox.main_thread import MainThread

main = MainThread(sensor=sensor, projector=projector, aruco=aruco)

​

# Start the thread 

main.run()

Control the features of the main thread

main.widget_plot_module()

Import the desired module

# Import the modules to use and initialize them

from sandbox.modules.gimli import GeoelectricsModule

geoelec = GeoelectricsModule()

Add the module to the main thread

main.add_module(name ='GeoelectricModule', module=geoelec)

main.run()

Steps to run the simulation

main.stop()

1) create a mesh from the sandbox topography

#Get current frame

frame = sensor.get_frame()

extent = sensor.extent

# Normalize the frame and get some real resistivity values 

frame2, extent2 = geoelec.scale_linear(frame, extent, vmin=5, vmax=1e5)

step = 7.5 # This is to generate a coarser mesh, for faster runtime simulation

mesh, data = geoelec.create_mesh(frame2, step)

print(mesh)

# We can visualize the original fine mesh and the coarser mesh that will be

# used in the simulations, and a small comparison between both resolutions

fig = geoelec.show_mesh()

2) Position the 4 arucos and assign the id to the type of electrode

If no arucos available, you can manually set some dummy arucos in the model by doing:

aruco.set_aruco_position(dict_position={}) #be sure the dict is empty

# {id:[x_coordinate, y_coordinate]}

dict_position = {3: [50, 100],

                 2: [100, 100],

                 5: [150, 100],

                 6: [200, 100]}

aruco.set_aruco_position(dict_position=dict_position, frame=sensor.get_frame())

aruco.update()

#Run cell again if arucos are still not visible

main.run()

main.stop()

# The id of the aruco will appear next to the place it is detected, or as a list doing:

df = geoelec.df_markers

assert len(df)==4

df

# The id is the index of the dataframe

# 0 : electrode a

# 1 : electrode b

# 2 : electrode m

# 3 : electrode n

#Assign the aruco id to the electrode id

geoelec.set_id_aruco({3: 0,

                      6: 1,

                      2: 2,

                      5: 3})

assert geoelec.id is not None

geoelec.id

geoelec.set_aruco_electrodes(df)

assert geoelec.electrode is not None

geoelec.electrode

# Remember, this will be the positions for the electrodes

# row 0 : electrode a

# row 1 : electrode b

# row 2 : electrode m

# row 3 : electrode n

3) create data container ERT

# This will describe the type of measurement performed and create the geometric factors

import numpy as np

measurements = np.array([[0, 1, 2, 3],])

scheme_type = "abmn"  #Dipole-Dipole

    

scheme = geoelec.create_data_containerERT(measurements, scheme_type)

print(scheme)

4) calculate current flow based on the aruco positions

sim, pot = geoelec.calculate_current_flow(time=True)

fig = geoelec.show_streams(quiver=False)

5) perform a sensitivity analysis

geoelec.calculate_sensitivity(time=True)

fig = geoelec.show_sensitivity()

To display the results in the thread of the sandbox use:

main.run()

geoelec.p_stream = True  # plot the stream lines

geoelec.view = "potential"  # to show the geoelectric field

geoelec.p_stream = True  # plot the stream lines

geoelec.view = "sensitivity"  # to show the sensitivity analysis

geoelec.p_stream = False  # plot the stream lines

geoelec.p_quiver = True  # plot the vector field of the geoelectric field

geoelec.view = "mesh"  # to show the geoelectric field

# or is also possible to use the widgets

geoelec.widgets_controller()

main.stop()

All the previous can be summarized using the widgets

main.run()

​

aruco.set_aruco_position(dict_position={}) #be sure the dict is empty

# {id:[x_coordinate, y_coordinate]}

dict_position = {0: [50, 150],

                 1: [100, 100],

                 2: [150, 100],

                 3: [200, 100]}

aruco.set_aruco_position(dict_position=dict_position, frame=sensor.get_frame())

aruco.update()

geoelec.show_widgets()

Note: You can use the same procedure in real time. This will work as long as the 4 arucos are detected. If you want to stop the simulation just remove or hide one of the arucos

# stop thread of sandbox

​

​

​

​

​

main.stop()





================================================
FILE: notebooks/tutorials/12_PynoddyModule/kinematic_modeling.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: notebooks/tutorials/13_DummySensor/Dummy-sensor-topography-example.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: sandbox/__init__.py
================================================
"""
Module initialisation for sandbox
Created on 15/04/2020

@authors: Daniel Escallon, Simon Virgo, Miguel de la Varga
@Project Lead: Florian Wellmann
"""
# Main information for all the modules to work (calibration data, projector and sensor)
__version__ = '1.0'

import os
_package_dir = os.path.dirname(__file__)
_calibration_dir = os.path.abspath(os.path.dirname(__file__) + '/../notebooks/calibration_files/')+os.sep
_test_data = {'topo': os.path.abspath(os.path.dirname(__file__) +
                                      '/../notebooks/tutorials/06_LoadSaveTopoModule/saved_DEMs/')+os.sep,
              'landslide_topo': os.path.abspath(os.path.dirname(__file__) +
                                                '/../notebooks/tutorials/07_LandslideSimulation/saved_DEMs/')+os.sep,
              'landslide_release': os.path.abspath(os.path.dirname(__file__) +
                                                   '/../notebooks/tutorials/07_LandslideSimulation/'
                                                   'saved_ReleaseAreas/')+os.sep,
              'landslide_simulation': os.path.abspath(os.path.dirname(__file__) +
                                                      '/../notebooks/tutorials/07_LandslideSimulation/'
                                                      'simulation_data/')+os.sep,
              'gempy_data': os.path.abspath(os.path.dirname(__file__) +
                                            '/../notebooks/tutorials/04_GempyModule/Model_Construction/'
                                            'Bennisson_model/data/')+os.sep,
              'gempy_example_data': os.path.abspath(os.path.dirname(__file__) +
                                            '/../notebooks/tutorials/04_GempyModule/Example_Models/'
                                            'data_examples/')+os.sep,
              'test': os.path.abspath(os.path.dirname(__file__) + '/../tests/test_data/')+os.sep,
              'landscape_generation': os.path.abspath(os.path.dirname(__file__) +
                                                      '/../notebooks/tutorials/09_LandscapeGeneration/')+os.sep,
              'pynoddy_data': os.path.abspath(os.path.dirname(__file__) +
                                                      '/../notebooks/tutorials/12_PynoddyModule/output/')+os.sep
              }

# Create folders if not existing
# Topo folder
if not os.path.isdir(_test_data.get("topo")):
    os.mkdir(_test_data.get("topo"))

# Landslides folders
if not os.path.isdir(_test_data.get("landslide_topo")):
    os.mkdir(_test_data.get("landslide_topo"))
if not os.path.isdir(_test_data.get("landslide_release")):
    os.mkdir(_test_data.get("landslide_release"))
if not os.path.isdir(_test_data.get("landslide_simulation")):
    os.mkdir(_test_data.get("landslide_simulation"))

# Test folders
if not os.path.isdir(_test_data.get("test")):
    os.mkdir(_test_data.get("test"))
    os.mkdir(_test_data.get("test")+"temp")
    os.mkdir(_test_data.get("test") + "noddy")

# Landscape folders
if not os.path.isdir(_test_data.get("landscape_generation")+"checkpoints"):
    os.mkdir(_test_data.get("landscape_generation")+"checkpoints")
if not os.path.isdir(_test_data.get("landscape_generation")+"results"):
    os.mkdir(_test_data.get("landscape_generation")+"results")
if not os.path.isdir(_test_data.get("landscape_generation")+"saved_DEMs"):
    os.mkdir(_test_data.get("landscape_generation")+"saved_DEMs")
    os.mkdir(_test_data.get("landscape_generation") + "saved_DEMs/test")

# Gempy folders
if not os.path.isdir(_test_data.get("gempy_data")):
    os.mkdir(_test_data.get("gempy_data"))

if not os.path.isdir(_test_data.get("gempy_example_data")):
    os.mkdir(_test_data.get("gempy_example_data"))

# Pynoddy folders
if not os.path.isdir(_test_data.get("pynoddy_data")):
    os.mkdir(_test_data.get("pynoddy_data"))

# logging and exception handling
from sandbox.utils.logger import set_logger


# download sample files. If already downloaded they are ignored
from sandbox.utils.download_sample_datasets import (download_test_data,
                                                    download_topography_data,
                                                    download_landscape_name,
                                                    download_landscape_all,
                                                    download_landslides_data,
                                                    download_benisson_model)


if __name__ == '__main__':
    pass




================================================
FILE: sandbox/main_thread.py
================================================
import asyncio

import collections
import numpy
import threading
import panel as pn
pn.extension()
import matplotlib.pyplot as plt
import pandas as pd
import traceback
from datetime import datetime
import skimage.transform
import platform
_platform = platform.system()

dateTimeObj = datetime.now()

from sandbox.projector import Projector, ContourLinesModule, CmapModule
from sandbox.sensor import Sensor
from sandbox.markers import MarkerDetection
from sandbox import set_logger
logger = set_logger(__name__)


class MainThread:
    """
    Module with threading methods
    """

    def __init__(self, sensor: Sensor, projector: Projector, aruco: MarkerDetection = None,
                 check_change: bool = False, kwargs_contourlines: dict = {}, kwargs_cmap: dict = {},
                 **kwargs):
        """

        Args:
            sensor:
            projector:
            aruco:
            modules:
            crop:
            clip:
            check_change:
            **kwargs:
        """
        self._error_message = ''
        # TODO: in all the modules be carefull with zorder
        self.sensor = sensor
        self.projector = projector
        self.projector.clear_axes()
        self.contours = ContourLinesModule(extent=self.sensor.extent, **kwargs_contourlines)
        self.cmap_frame = CmapModule(extent=self.sensor.extent, **kwargs_cmap)

        # start the modules
        self.modules = collections.OrderedDict({'CmapModule': self.cmap_frame, 'ContourLinesModule': self.contours})
        self._modules = collections.OrderedDict({'CmapModule': self.cmap_frame, 'ContourLinesModule': self.contours})

        # threading
        self.lock = threading.Lock()
        self.thread = None
        self.thread_status = 'stopped'  # status: 'stopped', 'running', 'paused'
        self.main_task = None

        # connect to ArucoMarker class
        # if CV2_IMPORT is True:
        self.Aruco = aruco
        self.ARUCO_ACTIVE = False
        if isinstance(self.Aruco, MarkerDetection):
            self.ARUCO_ACTIVE = True

        self.sb_params = {'frame': self.sensor.get_frame(),
                          'ax': self.projector.ax,
                          'set_colorbar': self.projector.set_colorbar,
                          'set_legend': self.projector.set_legend,
                          'extent': self.sensor.extent,
                          'box_dimensions': self.sensor.physical_dimensions,
                          'marker': pd.DataFrame(),
                          'cmap': plt.cm.get_cmap('gist_earth'),
                          'norm': None,
                          'active_cmap': True,
                          'active_shading': True,
                          'active_contours': True,
                          'same_frame': False,
                          'lock_thread': self.lock,
                          'trigger': self.projector.trigger,
                          # TODO: Carefull with this use because it can make to paint the figure incompletely
                          'del_contour': True, }
        # 'freeze_frame': False}

        self.previous_frame = self.sb_params['frame']

        # To reduce the noise of the data
        self.check_change = check_change
        self._rtol = 0.07  # Widgets for this
        self._atol = 0.001
        # render the frame
        self.cmap_frame.render_frame(self.sb_params['frame'], self.sb_params['ax'])
        # plot the contour lines
        self.contours.plot_contour_lines(self.sb_params['frame'], self.sb_params['ax'])
        self.projector.trigger()

        self._create_widgets()

        self._loaded_frame = False
        self._error_message = ''
        self._widget_error_markdown = pn.pane.Markdown("<p>Open_AR_Sandbox</p>")

    # @property @TODO: test if this works
    # def sb_params(self):
    #    return {'frame': self.sensor.get_frame(),
    #              'ax': self.projector.ax,
    #              'extent': self.sensor.extent,
    #              'marker': pd.DataFrame(),
    #              'cmap': plt.cm.get_cmap('gist_earth'),
    #              'norm': None,
    #              'active_cmap': True,
    #              'active_contours': True,
    #              'same_frame': False,
    #              'freeze_frame': False}

    def update(self, **kwargs):
        """
        Args:
            **kwargs:

        Returns:

        """
        self.sb_params['ax'] = self.projector.ax

        if self._loaded_frame:
            frame = self.previous_frame  # if loaded DEM the previous frame will have this information
            self.sb_params['extent'] = [0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()]
            self.sb_params[
                'same_frame'] = False  # TODO: need to organize the usage of same_frame because is contradictory
        else:
            frame = self.sensor.get_frame()
            self.sb_params['extent'] = self.sensor.extent
            # This is to avoid noise in the data
            if self.check_change:
                cl = numpy.isclose(self.previous_frame, frame, atol=self._atol, rtol=self._rtol, equal_nan=True)
                self.previous_frame[numpy.logical_not(cl)] = frame[numpy.logical_not(cl)]
                frame = self.previous_frame
                # self.sb_params['same_frame'] = True #TODO: Check for usage of this part
            else:
                self.previous_frame = frame
                self.sb_params['same_frame'] = False
        self.sb_params['frame'] = frame

        # filter
        self.lock.acquire()
        if self.ARUCO_ACTIVE:
            df = self.Aruco.update()
        else:
            df = pd.DataFrame()
        self.lock.release()

        self.sb_params['marker'] = df

        try:
            if self._error_message:
                self.sb_params['ax'].texts = []
                self._error_message = ''
                self._widget_error_markdown.object = "Running"
            self.lock.acquire()
            _cmap = ['CmapModule'] if 'CmapModule' in self.modules.keys() else []
            _contours = ['ContourLinesModule'] if 'ContourLinesModule' in self.modules.keys() else []
            _always = _cmap + _contours
            _actual = [name for name in self.modules.keys() if name not in _always]
            for key in list(
                    _actual + _always):  # TODO: maybe use OrderedDict to put this modules always at the end of the iteration
                self.sb_params = self.modules[key].update(self.sb_params)
            self.lock.release()
        except Exception as e:
            traceback.print_exc()
            logger.critical(e, exc_info=True)
            self._error_message = str(dateTimeObj) + str(type(e)) + str(e)
            self._widget_error_markdown.object = self._error_message
            self.lock.release()
            self.thread_status = 'stopped'
            self.projector.write_text("Ups... Something went wrong. The Thread is paused..."
                                      "\n Check 'self._error_message' to see what happened"
                                      "\n or open the 'sandbox.log' file for a detailed description")

        self.sb_params['ax'].set_xlim(xmin=self.sb_params.get('extent')[0], xmax=self.sb_params.get('extent')[1])
        self.sb_params['ax'].set_ylim(ymin=self.sb_params.get('extent')[2], ymax=self.sb_params.get('extent')[3])

        if isinstance(self.Aruco, MarkerDetection):
            _ = self.Aruco.plot_aruco(self.sb_params['ax'], self.sb_params['marker'])
            # Update of legend
            self.sb_params['set_legend'](self.Aruco.legend_elements)
        self.lock.acquire()
        self.projector.trigger()
        self.lock.release()

    def load_frame(self, frame: numpy.ndarray = None, from_file: str=None):
        """
        During the sandbox thread, if you want to fix a frame but not interrupt the thread,
        load the desired numpy array here.
        This will change the flag self._loaded_frame = False to True in the update function and
        stop the sensor frame acquisition.
        # TODO: Make this compatible with DEM of differ shapes (e.g. bennisson DEM)
        To stop this, pass: frame = None or change the flag self._loaded_frame to False.
        Args:
            frame: numpy.ndarray: must be a matrix of desired resolution
            from_file: Path to DEM. Can be either .npz or .npy (internally normalized)
        Returns:

        """
        if frame is None and from_file is None:
            self._loaded_frame = False
            logger.info("No frame to load, resuming sandbox frame acquisition")
            return False

        if isinstance(from_file, str):
            try:
                file = numpy.load(from_file)
            except Exception:
                logger.error("%s as path not valid" % from_file, exc_info=True)
                return False
            if from_file.split(".")[1] == "npy":
                frame_new = self.normalize_topography(file, self.sensor.extent)
                self._loaded_frame = True
                self.previous_frame = frame_new
                logger.info("loaded .npy file")
                return True
            elif from_file.split(".")[1] == "npz":
                frame_new = file["arr_0"]
                frame_new = frame_new - frame_new.min()
                self._loaded_frame = True
                self.previous_frame = frame_new
                logger.info("loaded .npz file")
                return True
            else:
                logger.error("%s format not recognized. Please pass a .npy or .npz file" % from_file)
                return False

        if isinstance(frame, numpy.ndarray):
            self._loaded_frame = True
            self.previous_frame = frame
            logger.info("loaded")
            return True
        logger.error("Frame and path not valid: Frame -> %s, Path -> %s" % (frame, from_file))
        return False

    @staticmethod
    def normalize_topography(dem, target_extent):
        """
        # TODO: Multiple implementations. TopoModule and LoadSaveModule
        Normalize any size of numpy array to fit the sandbox frame.
        Useful when passing DEM with resolution bigger than sandbox sensor.
        Args:
            dem:
            target_extent: [minx, maxx, miny, maxy, vmin, vmax] ->
            [0, frame_width, 0, frame_height, vmin_sensor, vmax_sensor]
        Returns:
             normalized frame
        """
        # Change shape of numpy array to desired shape
        topo_changed = skimage.transform.resize(dem,
                                                (target_extent[3], target_extent[1]),
                                                order=3,
                                                mode='edge',
                                                anti_aliasing=True,
                                                preserve_range=False)

        topo_min = topo_changed.min()
        topo_max = topo_changed.max()
        # when the min value is not 0
        topo_changed = topo_changed - topo_min
        topo_changed = topo_changed * (target_extent[-1] - target_extent[-2]) / (topo_max - topo_min)

        return topo_changed

    def add_module(self, name: str, module):
        """Add an specific module to run the update in the main thread"""
        self.lock.acquire()
        self.modules[name] = module
        self._modules[name] = module
        self.lock.release()
        # self.modules.move_to_end(name, last=True)
        logger.info('module ' + name + ' added to modules')

    def remove_module(self, name: str):
        """Remove a current module from the main thread"""
        if name in self.modules.keys():
            self.lock.acquire()
            self.modules.pop(name)
            logger.info('module ' + name + ' removed')
            self.lock.release()
        else:
            logger.warning('No module with name ' + name + ' was found')

    def module_manager(self, active_modules: list = []):
        # add a module
        for name_module in active_modules:
            if name_module not in self.modules:
                self.add_module(name=name_module, module=self._modules[name_module])
        # delete the module
        if len(active_modules) > 0:
            [self.remove_module(name) for name in self.modules if name not in active_modules]
        # self._update_widget_module_selector()
        # if self._widget_module_selector is not None:
        #    self._widget_module_selector.value = list(self.modules.keys())
        #    self._widget_module_selector.options = list(self._modules.keys())

    def _update_widget_module_selector(self):
        if self._widget_module_selector is not None:
            self._widget_module_selector.value = list(self.modules.keys())
            self._widget_module_selector.options = list(self._modules.keys())


    async def thread_loop(self):
        while self.thread_status == 'running':
            self.update()
            await asyncio.sleep(0.1) #give other threads a chance to run

    def run(self):
        if self.thread_status != 'running':
            if _platform == "Linux":
                if self.sensor.s_name == "kinect_v2" or self.sensor.s_name == "lidar":
                    self.sensor.Sensor._run()
            self.thread_status = 'running'
            self.main_task = asyncio.create_task(self.thread_loop())
            #self.thread = threading.Thread(target=self.thread_loop, daemon=True, )
            #self.thread.start()
            logger.info('Thread started or resumed...')

        else:
            logger.info('Thread already running.')

    def stop(self):
        if self.thread_status is not 'stopped':
            if _platform == "Linux":
                if self.sensor.s_name == "kinect_v2" or self.sensor.s_name == "lidar":
                    self.sensor.Sensor._stop()
            self.thread_status = 'stopped'  # set flag to end thread loop
            #self.thread.join()  # wait for the thread to finish
            self.main_task.cancel()
            logger.info('Thread stopped.')
        else:
            logger.info('thread was not running.')

    def pause(self):
        if self.thread_status == 'running':
            self.thread_status = 'paused'  # set flag to end thread loop
            #self.thread.join()  # wait for the thread to finish
            self.main_task.cancel()
            logger.info('Thread paused.')
        else:
            logger.info('There is no thread running.')

    def resume(self):
        if self.thread_status != 'stopped':
            self.run()
        else:
            logger.info('Thread already stopped.')

    def widget_plot_module(self):
        if isinstance(self.Aruco, MarkerDetection):
            marker = pn.Column(self.widgets_aruco_visualization(), self.widget_thread_controller())
            widgets = pn.Column(self.cmap_frame.show_widgets(),
                                self.contours.show_widgets())
            rows = pn.Row(widgets, marker)
        else:
            widgets = pn.Column(self.cmap_frame.show_widgets(),
                                self.contours.show_widgets())
            rows = pn.Row(widgets, self.widget_thread_controller())

        panel1 = pn.Column("## Plotting interaction widgets", rows)
        self._update_widget_module_selector()

        panel2 = self.projector.show_widgets_sidepanels()

        panel = pn.Tabs(("Main frame controller", panel1),
                        ("Side panel controller", panel2))

        return panel

    def widget_thread_controller(self):
        panel = pn.Column("##<b>Thread Controller</b>",
                          self._widget_thread_selector,
                          self._widget_check_difference,
                          self._widget_module_selector,
                          self._widget_clear_axes,
                          self._widget_error_markdown
                          # self._widget_freeze_frame)
                          )
        return panel

    def _create_widgets(self):
        self._widget_thread_selector = pn.widgets.RadioButtonGroup(name='Thread controller',
                                                                   options=["Start", "Stop"],
                                                                   value="Start",
                                                                   button_type='success')
        self._widget_thread_selector.param.watch(self._callback_thread_selector, 'value', onlychanged=False)

        self._widget_check_difference = pn.widgets.Checkbox(name='Check changes in fame', value=self.check_change)
        self._widget_check_difference.param.watch(self._callback_check_difference, 'value',
                                                  onlychanged=False)

        self._widget_clear_axes = pn.widgets.Button(name="Clear axes from projector / refresh list",
                                                    button_type="warning")
        self._widget_clear_axes.param.watch(self._callback_clear_axes, 'clicks',
                                            onlychanged=False)

        self._widget_module_selector = pn.widgets.CrossSelector(name="Module manager",
                                                                value=list(self.modules.keys()),
                                                                options=list(self._modules.keys()),
                                                                definition_order=False)
        self._widget_module_selector.param.watch(self._callback_module_selector, 'value',
                                                 onlychanged=False)

    def _callback_clear_axes(self, event):
        self.projector.clear_axes()
        self._update_widget_module_selector()
        # if self._widget_module_selector is not None:
        #    self._widget_module_selector.value = list(self.modules.keys())
        #    self._widget_module_selector.options = list(self._modules.keys())

    def _callback_check_difference(self, event):
        self.check_change = event.new

    def _callback_module_selector(self, event):
        self.module_manager(event.new)

    def _callback_thread_selector(self, event):
        if event.new == "Start":
            self.run()
        elif event.new == "Stop":
            self.stop()

    def widgets_aruco_visualization(self):
        self._widget_aruco = pn.widgets.Checkbox(name='Aruco Detection', value=self.ARUCO_ACTIVE)
        self._widget_aruco.param.watch(self._callback_aruco, 'value',
                                       onlychanged=False)
        panel = pn.Column("## Activate aruco detection", self._widget_aruco, self.Aruco.widgets_aruco())
        return panel

    def _callback_aruco(self, event):
        self.ARUCO_ACTIVE = event.new



================================================
FILE: sandbox/sandbox_api.py
================================================
import panel as pn
import traceback
from sandbox import _calibration_dir, set_logger
import platform
logger = set_logger(__name__)
_platform = platform.system()

# Store the name of the sensor as a global variable, and the projector resolution
# so it can be used and changed in the same session for all the functions
name_sensor = "kinect_v2"
p_width = 1280
p_height = 800


def calibrate_projector():
    from sandbox.projector import Projector
    proj = Projector(use_panel=True)
    widget = proj.calibrate_projector()
    widget.show()
    return proj


def calibrate_sensor(calibprojector: str = _calibration_dir + "my_projector_calibration.json",
                     name: str = None):
    global name_sensor
    if name is None:
        name = name_sensor
    else:
        name_sensor = name
    from sandbox.sensor import CalibSensor
    module = CalibSensor(calibprojector=calibprojector, name=name)
    widget = module.calibrate_sensor()
    widget.show()
    return module.sensor


def start_server(calibprojector: str = None,  # _calibration_dir + "my_projector_calibration.json",
                 calibsensor: str = None,  # _calibration_dir + "my_sensor_calibration.json",
                 sensor_name: str = None,
                 aruco_marker: bool = True,
                 kwargs_external_modules: dict = {},
                 kwargs_gempy_module: dict = {},
                 kwargs_projector: dict = {},
                 kwargs_sensor: dict = {},
                 kwargs_aruco: dict = {},
                 ):
    global name_sensor, p_width, p_height
    if sensor_name is None:
        sensor_name = name_sensor
    else:
        name_sensor = sensor_name

    from sandbox.projector import Projector
    if kwargs_projector.get("p_width") is not None:
        p_width = kwargs_projector.get("p_width")
    if kwargs_projector.get("p_height") is not None:
        p_height = kwargs_projector.get("p_height")
    projector = Projector(calibprojector=calibprojector, use_panel=True, **kwargs_projector)

    from sandbox.sensor import Sensor
    sensor = Sensor(calibsensor=calibsensor, name=sensor_name, **kwargs_sensor)

    if aruco_marker:
        from sandbox.markers import MarkerDetection
        aruco = MarkerDetection(sensor=sensor, **kwargs_aruco)
    else:
        aruco = None

    module = Sandbox(sensor=sensor,
                     projector=projector,
                     aruco=aruco,
                     kwargs_gempy_module=kwargs_gempy_module,
                     kwargs_external_modules=kwargs_external_modules)

    module.start()

    return module


class Sandbox:
    """
    Wrapping API-class
    """

    def __init__(self,
                 sensor,  # : Sensor,
                 projector,  # : Projector,
                 aruco,  # : MarkerDetection = None,
                 kwargs_contourlines: dict = {},
                 kwargs_cmap: dict = {},
                 kwargs_external_modules: dict = {},
                 kwargs_gempy_module: dict = {},
                 ):
        self._gempy_import = False
        self._devito_import = False
        self._pygimli_import = False
        self._torch_import = False
        self._check_import(**kwargs_external_modules)

        self.sensor = sensor
        self._sensor_calib = self.sensor.json_filename
        self.projector = projector
        self._projector_calib = self.projector.json_filename
        self.aruco = aruco
        from sandbox.markers import MarkerDetection
        if isinstance(self.aruco, MarkerDetection):
            self._disable_aruco = False
            self.ARUCO_ACTIVE = True
        else:
            self._disable_aruco = True
            self.ARUCO_ACTIVE = False

        self.Modules = None
        self.module_active = False
        self.load_modules(kwargs_gempy_module=kwargs_gempy_module, **kwargs_external_modules)
        self.Main_Thread = self.start_main_thread(kwargs_contourlines=kwargs_contourlines,
                                                  kwargs_cmap=kwargs_cmap)
        self.lock = self.Main_Thread.lock
        logger.info('Sandbox server ready')

    def _check_import(self,
                      gempy_module: bool = False,
                      gimli_module: bool = False,
                      torch_module: bool = False,
                      devito_module: bool = False,
                      ):
        if gempy_module:
            try:  # Importing Gempy for GempyModule
                import gempy
                self._gempy_import = True
                del gempy
            except Exception as e:
                logger.warning(e, exc_info=True)

        if _platform == "Linux":
            if devito_module:
                try:  # Importing Devito for SeismicModule - Only working for Linux system
                    import devito
                    self._devito_import = True
                    del devito
                except Exception as e:
                    logger.warning(e, exc_info=True)
            else:
                _devito_import = False

        if gimli_module:
            try:  # Importing pygimli for GeoelectricsModule
                import pygimli
                self._pygimli_import = True
                del pygimli
            except Exception as e:
                logger.warning(e, exc_info=True)
        if torch_module:
            try:  # Importing pytorch for LandscapeGeneration
                import torch
                self._torch_import = True
                del torch
            except Exception as e:
                logger.warning(e, exc_info=True)

    def load_modules(self,
                     gempy_module: bool = False,
                     gimli_module: bool = False,
                     torch_module: bool = False,
                     devito_module: bool = False,
                     kwargs_gempy_module: dict = {},
                     ):
        from sandbox.modules import (TopoModule, GradientModule, LoadSaveTopoModule, LandslideSimulation,
                                     SearchMethodsModule)
        from sandbox.projector import ContourLinesModule, CmapModule
        self.Modules = {'ContourLinesModule': ContourLinesModule(extent=self.sensor.extent),
                        'CmapModule': CmapModule(extent=self.sensor.extent),
                        'TopoModule': TopoModule(extent=self.sensor.extent),
                        'GradientModule': GradientModule(extent=self.sensor.extent),
                        'LoadSaveTopoModule': LoadSaveTopoModule(extent=self.sensor.extent),
                        'LandslideSimulation': LandslideSimulation(extent=self.sensor.extent),
                        'SearchMethodsModule': SearchMethodsModule(extent=self.sensor.extent)}
        #self.Modules['SearchMethodsModule'].update_mesh(self.sensor.get_frame(),
        #                                                margins_crop=self.Modules['SearchMethodsModule'].margins_crop,
        #                                                fill_value=0)
        #self.Modules['SearchMethodsModule'].activate_frame_capture = False
        if gempy_module and self._gempy_import:
            from sandbox.modules.gempy import GemPyModule
            self.Modules['GemPyModule'] = GemPyModule(extent=self.sensor.extent,
                                                      box=self.sensor.physical_dimensions,
                                                      **kwargs_gempy_module)
        if devito_module and self._devito_import:
            from sandbox.modules.devito import SeismicModule
            self.Modules['SeismicModule'] = SeismicModule(extent=self.sensor.extent)

        if gimli_module and self._pygimli_import:
            from sandbox.modules.gimli import GeoelectricsModule
            self.Modules['GeoelectricsModule'] = GeoelectricsModule(extent=self.sensor.extent)

        if torch_module and self._torch_import:
            from sandbox.modules.pytorch import LandscapeGeneration
            self.Modules['LandscapeGeneration'] = LandscapeGeneration(extent=self.sensor.extent)

    def start_main_thread(self, kwargs_contourlines: dict = {}, kwargs_cmap: dict = {}):
        from sandbox.main_thread import MainThread
        thread = MainThread(sensor=self.sensor, projector=self.projector, aruco=self.aruco,
                            kwargs_contourlines=kwargs_contourlines, kwargs_cmap=kwargs_cmap)
        thread._modules = self.Modules
        thread.run()
        return thread

    def add_to_main_thread(self, module_name: str):
        if module_name in self.Modules:
            self.Main_Thread.add_module(module_name, self.Modules[module_name])
            try:
                new_tab = pn.Tabs((module_name, self.Modules[module_name].show_widgets()),
                                  ('Main Thread Controller', self.Main_Thread.widget_plot_module()))
                new_tab.show()
            except Exception as e:
                logger.error(e, exc_info=True)
        else:
            logger.warning('No module to add with name: %s' % module_name)

    def remove_from_main_thread(self, module_name: str = None):
        if module_name is not None:
            if module_name in self.Modules:
                self.Main_Thread.remove_module(module_name)
            else:
                logger.warning('No module to remove with name: %s' % module_name)
        else:
            # TODO: Is this the best way to delete the modules except the colormap and the contourlines?
            #all = self.Main_Thread.modules.keys()
            for name in list(self.Main_Thread.modules.keys()):
                if name != 'CmapModule' and name != 'ContourLinesModule':
                    self.Main_Thread.remove_module(name)
            self.projector.clear_axes()

    def start(self):
        #self.Main_Thread.run()
        self.show_widgets().show()
        self.Main_Thread._update_widget_module_selector()

    def _create_widgets(self):
        # Local Modules
        self._widget_main_thread = pn.widgets.Button(name="MainThread_Controllers", button_type="success")
        self._widget_main_thread.param.watch(self._callback_main_thread, 'clicks', onlychanged=False)

        self._widget_gradient = pn.widgets.Button(name="GradientModule", button_type="success")
        self._widget_gradient.param.watch(self._callback_gradient, 'clicks', onlychanged=False)

        self._widget_load_save_topo = pn.widgets.Button(name="LoadSaveTopoModule", button_type="success")
        self._widget_load_save_topo.param.watch(self._callback_load_save, 'clicks', onlychanged=False)

        self._widget_topo = pn.widgets.Button(name="TopoModule", button_type="success")
        self._widget_topo.param.watch(self._callback_topo, 'clicks', onlychanged=False)

        self._widget_landslide = pn.widgets.Button(name="LandslideSimulation", button_type="success")
        self._widget_landslide.param.watch(self._callback_landslide, 'clicks', onlychanged=False)

        self._widget_search = pn.widgets.Button(name="SearchMethodsModule", button_type="success")
        self._widget_search.param.watch(self._callback_search, 'clicks', onlychanged=False)

        # External Modules
        self._widget_gempy = pn.widgets.Button(name="GempyModule", button_type="success")
        self._widget_gempy.param.watch(self._callback_gempy, 'clicks', onlychanged=False)

        self._widget_pygimli = pn.widgets.Button(name="GeoelectricsModule", button_type="success")
        self._widget_pygimli.param.watch(self._callback_pygimli, 'clicks', onlychanged=False)

        self._widget_devito = pn.widgets.Button(name="SeismicModule", button_type="success")
        self._widget_devito.param.watch(self._callback_devito, 'clicks', onlychanged=False)

        self._widget_torch = pn.widgets.Button(name="LandscapeGeneration", button_type="success")
        self._widget_torch.param.watch(self._callback_torch, 'clicks', onlychanged=False)

        self._widget_calibration_projector = pn.widgets.FileInput(name="Load projector calibration", accept=".json")
        self._widget_calibration_projector.param.watch(self._callback_calibration_projector, 'value')

        self._widget_calibration_sensor = pn.widgets.FileInput(name="Load sensor calibration", accept=".json")
        self._widget_calibration_sensor.param.watch(self._callback_calibration_sensor, 'value')

        self._widget_create_calibration_projector = pn.widgets.Button(name="Calibrate projector", button_type="success")
        self._widget_create_calibration_projector.param.watch(self._callback_create_calibration_projector, 'clicks',
                                                              onlychanged=False)

        self._widget_create_calibration_sensor = pn.widgets.Button(name="Calibrate Sensor", button_type="success")
        self._widget_create_calibration_sensor.param.watch(self._callback_create_calibration_sensor, 'clicks',
                                                           onlychanged=False)

        self._widget_new_server = pn.widgets.Button(name="New Server", button_type="warning")
        self._widget_new_server.param.watch(self._callback_new_server, 'clicks', onlychanged=False)

        self._widget_thread_selector = pn.widgets.RadioButtonGroup(name='Thread controller',
                                                                   options=["Start", "Stop"],
                                                                   value="Start",
                                                                   button_type='success')
        self._widget_thread_selector.param.watch(self._callback_thread_selector, 'value', onlychanged=False)

        self._widget_aruco = pn.widgets.Checkbox(name='Aruco Detection', value=self.ARUCO_ACTIVE,
                                                 disabled=self._disable_aruco)
        self._widget_aruco.param.watch(self._callback_aruco, 'value',
                                       onlychanged=False)

        return True

    def show_widgets(self):
        self._create_widgets()
        widgets = pn.Column("# Module selector",
                            self._widget_main_thread,
                            '<b>Select the module you want to show the widgets and start </b>',
                            self._widget_topo,
                            self._widget_gradient,
                            self._widget_load_save_topo,
                            self._widget_landslide,
                            self._widget_search,
                            '<b>External modules</b>',
                            self._widget_gempy if self.Modules.get('GemPyModule') is not None else None,
                            self._widget_pygimli if self.Modules.get('GeoelectricsModule') is not None else None,
                            self._widget_devito if self.Modules.get('SeismicModule') is not None else None,
                            self._widget_torch if self.Modules.get('LandscapeGeneration') is not None else None,
                            '<b>Change the calibration file</b>',
                            pn.WidgetBox('Projector',
                                         self._widget_calibration_projector,
                                         'Sensor',
                                         self._widget_calibration_sensor),
                            '<b>Create new projector calibration file</b>',
                            self._widget_create_calibration_projector,
                            '<b>Create new sensor calibration file</b>',
                            self._widget_create_calibration_sensor,
                            )
        thread = pn.Column("##<b>Thread Controller</b>",
                           self._widget_thread_selector,
                           '<b>Start a new server</b>',
                           self._widget_new_server,
                           "<b>Deactivate or activate aruco detection</b>",
                           self._widget_aruco,
                           "<b>Manager of all modules</b>",
                           self.Main_Thread._widget_module_selector,
                           self.Main_Thread._widget_clear_axes,
                           self.Main_Thread._widget_error_markdown)

        panel = pn.Row(widgets, thread)

        return panel

    def _callback_main_thread(self, event):
        self.Main_Thread.widget_plot_module().show()

    def _callback_gradient(self, event):
        #self.remove_from_main_thread()
        self.add_to_main_thread('GradientModule')

    def _callback_load_save(self, event):
        #self.remove_from_main_thread()
        self.add_to_main_thread('LoadSaveTopoModule')

    def _callback_topo(self, event):
        #self.remove_from_main_thread()
        self.add_to_main_thread('TopoModule')

    def _callback_landslide(self, event):
        #self.remove_from_main_thread()
        self.add_to_main_thread('LandslideSimulation')

    def _callback_search(self, event):
        #self.remove_from_main_thread()
        self.add_to_main_thread('SearchMethodsModule')

    def _callback_gempy(self, event):
        #self.remove_from_main_thread()
        self.add_to_main_thread('GemPyModule')

    def _callback_pygimli(self, event):
        self.add_to_main_thread('GeoelectricsModule')

    def _callback_devito(self, event):
        self.add_to_main_thread('SeismicModule')

    def _callback_torch(self, event):
        self.add_to_main_thread('LandscapeGeneration')

    def _callback_calibration_projector(self, event):
        global p_width, p_height
        data_bytes = event.new
        data_decode = data_bytes.decode()
        self._projector_calib = data_decode
        self.projector.__init__(data_decode, p_width=p_width, p_height=p_height)
        self.Main_Thread.projector = self.projector

    def _callback_calibration_sensor(self, event):
        global name_sensor
        data_bytes = event.new
        data_decode = data_bytes.decode()
        self._sensor_calib = data_decode
        self.sensor.__init__(data_decode, name=name_sensor)
        self.Main_Thread.sensor = self.sensor

    def _callback_create_calibration_projector(self, event):
        self.projector = calibrate_projector()
        self.Main_Thread.projector = self.projector

    def _callback_create_calibration_sensor(self, event):
        self.Main_Thread.stop()
        self.sensor = calibrate_sensor()
        self.Main_Thread.sensor = self.sensor

    def _callback_new_server(self, event):
        global p_width, p_height
        self.projector.__init__(self._projector_calib, p_width=p_width, p_height=p_height)
        self.Main_Thread.projector = self.projector

    def _callback_thread_selector(self, event):
        if event.new == "Start":
            self.Main_Thread.run()
        elif event.new == "Stop":
            self.Main_Thread.stop()

    def _callback_aruco(self, event):
        self.Main_Thread.ARUCO_ACTIVE = event.new















================================================
FILE: sandbox/markers/__init__.py
================================================
from .aruco import ArucoMarkers
from .markers_plotting import MarkerDetection

if __name__ == '__main__':
    pass



================================================
FILE: sandbox/markers/aruco.py
================================================
from warnings import warn
import matplotlib.pyplot as plt
import numpy
from scipy.spatial.distance import cdist
from .dummy_aruco import dummy_markers_in_frame
import pandas as pd
from sandbox import set_logger
logger = set_logger(__name__)

pd.options.mode.chained_assignment = None
# default='warn' # TODO: SettingWithCopyWarning appears when using LoadTopoModule with arucos

try:
    import cv2
    from cv2 import aruco
    CV2_IMPORT = True
except ImportError:
    CV2_IMPORT = False
    logger.warning('opencv is not installed. Object detection will not work', exc_info=True)


class ArucoMarkers(object):  # TODO: Include widgets to calibrate arucos
    """
    class to detect Aruco markers in the kinect data (IR and RGB)
    An Area of interest can be specified, markers outside this area will be ignored
    """

    def __init__(self, sensor=None, aruco_dict=None, **kwargs):
        if not aruco_dict:
            if CV2_IMPORT:
                self.aruco_dict = aruco.DICT_4X4_50  # set the default dictionary here
            else:
                self.aruco_dict = None
        else:
            self.aruco_dict = aruco_dict
        # self.area = area  # TODO: set a square Area of interest here (Hot-Area). Need it?
        if sensor is not None:
            if hasattr(sensor.Sensor, "name"):
                name = sensor.Sensor.name
                if name == "dummy":
                    self.kinect = "dummy"
                    logger.info("Using dummy arucos. "
                                "Create your own aruco positions using .set_aruco_position() function")
                elif name == "kinect_v2":
                    self.kinect = sensor.Sensor
                    self.calib = sensor
                    logger.info("KinectV2 loaded")
                elif name == "lidar":
                    self.kinect = sensor.Sensor
                    self.calib = sensor
                    logger.info("LiDAR loaded")
                else:
                    self.kinect = "dummy"
                    logger.warning("%s not recognized as supported sensor for aruco detection. "
                                "Using dummy arucos" % name)
            else:
                if sensor == "dummy":
                    logger.info("Using dummy arucos. "
                                "Create your own aruco positions using .set_aruco_position() function")
                else:
                    logger.warning("No sensor loaded. Detection will only work in color image. Using dummy arucos")
                self.kinect = "dummy"

        self.ir_markers = None
        # if self.calib is not None:
        #    if self.calib.aruco_corners is not None:
        #        self.rgb_markers = pd.read_json(self.calib.aruco_corners)
        #    else:
        #        self.rgb_markers = None
        self.projector_markers = None
        self.dict_markers_current = None  # markers that were detected in the last frame
        # self.dict_markers_all = all markers ever detected with their last known position and timestamp
        self.dict_markers_all = self.dict_markers_current

        self.middle = None
        self.corner_middle = None
        self.point_markers = None

        # dataframes and variables used in the update loop:
        self.markers_in_frame = pd.DataFrame()
        self.aruco_markers = pd.DataFrame()
        self._threshold = 10.0

        # Pose Estimation
        self.mtx = numpy.array([[1977.4905366892494, 0.0, 547.6845435554575],  # Hardcoded distortion parameters
                                [0.0, 2098.757943278828, 962.426967248953],
                                [0.0, 0.0, 1.0]])
        self.dist = numpy.array([[-0.1521704243263453],  # Hard-coded distortion parameters
                                 [-0.5137710352422746],
                                 [-0.010673768065933672],
                                 [0.01065954734833698],
                                 [2.2812034123550817],
                                 [0.15820606213404878],
                                 [0.5618247374672848],
                                 [-2.195963638734801],
                                 [0.0],
                                 [0.0],
                                 [0.0],
                                 [0.0],
                                 [0.0],
                                 [0.0]])
        self._size_of_marker = 0.02  # size of aruco markers in meters
        self._length_of_axis = 0.05  # length of the axis drawn on the frame in meters

        # Automatic calibration #TODO: Deprecated?
        # self.load_corners_ids()
        init_correction_x = 20
        init_correction_y = -80
        self.set_xy_correction(init_correction_x, init_correction_y)
        logger.info('Aruco module loaded')

    def set_xy_correction(self, x: int, y: int):
        self.CoordinateMap = pd.DataFrame()
        if self.kinect == "dummy":
            self.CoordinateMap = None
            logger.info('using dummy aruco module')
            return
        if self.kinect.name == "kinect_v2":
            import platform
            _platform = platform.system()
            if _platform == "Linux":
                from sandbox.markers.aruco_linux import start_mapping, set_correction
                # TODO: correction in x and y direction for the mapping between color space and depth space
                self._correction_x = x
                self._correction_y = y
                set_correction(self._correction_x, self._correction_y)
                while len(self.CoordinateMap) < 5:
                    self.CoordinateMap = start_mapping(self.kinect)
            elif _platform == "Windows":
                from sandbox.markers.aruco_windows import start_mapping, set_correction
                # TODO: correction in x and y direction for the mapping between color space and depth space
                self._correction_x = x
                self._correction_y = y
                set_correction(self._correction_x, self._correction_y)
                while len(self.CoordinateMap) < 5:
                    self.CoordinateMap = start_mapping(self.kinect)
            else:
                logger.warning("%s not supported" % _platform)
        elif self.kinect.name == "lidar":
            from sandbox.markers.lidar_aruco import start_mapping, set_correction
            self._correction_x = x
            self._correction_y = y
            set_correction(self._correction_x, self._correction_y)
            while len(self.CoordinateMap) < 5:
                self.CoordinateMap = start_mapping(self.kinect)
        else:
            logger.warning("%s Not supported for aruco detection" % self.kinect.name)

    def aruco_detect(self, image):
        """ Function to detect an aruco marker in a color image
        Args:
            image: numpy array containing a color image (BGR type)
        Returns:
            corners: x, y location of a detected aruco marker(detect the 4 corners of the aruco)
            ids: id of the detected aruco
            rejectedImgPoints: show x, y coordinates of searches for aruco markers but not successful
       """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        aruco_dict = aruco.Dictionary_get(self.aruco_dict)
        parameters = aruco.DetectorParameters_create()
        corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)
        return corners, ids, rejectedImgPoints

    def get_location_marker(self, corners):
        """Get the middle position from the detected corners
         Args:
             corners: List containing the position x, y of the aruco marker
         Returns:
             pr1: x location
             pr2: y location
        """
        pr1 = int(numpy.mean(corners[:, 0]))
        pr2 = int(numpy.mean(corners[:, 1]))
        return pr1, pr2

    def search_aruco(self, frame: numpy.ndarray = None, **kwargs) -> pd.DataFrame:
        """
        searches for aruco markers in the current kinect image and writes detected markers to
        self.markers_in_frame. call this first in the update function.
        Args
            frame: gets the color frame to search the markers on
        Returns
            markers_in_frame
        """
        if self.kinect == "dummy":
            dict_position = kwargs.get("dict_position")
            depth_frame = kwargs.get("depth_frame")
            plt.pause(0.15)  # TODO: To avoid problems with the common issue #3 of NoneType dpi
            self.markers_in_frame = dummy_markers_in_frame(dict_position, depth_frame)
            return self.markers_in_frame

        if frame is None:
            frame = self.kinect.get_color()
        corners, ids, rejectedImgPoints = self.aruco_detect(frame)
        if ids is not None:
            labels = {"ids", "x", "y", "Counter"}
            df = pd.DataFrame(columns=labels)
            for j in range(len(ids)):
                if ids[j] not in df.ids.values:
                    x_loc, y_loc = self.get_location_marker(corners[j][0])
                    df_temp = pd.DataFrame(
                        {"ids": [ids[j][0]], "x": [x_loc], "y": [y_loc]})
                    df = pd.concat([df, df_temp], sort=False)

            df = df.reset_index(drop=True)
            self.markers_in_frame = self.convert_color_to_depth(None, self.CoordinateMap, data=df)
            self.markers_in_frame.insert(0, 'counter', 0)
            self.markers_in_frame.insert(1, 'box_x', numpy.NaN)
            self.markers_in_frame.insert(2, 'box_y', numpy.NaN)
            self.markers_in_frame.insert(0, 'is_inside_box', numpy.NaN)
            self.markers_in_frame = self.markers_in_frame.set_index(self.markers_in_frame['ids'], drop=True)
            self.markers_in_frame = self.markers_in_frame.drop(columns=['ids'])
        else:
            labels = {"ids", "x", "y", "Counter"}
            self.markers_in_frame = pd.DataFrame(columns=labels)
        return self.markers_in_frame

    def update_marker_dict(self):
        """
        updates existing marker points in self.aruco_markers. new found markers are automatically added.
        A marker that is not detected for more than *self._threshold* frames is removed from the list.
        call in update after self.search_aruco():
        Returns:
            changes in place
        """
        for j in self.markers_in_frame.index:
            if j not in self.aruco_markers.index:
                # add new aruco
                self.aruco_markers = self.aruco_markers.append(self.markers_in_frame.loc[j])
            else:
                # Update aruco
                df_temp = self.markers_in_frame.loc[j]
                self.aruco_markers.at[j] = df_temp

        for i in self.aruco_markers.index:  # increment counter for not found arucos
            if i not in self.markers_in_frame.index:
                self.aruco_markers.at[i, 'counter'] += 1.0

            if self.aruco_markers.loc[i]['counter'] >= self._threshold:
                self.aruco_markers = self.aruco_markers.drop(i)

        # return self.aruco_markers

    def transform_to_box_coordinates(self):
        """
        checks if aruco markers are within the dimensions of the sandbox (boolean: is_inside_box)
        and converts the location to box coordinates x,y. call after self.update_markers in the update loop
        Returns:
        """
        if self.kinect == "dummy":
            if len(self.aruco_markers) > 0:
                self.aruco_markers['is_inside_box'] = self.aruco_markers['is_inside_box'].astype('bool')
            return

        if len(self.aruco_markers) > 0:
            self.aruco_markers['box_x'] = self.aruco_markers['Depth_x'] - self.calib.s_left
            self.aruco_markers['box_y'] = self.calib.s_height - self.aruco_markers['Depth_y'] - self.calib.s_bottom
            for j in self.aruco_markers.index:
                self.aruco_markers['is_inside_box'].loc[j] = \
                    self.calib.s_frame_width > (self.aruco_markers['Depth_x'].loc[j] - self.calib.s_left) and \
                    (self.aruco_markers['Depth_x'].loc[j] - self.calib.s_left) > 0 and \
                    (self.calib.s_frame_height > (self.calib.s_height - self.aruco_markers['Depth_y'].loc[j] -
                                                  self.calib.s_bottom) and \
                     (self.calib.s_height - self.aruco_markers['Depth_y'].loc[j] - self.calib.s_bottom) > 0)

    ############### Utilities ########################

    def find_markers_ir(self, IR=None, amount=None):
        """ Function to search for a determined amount of arucos in the infrared image. It will continue searching in
        different frames of the image until it finds all the markers
        Args:
            IR= search in the infrared frame. If None then captures a new frame
            amount: specify the number of arucos to search
        Returns:
            ir_marker: DataFrame with the id, x, y coordinates for the location of the aruco
                        And rotation and translation vectors for the pos estimation
        """
        labels = {'ids', 'Corners_IR_x', 'Corners_IR_y', "Rotation_vector", "Translation_vector"}
        df = pd.DataFrame(columns=labels)

        if amount is not None:
            while len(df) < amount:

                minim = 0
                maxim = numpy.arange(1000, 30000, 500)
                if IR is None:
                    IR = self.kinect.get_ir_frame_raw()
                for i in maxim:
                    ir_use = numpy.interp(IR, (minim, i), (0, 255)).astype('uint8')
                    ir3 = numpy.stack((ir_use, ir_use, ir_use), axis=2)
                    corners, ids, rejectedImgPoints = self.aruco_detect(ir3)

                    if not ids is None:
                        for j in range(len(ids)):
                            if ids[j] not in df.ids.values:
                                rvec, tvec, trash = aruco.estimatePoseSingleMarkers([corners[j][0]],
                                                                                    self._size_of_marker,
                                                                                    self.mtx, self.dist)
                                x_loc, y_loc = self.get_location_marker(corners[j][0])
                                df_temp = pd.DataFrame(
                                    {'ids': [ids[j][0]], 'Corners_IR_x': [x_loc], 'Corners_IR_y': [y_loc],
                                     "Rotation_vector": [rvec], "Translation_vector": [tvec]})
                                df = pd.concat([df, df_temp], sort=False)

        self.ir_markers = df.reset_index(drop=True)
        return self.ir_markers

    def find_markers_rgb(self, color=None, amount=None):
        """ Function to search for a determined amount of arucos in the color image. It will continue searching in
        different frames of the image until it finds all the markers
        Args:
            color: search in the color frame. If None then captures a new frame
            amount: specify the number of arucos to search
        Returns:
            rgb_markers: DataFrame with the id, x, y coordinates for the location of the aruco
                        and rotation and translation vectors for the pos estimation
        """

        labels = {"ids", "Corners_RGB_x", "Corners_RGB_y", "Rotation_vector", "Translation_vector"}
        df = pd.DataFrame(columns=labels)

        if amount is not None:
            while len(df) < amount:
                if color is None:
                    color = self.kinect.get_color()
                corners, ids, rejectedImgPoints = self.aruco_detect(color)

                if not ids is None:
                    for j in range(len(ids)):
                        if ids[j] not in df.ids.values:
                            rvec, tvec, trash = aruco.estimatePoseSingleMarkers([corners[j][0]], self._size_of_marker,
                                                                                self.mtx, self.dist)
                            x_loc, y_loc = self.get_location_marker(corners[j][0])
                            df_temp = pd.DataFrame(
                                {"ids": [ids[j][0]], "Corners_RGB_x": [x_loc], "Corners_RGB_y": [y_loc],
                                 "Rotation_vector": [rvec], "Translation_vector": [tvec]})
                            df = pd.concat([df, df_temp], sort=False)

        self.rgb_markers = df.reset_index(drop=True)
        return self.rgb_markers

    def find_markers_projector(self, color=None, amount=None):
        """ Function to search for a determined amount of arucos in the projected image. It will continue searching in
        different frames of the image until it finds all the markers
        Args:
            color: search in the color frame. If None then captures a new frame
            amount: specify the number of arucos to search
        Returns:
            projector_markers: DataFrame with the id, x, y coordinates for the location of the aruco
                                and rotation and translation vectors for the pos estimation
            corner_middle: list that include the location of the central corner aruco with id=20
        """

        labels = {"ids", "Corners_projector_x", "Corners_projector_y", "Rotation_vector", "Translation_vector"}
        df = pd.DataFrame(columns=labels)

        if amount is not None:
            while len(df) < amount:
                if color is None:
                    color = self.kinect.get_color()
                corners, ids, rejectedImgPoints = self.aruco_detect(color)

                if ids is not None:
                    for j in range(len(ids)):
                        if ids[j] == 20:
                            # predefined id value to coincide with the projected aruco for the automatic calibration
                            # method used to calculate the scaling factor
                            self.corner_middle = corners[j][0]
                        if ids[j] not in df.ids.values:
                            rvec, tvec, trash = aruco.estimatePoseSingleMarkers([corners[j][0]], self._size_of_marker,
                                                                                self.mtx, self.dist)
                            x_loc, y_loc = self.get_location_marker(corners[j][0])
                            df_temp = pd.DataFrame(
                                {"ids": [ids[j][0]], "Corners_projector_x": [x_loc], "Corners_projector_y": [y_loc],
                                 "Rotation_vector": [rvec], "Translation_vector": [tvec]})
                            df = pd.concat([df, df_temp], sort=False)

        self.projector_markers = df.reset_index(drop=True)

        return self.projector_markers, self.corner_middle

    def create_aruco_marker(self, id: int = 1, resolution: int = 50, show: bool = False,
                            save: bool = False, path: str = './',
                            fig_filename = None):
        """ Function that creates a single aruco marker providing its id and resolution
        Args:
            id: int indicating the id of the aruco to create
            resolution: int
            show: boolean. Display the created aruco marker
            save: boolean. save the created aruco marker as an image "Aruco_Markers.jpg"
            path: path to where the aruco will be saved. If none specified will be saved in the same direcory of execution the code
            :param fig_filename: filename of arcuo file
        Returns:
            ArucoImage: numpy array with the aruco information

        """
        self.ArucoImage = 0

        aruco_dictionary = aruco.Dictionary_get(self.aruco_dict)
        img = aruco.drawMarker(aruco_dictionary, id, resolution)
        fig, ax = plt.subplots()
        ax.imshow(img, cmap=plt.cm.gray, interpolation="nearest")
        ax.axis("off")
        if show is True:
            fig.show()
        else:
            plt.close(fig)

        if save is True:
            if fig_filename is None:
                fig.savefig(path + "Aruco_Markers.png")
            else:
                fig.savefig(path + fig_filename)

        self.ArucoImage = img
        return self.ArucoImage

    def create_arucos_pdf(self, nx: int = 5, ny: int = 5, resolution: int = 50, path: str = './'):
        """
        Function to create a pdf file with nx X ny number of arucos and save them in specified path
        Args:
            nx: number of rows
            ny: number of columns
            resolution: resolution of the image (arucos)
            path: path to where the aruco will be saved. If none specified will be saved in the same direcory of execution the code
        Returns:
            image of the arucos and the saved pdf
        """
        aruco_dictionary = aruco.Dictionary_get(self.aruco_dict)
        fig = plt.figure()
        for i in range(1, nx * ny + 1):
            ax = fig.add_subplot(ny, nx, i)
            img = aruco.drawMarker(aruco_dictionary, i, resolution)
            ax.imshow(img, cmap='gray')
            ax.axis("off")
        fig.savefig(path + "markers.pdf")
        fig.show()
        return fig

    def plot_aruco_location(self, string_kind='RGB'):
        """ Function to visualize the location of the detected aruco markers in the image.
        Args:
            string_kind: IR -> Infrared detection of aruco and visualization in infrared image
                         RGB -> Detection of aruco in color space and visualization as color image
                         Projector -> Detection of projected arucos inside sandbox and visualization in color image
        Returns:
            image plot
        """
        plt.figure(figsize=(20, 20))
        if string_kind == 'IR':
            plt.imshow(self.kinect.get_ir_frame(), cmap="gray")
            plt.plot(self.ir_markers["Corners_IR_x"], self.ir_markers["Corners_IR_y"], "or")
            plt.show()
        elif string_kind == 'Projector':
            plt.imshow(self.kinect.get_color(), cmap="gray")
            plt.plot(self.projector_markers["Corners_projector_x"],
                     self.projector_markers["Corners_projector_y"], "or")
            plt.show()
        elif string_kind == 'RGB':
            # color = self.kinect.get_color()
            # color = color[self.kinect.calib.s_bottom:-self.kinect.calib.s_top,
            #       self.kinect.calib.s_left:-self.kinect.calib.s_right]
            plt.imshow(self.kinect.get_color())
            plt.plot(self.rgb_markers["Corners_RGB_x"], self.rgb_markers["Corners_RGB_y"], "or")
            plt.show()
        else:
            logger.warning('Select Type of projection -> IR, RGB or Projector')

    def convert_color_to_depth(self, ids, map, strg=None, data=None):
        """ Function to search in the previously created CoordinateMap - "create_CoordinateMap()" - the position of any
        detected aruco marker from the color space to the depth space.
        Args:
            strg: "Proj" or "Real". Select which type of aruco want to be converted
            ids: int. indicate the id of the aruco that want to be converted
            map: DataFrame. From the create_CoordinateMap() function
            data:
        Returns:
            value: Return the line from the CoordinateMap DataFrame showing the equivalence of its position in the color
            space to the depth space
        """
        color_data = map[['Color_x', 'Color_y']]
        if strg is not None:
            if strg == 'Proj':
                rgb = self.projector_markers
                rgb2 = rgb.loc[rgb['ids'] == ids]
                x_rgb = int(rgb2.Corners_projector_x.values)
                y_rgb = int(rgb2.Corners_projector_y.values)
            elif strg == 'Real':
                rgb = self.rgb_markers
                rgb2 = rgb.loc[rgb['ids'] == ids]
                x_rgb = int(rgb2.Corners_RGB_x.values)
                y_rgb = int(rgb2.Corners_RGB_y.values)

            distance = cdist([[x_rgb, y_rgb]], color_data)
            sorted_val = numpy.argsort(distance)[:][0]
            value = map.loc[sorted_val[0]]

        else:
            value = pd.DataFrame()
            if data is not None:
                for i in range(len(data)):
                    x_loc = data.loc[i].x
                    y_loc = data.loc[i].y

                    distance = cdist([[x_loc, y_loc]], color_data)
                    sorted_val = numpy.argsort(distance)[:][0]
                    value_i = pd.DataFrame(map.loc[sorted_val[0]]).T
                    value_i.insert(0, 'ids', data.loc[i].ids)
                    value = pd.concat([value, value_i], sort=False)

        return value

    def location_points(self, amount=None, plot=True):
        """ Function to search for a determined amount of arucos to introduce as a data point to the depth space
        Args:
            amount: specify the number of arucos to search
            plot: boolean to show the plot on color space and depth space if the mapped values are right
        Returns:
            point_markers: DataFrame with the id, x, y coordinates for the location of the aruco
        """
        labels = {"ids", "x", "y"}
        df = pd.DataFrame(columns=labels)

        if amount is not None:
            while len(df) < amount:
                frame = self.kinect.get_color()
                color = frame  # [self.rgb_markers.Corners_RGB_y.min():self.rgb_markers.Corners_RGB_y.max(),
                # self.rgb_markers.Corners_RGB_x.min():self.rgb_markers.Corners_RGB_x.max()]
                corners, ids, rejectedImgPoints = self.aruco_detect(color)

                if ids is not None:
                    for j in range(len(ids)):
                        if ids[j] not in df.ids.values:
                            x_loc, y_loc = self.get_location_marker(corners[j][0])
                            df_temp = pd.DataFrame({"ids": [ids[j][0]], "x": [x_loc], "y": [y_loc]})
                            df = pd.concat([df, df_temp], sort=False)

        df = df.reset_index(drop=True)
        self.point_markers = self.convert_color_to_depth(None, self.CoordinateMap, data=df)

        self.point_markers = self.point_markers.set_index(pd.Index(numpy.arange(len(self.point_markers))))

        if plot:
            color_crop = self.kinect.get_color()
            depth_crop = self.kinect.get_ir_frame()
            plt.figure(figsize=(20, 20))
            plt.subplot(2, 1, 1)
            plt.imshow(color_crop)
            plt.plot(self.point_markers.Color_x, self.point_markers.Color_y, "or")

            plt.subplot(2, 1, 2)
            plt.imshow(depth_crop)
            plt.plot(self.point_markers.Depth_x, self.point_markers.Depth_y, "or")
            plt.xlim(self.calib.s_left, depth_crop.shape[1] - self.calib.s_right)
            plt.ylim(depth_crop.shape[0] - self.calib.s_bottom, self.calib.s_top)
            plt.show()

        return self.point_markers

    def calibrate_camera_charucoBoard(self):
        """
        Method to obtain the camera intrinsic parameters to perform the aruco pose estimation
        Args:
        Returns:
            mtx: cameraMatrix Output 3x3 floating-point camera matrix
            dist: Output vector of distortion coefficient
            rvecs: Output vector of rotation vectors (see Rodrigues ) estimated for each board view
            tvecs: Output vector of translation vectors estimated for each pattern view.
        """

        aruco_dict = aruco.Dictionary_get(self.aruco_dict)
        board = aruco.CharucoBoard_create(7, 5, 1, .8, aruco_dict)
        images = []
        logger.info('Start moving randomly the aruco board')
        n = 400  # number of frames
        for i in range(n):
            frame = self.kinect.get_color()
            images.append(frame)
        logger.info("Stop moving the board")
        img_frame = numpy.array(images)[0::5]

        logger.info("Calculating Aruco location of %s images" % str(img_frame.shape[0]))
        allCorners = []
        allIds = []
        decimator = 0

        for im in img_frame:
            # print("=> Processing image {0}".format(im))
            # frame = cv2.imread(im)
            gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
            res = cv2.aruco.detectMarkers(gray, aruco_dict)

            if len(res[0]) > 0:
                res2 = cv2.aruco.interpolateCornersCharuco(res[0], res[1], gray, board)
                if res2[1] is not None and res2[2] is not None and len(res2[1]) > 3 and decimator % 1 == 0:
                    allCorners.append(res2[1])
                    allIds.append(res2[2])

            decimator += 1
        imsize = gray.shape
        logger.info("Finish")

        logger.info("Calculating camera parameters")
        cameraMatrixInit = numpy.array([[2000., 0., imsize[0] / 2.],
                                        [0., 2000., imsize[1] / 2.],
                                        [0., 0., 1.]])

        distCoeffsInit = numpy.zeros((5, 1))
        flags = (cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_RATIONAL_MODEL)
        ret, mtx, dist, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors = \
            cv2.aruco.calibrateCameraCharucoExtended(
                charucoCorners=allCorners,
                charucoIds=allIds,
                board=board,
                imageSize=imsize,
                cameraMatrix=cameraMatrixInit,
                distCoeffs=distCoeffsInit,
                flags=flags,
                criteria=(cv2.TERM_CRITERIA_EPS & cv2.TERM_CRITERIA_COUNT, 10000, 1e-9)
            )

        logger.info("Finish")

        self.calib.camera_mtx = mtx.tolist()
        self.calib.camera_dist = dist.tolist()

        return mtx, dist, rvecs, tvecs

    def real_time_poseEstimation(self):
        """
        Method that display real time detection of the aruco markers with the pose estimation and id of each
        Returns:
        """
        cv2.namedWindow("Aruco")
        # frame = self.kinect.get_color()
        frame = self.kinect.get_color()  # [270:900,640:1400]
        rval = True

        while rval:
            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
            parameters = aruco.DetectorParameters_create()
            aruco_dict = aruco.Dictionary_get(self.aruco_dict)
            corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)
            if ids is not None:
                frame = aruco.drawDetectedMarkers(frame, corners, ids)
                # side lenght of the marker in meter
                rvecs, tvecs, trash = aruco.estimatePoseSingleMarkers(corners, self._size_of_marker, self.mtx,
                                                                      self.dist)
                for i in range(len(tvecs)):
                    frame = aruco.drawAxis(frame, self.mtx, self.dist, rvecs[i], tvecs[i], self._length_of_axis)

            cv2.imshow("Aruco", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
            # frame = self.kinect.get_color()
            frame = self.kinect.get_color()  # [270:900,640:1400]

            key = cv2.waitKey(20)
            if key == 27:  # exit on ESC
                break

        cv2.destroyWindow("Aruco")

    def drawPoseEstimation(self, df, frame):
        """
        Method that draws over the frame the coordinate system of each aruco marker in relation to the camera space
        Args:
            df: data frame containing the information of the tranlation and rotation vectors previously detected
            frame: frame to draw the coordinate sytems
        Returns:
            frame: with the resulting coordinate system

        """
        for i in range(len(df)):
            frame = aruco.drawAxis(frame,
                                   self.mtx,
                                   self.dist,
                                   df.loc[i].Rotation_vector[0],
                                   df.loc[i].Translation_vector[0],
                                   self._length_of_axis)
        return frame.get()

    def p_arucoMarker(self):
        """ Method to create an empty frame including 2 aruco markers.
        one in the upper left corner
        second one in the central part of the image.
        The id of the left-upper aruco is determined by the aruco position in the corner with resolution of 50
        The id in the center of the image is set to be 20 and resolution of 100
        Returns:
            Frame as numpy array with the information of the aruco markers
        """
        width = self.calib.p_frame_width
        height = self.calib.p_frame_height

        # Creation of the aruco images as numpy array with size of resolution
        img_LU = self.create_aruco_marker(id=self.corner_id_LU, resolution=50)
        img_c = self.create_aruco_marker(id=self.center_id, resolution=100)

        # creation of empty numpy array with the size of the frame projected
        god = numpy.zeros((height, width))
        god.fill(255)

        # Placement of aruco markers in the image.
        # The Left upper aruco will be placed with a constant offset distance in x and y from the corner
        god[height - img_LU.shape[0] - self.offset:height - self.offset, self.offset:img_LU.shape[1] + self.offset] = \
            numpy.flipud(img_LU)
        # The central aruco will be placed exactly in the middle of the image
        god[int(height / 2) - int(img_c.shape[0] / 2):
            int(height / 2) + int(img_c.shape[0] / 2),
            int(width / 2) - int(img_c.shape[0] / 2):
            int(width / 2) + int(img_c.shape[0] / 2)] = numpy.flipud(img_c)

        return god

    def move_image(self):
        """ Method to determine the distances between the aruco position in the corner of the sandbox in relation
        with the projected frame and the projected aruco marker.
        Returns:
            p_frame_left: new value to update the calib.p_frame_left
            p_frame_top: new value to update the calib.p_frame_top
            p_frame_width: new value to update the calib.p_frame_width
            p_frame_height: new value to update the calib.p_frame_height
        """

        # Find the 2 corners of the projection
        df_p, corner = self.find_markers_projector(amount=2)
        # save the location of the aruco from the calibration file
        df_r = self.aruco_corners

        # extract the position x and y of the projected aruco
        x_p = int(df_p.loc[df_p.ids == self.corner_id_LU].Corners_projector_x.values)
        y_p = int(df_p.loc[df_p.ids == self.corner_id_LU].Corners_projector_y.values)

        # extract the position x and y of the corner sandbox where the projected aruco should be
        x_r = int(df_r.loc[df_r.ids == self.corner_id_LU].Color_x.values)
        y_r = int(df_r.loc[df_r.ids == self.corner_id_LU].Color_y.values)

        # scale factor using the resolution of the central aruco -> 100 pixels represented in reality
        cor = numpy.asarray(corner)
        scale_factor_x = 100 / (cor[:, 0].max() - cor[:, 0].min())
        scale_factor_y = 100 / (cor[:, 1].max() - cor[:, 1].min())

        # move x and y direction the whole frame to make coincide the projected aruco with the corner
        x_move = int(((x_p - x_r) * scale_factor_x)) - self.offset - self.pixel_displacement
        y_move = int(((y_p - y_r) * scale_factor_y)) - self.offset - self.pixel_displacement

        # provide with the location of the
        p_frame_left = self.calib.p_frame_left - x_move
        p_frame_top = self.calib.p_frame_top - y_move

        # Now same procedure with the center aruco by changing the width and height of the frame to make
        # coincide the center projected aruco with the center of the sandbox.
        x_c = df_r.Color_x.mean()
        y_c = df_r.Color_y.mean()

        x_pc = int(df_p.loc[df_p.ids == self.center_id].Corners_projector_x.values)
        y_pc = int(df_p.loc[df_p.ids == self.center_id].Corners_projector_y.values)

        width_move = int((x_c - x_pc) * scale_factor_x) + x_move - self.pixel_displacement
        height_move = int((y_c - y_pc) * scale_factor_y) + y_move - self.pixel_displacement

        p_frame_width = self.calib.p_frame_width + width_move
        p_frame_height = self.calib.p_frame_height + height_move

        return p_frame_left, p_frame_top, p_frame_width, p_frame_height

    def crop_image_aruco(self):
        """ Method that takes the location of the 4 real corners and crop the sensor extensions to this frame
        Returns:
            s_top: new value to update the calib.s_top
            s_left: new value to update the calib.s_left
            s_bottom: new value to update the calib.s_bottom
            s_right: new value to update the calib.s_right
        """
        id_LU = self.aruco_corners.loc[self.aruco_corners.ids == self.corner_id_LU]
        id_DR = self.aruco_corners.loc[self.aruco_corners.ids == self.corner_id_DR]

        s_top = int(id_LU.Depth_y)
        s_left = int(id_LU.Depth_x)
        s_bottom = int(self.calib.s_height - id_DR.Depth_y)
        s_right = int(self.calib.s_width - id_DR.Depth_x)

        return s_top, s_left, s_bottom, s_right

    def load_corners_ids(self):
        """DEPRECATED"""
        if self.calib.aruco_corners is not None:
            self.aruco_corners = pd.read_json(self.calib.aruco_corners)
            temp = self.aruco_corners.loc[numpy.argsort(self.aruco_corners.Color_x)[:2]]
            self.corner_id_LU = int(temp.loc[temp.Color_y == temp.Color_y.min()].ids.values)
            temp1 = self.aruco_corners.loc[numpy.argsort(self.aruco_corners.Color_x)[-2:]]
            self.corner_id_DR = int(temp1.loc[temp1.Color_y == temp1.Color_y.max()].ids.values)
            self.center_id = 20

        # TODO: pixel distance from the frame corner so the aruco is always projected inside the sandbox
        self.offset = 100
        # TODO: move the image this amount of pixels so when moving the image is at this distance from the detected aruco
        self.pixel_displacement = 10



================================================
FILE: sandbox/markers/aruco_linux.py
================================================
#%%
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from tqdm.autonotebook import tqdm
from sandbox.sensor.kinectV2 import KinectV2
from sandbox import set_logger
logger = set_logger(__name__)

#%%
depth_params = None
color_params = None
distorted_depth = None
undistorted_depth = None
registered_RGB = None
big_depth = None
device = None
dp_camera_x = None
dp_camera_y = None
dp_camera_z = None
rgb = None
depth = None
x_correction = 0
y_correction = 0
#%%


def set_correction(x, y):
    global x_correction, y_correction
    x_correction = x
    y_correction = y


def set_device(kinect):
    global device
    device = kinect.device


def set_device_params(kinect):
    global depth_params, color_params
    depth_params = kinect.device.ir_camera_params
    color_params = kinect.device.color_camera_params


def start_mapping(kinect: KinectV2):
    """
        Takes the kinect sensor and create the map to convert color space to depth space
        Args:
            kinect: Sensor

        Returns:
            pd.Dataframe
        """
    # depth_to_color
    set_device(kinect)
    set_device_params(kinect)
    status = kinect._thread_status
    if status == "running":
        kinect._stop()
    depth, _, undistorted_depth, _, _ = registration()

    _ = depth_to_camera(undistorted_depth)
    df = create_CoordinateMap(depth.to_array())
    logger.info("CoordinateMap created")
    if status == "running":
        kinect._run()
    return df


def registration():
    """
    Takes an original frame from the freenect library to be able to create the undistorted depth frame
    Returns:
        undistorted_depth, registered_RGB, big_depth
    """
    from freenect2 import FrameType
    global distorted_depth

    frames = {}
    with device.running():
        for type_, frame in device:
            frames[type_] = frame
            if FrameType.Color in frames and FrameType.Depth in frames and FrameType.Ir in frames:
                break
    global rgb, depth
    rgb, depth = frames[FrameType.Color], frames[FrameType.Depth]

    global undistorted_depth, registered_RGB, big_depth
    undistorted_depth, registered_RGB, big_depth = device.registration.apply(
        rgb, depth, with_big_depth=True)
    return depth, rgb, undistorted_depth, registered_RGB, big_depth


def distort(mx, my):
    """
    see http://en.wikipedia.org/wiki/Distortion_(optics) for description
    """
    dx = (mx - depth_params.cx) / depth_params.fx
    dy = (my - depth_params.cy) / depth_params.fy
    dx2 = dx * dx
    dy2 = dy * dy
    r2 = dx2 + dy2
    dxdy2 = 2 * dx * dy
    kr = 1 + ((depth_params.k3 * r2 + depth_params.k2) * r2 + depth_params.k1) * r2
    x = depth_params.fx * (dx * kr + depth_params.p2 * (r2 + 2 * dx2) + depth_params.p1 * dxdy2) + depth_params.cx;
    y = depth_params.fy * (dy * kr + depth_params.p1 * (r2 + 2 * dy2) + depth_params.p2 * dxdy2) + depth_params.cy;
    return x, y


def depth_to_color(mx, my, z):
    """
    Takes the indexes mx, my from the depth space -and the value of depth at those indexes, to get the
    index position in the color space
    Args:
        mx: index in x position
        my: index in y position
        z: z[my][mx]

    Returns:
        rx, ry
    """
    # these seem to be hardcoded in the original SDK static const float
    depth_q = 0.01
    color_q = 0.002199

    mx = (mx - depth_params.cx) * depth_q
    my = (my - depth_params.cy) * depth_q

    wx = (mx * mx * mx * color_params.mx_x3y0) + \
        (my * my * my * color_params.mx_x0y3) + \
        (mx * mx * my * color_params.mx_x2y1) + \
         (my * my * mx * color_params.mx_x1y2) + \
        (mx * mx * color_params.mx_x2y0) + \
         (my * my * color_params.mx_x0y2) + \
         (mx * my * color_params.mx_x1y1) + \
         (mx * color_params.mx_x1y0) + \
         (my * color_params.mx_x0y1) + \
         (color_params.mx_x0y0)

    wy = (mx * mx * mx * color_params.my_x3y0) + \
         (my * my * my * color_params.my_x0y3) + \
        (mx * mx * my * color_params.my_x2y1) + \
         (my * my * mx * color_params.my_x1y2) + \
        (mx * mx * color_params.my_x2y0) + \
         (my * my * color_params.my_x0y2) + \
         (mx * my * color_params.my_x1y1) + \
        (mx * color_params.my_x1y0) + \
         (my * color_params.my_x0y1) + \
         (color_params.my_x0y0)

    rx = (wx / (color_params.fx * color_q)) - (color_params.shift_m / color_params.shift_d)
    ry = (wy / color_q) + color_params.cy
    # calculating x offset for rgb image based on depth value
    rx = (rx + (color_params.shift_m / z)) * color_params.fx + (color_params.cx+0.5)

    return rx, ry


def depth_to_camera(depth=None):
    """
    Gets the real space coordinates in [m], from the focal point of the camera
    Args:
        depth: undistorted_depth
    Returns:

    """
    if depth is None:
        undistorted = depth
    else:
        undistorted = undistorted_depth

    global dp_camera_x, dp_camera_y, dp_camera_z
    points = device.registration.get_points_xyz_array(undistorted=undistorted)
    dp_camera_x, dp_camera_y, dp_camera_z = points[..., 0], points[..., 1], points[..., 2]
    return dp_camera_x, dp_camera_y, dp_camera_z


def create_CoordinateMap(depth):
    """ Function to create a point to point map of the spatial/pixel equivalences between the depth space, color space and
    camera space. This method requires the depth frame to assign a depth value to the color point.
    Returns:
        CoordinateMap: DataFrame with the x,y,z values of the depth frame; x,y equivalence between the depth space to camera space and
        real world values of x,y and z in meters
    """
    height, width = depth.shape
    x = np.arange(0, width)
    y = np.arange(0, height)
    xx, yy = np.meshgrid(x, y)
    xy_points = np.vstack([xx.ravel(), yy.ravel()]).T
    depth_x = []
    depth_y = []
    depth_z = []
    camera_x = []
    camera_y = []
    camera_z = []
    color_x = []
    color_y = []
    for i in tqdm(range(len(xy_points)), desc="Creating CoordinateMap"):
        x_point = xy_points[i, 0]
        y_point = xy_points[i, 1]
        z_point = depth[y_point][x_point]
        if z_point != 0:  # values that do not have depth information cannot be projected to the color space
            x, y = depth_to_color(x_point, y_point, z_point)

            camx = dp_camera_x[y_point][x_point]
            camy = dp_camera_y[y_point][x_point]
            camz = dp_camera_z[y_point][x_point]
            # since the position of the camera and sensor are different, they will not have the same coverage.
            # Specially in the extremes
            if y > 0:

                depth_x.append(x_point)
                depth_y.append(y_point)
                depth_z.append(z_point)
                camera_x.append(camx)
                camera_y.append(camy)
                camera_z.append(camz)
                ####TODO: constants addded since image is not exact when doing the transformation
                color_x.append(round(x) + x_correction)
                color_y.append(round(y) + y_correction)

    CoordinateMap = pd.DataFrame({'Depth_x': depth_x,
                                  'Depth_y': depth_y,
                                  'Depth_Z(mm)': depth_z,
                                  'Color_x': color_x,
                                  'Color_y': color_y,
                                  'Camera_x(m)': camera_x,
                                  'Camera_y(m)': camera_y,
                                  'Camera_z(m)': camera_z
                                  })

    return CoordinateMap


def plot_all(df=None, index=7000):
    """plot all the frames from the script"""
    plt.imshow(depth.to_array(), origin='lower')
    plt.colorbar()
    plt.show()
    plt.imshow(undistorted_depth.to_array(), origin='lower')
    plt.colorbar()
    plt.show()
    plt.imshow(registered_RGB.to_array(), origin='lower')
    plt.colorbar()
    plt.show()
    plt.imshow(big_depth.to_array(), origin='lower')
    plt.colorbar()
    plt.show()

    if df is not None:
        df_ind = df.iloc[index]
        plt.imshow(depth.to_array(), origin='lower')
        plt.plot(df_ind.Depth_x, df_ind.Depth_y, '*r')
        plt.colorbar()
        plt.show()

        plt.imshow(rgb.to_array(), origin='lower')
        plt.plot(df_ind.Color_x, df_ind.Color_y, '*r')
        plt.colorbar()
        plt.show()



================================================
FILE: sandbox/markers/aruco_windows.py
================================================
import numpy as np
import pandas as pd
from tqdm.autonotebook import tqdm
from sandbox.sensor.kinectV2 import KinectV2
from sandbox import set_logger
logger = set_logger(__name__)

#%%
device = None
x_correction = 0
y_correction = 0


#%%
def set_correction(x, y):
    global x_correction, y_correction
    x_correction = x
    y_correction = y


def set_device(kinect):
    global device
    device = kinect.device


def start_mapping(kinect: KinectV2):
    """
    Takes the kinect sensor and create the map to convert color space to depth space
    Args:
        kinect: Sensor

    Returns:
        pd.Dataframe
    """
    set_device(kinect)
    df = create_CoordinateMap(kinect.get_frame())
    logger.info("CoordinateMap created")
    return df


def create_CoordinateMap(depth):
    """ Function to create a point to point map of the spatial/pixel equivalences between the depth space,
    color space and camera space. This method requires the depth frame to assign a depth value to the color point.
    Returns:
        CoordinateMap: DataFrame with the x,y,z values of the depth frame; x,y equivalence between the depth space
        to camera space and real world values of x,y and z in meters
    """
    from pykinect2 import PyKinectV2
    height, width = depth.shape
    x = np.arange(0, width)
    y = np.arange(0, height)
    xx, yy = np.meshgrid(x, y)
    xy_points = np.vstack([xx.ravel(), yy.ravel()]).T
    depth_x = []
    depth_y = []
    depth_z = []
    camera_x = []
    camera_y = []
    camera_z = []
    color_x = []
    color_y = []
    for i in tqdm(range(len(xy_points)), desc="Creating CoordinateMap"):
        x_point = xy_points[i, 0]
        y_point = xy_points[i, 1]
        z_point = depth[y_point][x_point]
        if z_point != 0:   # values that do not have depth information cannot be projected to the color space
            point = PyKinectV2._DepthSpacePoint(x_point, y_point)
            col = device._mapper.MapDepthPointToColorSpace(point, z_point)
            cam = device._mapper.MapDepthPointToCameraSpace(point, z_point)
            # since the position of the camera and sensor are different, they will not have the same coverage. Specially in the extremes
            if col.y > 0:
                depth_x.append(x_point)
                depth_y.append(y_point)
                depth_z.append(z_point)
                camera_x.append(cam.x)
                camera_y.append(cam.y)
                camera_z.append(cam.z)
                # TODO: constants addded since image is not exact when doing the transformation
                color_x.append(round(col.x) + x_correction)
                color_y.append(round(col.y) + y_correction)

    CoordinateMap = pd.DataFrame({'Depth_x': depth_x,
                                  'Depth_y': depth_y,
                                  'Depth_Z(mm)': depth_z,
                                  'Color_x': color_x,
                                  'Color_y': color_y,
                                  'Camera_x(m)': camera_x,
                                  'Camera_y(m)': camera_y,
                                  'Camera_z(m)': camera_z
                                  })

    return CoordinateMap



================================================
FILE: sandbox/markers/dummy_aruco.py
================================================
import pandas as pd


def dummy_markers_in_frame(dict_position: dict, depth):
    """ Function to create a point to point map of the spatial/pixel equivalences between the depth space,
     color space and camera space.
     This method requires the depth frame to assign a depth value to the color point.
    Returns:
        CoordinateMap: DataFrame with the x,y,z values of the depth frame; x,y equivalence
        between the depth space to camera space and real world values of x,y and z in meters
    """
    height, width = depth.shape
    labels = {"ids",
              "depth_x",
              "depth_y",
              "box_x",
              "box_y",
              "is_inside_box",
              "counter"}
    df = pd.DataFrame(columns=labels)
    for ids in dict_position.keys():
        x, y = dict_position[ids]
        df_temp = pd.DataFrame(
            {'ids': [ids],
             'depth_x': [x],
             'depth_y': [y],
             'depth_z': [depth[y][x] if 0 < x < width and 0 < y < height else 0],
             'box_x': [x],
             'box_y': [y],
             'is_inside_box': [True if 0 < x < width and 0 < y < height else False],
             'counter': [0]
             }
        )
        df = pd.concat([df, df_temp], sort=False)
    df = df.set_index(df['ids'], drop=True)
    df = df.drop(columns=['ids'])
    return df



================================================
FILE: sandbox/markers/lidar_aruco.py
================================================
import numpy as np
import pandas as pd
from tqdm.autonotebook import tqdm
import pyrealsense2 as rs
from sandbox.sensor.lidar_l515 import LiDAR
from sandbox import set_logger
logger = set_logger(__name__)

x_correction = 0
y_correction = 0
depth_min = 0.11  # meter
depth_max = 1.0  # meter
sensor = None
depth_scale = None
depth_intrin = None
color_intrin = None
depth_to_color_extrin = None
color_to_depth_extrin = None
#%%


def set_correction(x, y):
    global x_correction, y_correction
    x_correction = x
    y_correction = y


def set_sensor(lidar):
    global sensor
    sensor = lidar


def set_sensor_params(sensor):
    global depth_scale, depth_intrin, color_intrin, depth_to_color_extrin, color_to_depth_extrin
    depth_scale = sensor.profile.get_device().first_depth_sensor().get_depth_scale()

    depth_intrin = sensor.profile.get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()
    color_intrin = sensor.profile.get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()

    depth_to_color_extrin = sensor.profile.get_stream(rs.stream.depth).as_video_stream_profile().get_extrinsics_to(
        sensor.profile.get_stream(rs.stream.color))
    color_to_depth_extrin = sensor.profile.get_stream(rs.stream.color).as_video_stream_profile().get_extrinsics_to(
        sensor.profile.get_stream(rs.stream.depth))


def start_mapping(sensor: LiDAR):
    """
        Takes the LiDAR L515 sensor and create the map to convert color space to depth space
        Args:
            sensor: Sensor

        Returns:
            pd.Dataframe
        """
    set_sensor(sensor)
    set_sensor_params(sensor)
    df = create_CoordinateMap(sensor.get_frame())
    logger.info("CoordinateMap created")
    return df


def project_color_to_depth(xy_pos):
    """
    Be sure to use the set_sensor(...), and set_params(...) before using this method.
    This function will return the coordinate position of from the color frame to the depth frame.
    It uses the rs.rs2_project_color_pixel_to_depth_pixel(...) function
    Args:
        xy_pos:

    Returns:

    """
    while True:
        frames = sensor.pipeline.wait_for_frames()
        depth_frame = frames.get_depth_frame()
        if not depth_frame:
            continue
        else:
            break
    point = rs.rs2_project_color_pixel_to_depth_pixel(depth_frame.get_data(),
                                                      depth_scale,
                                                      depth_min,
                                                      depth_max,
                                                      depth_intrin,
                                                      color_intrin,
                                                      depth_to_color_extrin,
                                                      color_to_depth_extrin,
                                                      xy_pos)
    return point


def create_CoordinateMap(depth):
    """ Function to create a point to point map of the spatial/pixel equivalences between the depth space, color space and
    camera space. This method requires the depth frame to assign a depth value to the color point.
    Returns:
        CoordinateMap: DataFrame with the x,y,z values of the depth frame; x,y equivalence between the depth space to camera space and
        real world values of x,y and z in meters
    """
    while True:
        frames = sensor.pipeline.wait_for_frames()
        depth_frame = frames.get_depth_frame()
        color_frame = frames.get_color_frame()
        if not depth_frame or not color_frame:
            continue
        else:
            break

    color = np.asanyarray(color_frame.get_data())
    height, width, _ = color.shape
    crop_margin = 5  # When no margi the codo get stuck at the margin value
    x = np.arange(crop_margin, width - crop_margin)
    y = np.arange(crop_margin, height - crop_margin)
    xx, yy = np.meshgrid(x, y)
    xy_points = np.vstack([xx.ravel(), yy.ravel()]).T
    depth_x = []
    depth_y = []
    depth_z = []
    color_x = []
    color_y = []
    # camera_x = [] # TODO: When are the camera values needed?
    # camera_y = []
    # camera_z = []
    for i in tqdm(range(len(xy_points)), desc="Creating CoordinateMap"):
        xcol_point = xy_points[i, 0]
        ycol_point = xy_points[i, 1]
        # if z_point != 0:  # values that do not have depth information cannot be projected to the color space
        point = rs.rs2_project_color_pixel_to_depth_pixel(depth_frame.get_data(),
                                                          depth_scale,
                                                          depth_min,
                                                          depth_max,
                                                          depth_intrin,
                                                          color_intrin,
                                                          depth_to_color_extrin,
                                                          color_to_depth_extrin,
                                                          [xcol_point, ycol_point])
        # If the points are inside the resolution of the depth frame
        if 1 < point[0] < 639 and 1 < point[1] < 479:
            point = list(map(round, point))
            z_point = depth[point[1], point[0]]

            color_x.append(xcol_point)
            color_y.append(ycol_point)
            # TODO: constants added since image is not exact when doing the transformation
            depth_x.append(point[0] + x_correction)
            depth_y.append(point[1] + y_correction)
            depth_z.append(z_point)

    CoordinateMap = pd.DataFrame({'Depth_x': depth_x,
                                  'Depth_y': depth_y,
                                  'Depth_Z(mm)': depth_z,
                                  'Color_x': color_x,
                                  'Color_y': color_y,
                                  # 'Camera_x(m)': camera_x,
                                  # 'Camera_y(m)': camera_y,
                                  # 'Camera_z(m)': camera_z
                                  })
    return CoordinateMap



================================================
FILE: sandbox/markers/markers_plotting.py
================================================
from .aruco import ArucoMarkers
import panel as pn
import matplotlib.colors as mcolors
from matplotlib.lines import Line2D
import numpy
import pandas as pd
import weakref
from sandbox import set_logger
logger = set_logger(__name__)


class MarkerDetection:
    def __init__(self, sensor, **kwargs):
        self.sensor = sensor
        self.Aruco = ArucoMarkers(sensor=sensor, **kwargs)
        self.df_aruco_position = pd.DataFrame()
        self.lines = None
        self.scat = None
        self._scat = None  # weak reference to a scat plot
        self._lin = None  # weak reference to a lines plot
        self.anot = None
        # aruco setup
        self.aruco_connect = False
        self.aruco_scatter = True
        self.aruco_annotate = True
        self.aruco_color = mcolors.to_hex('red')
        # Dummy sensor
        self._dict_position = {}
        self._widget_position = {}
        self._depth_frame = numpy.ones((sensor.extent[1], sensor.extent[3]))
        logger.info("Aruco detection ready")

    def update(self):
        if self.Aruco.kinect == "dummy":
            kwargs = {"dict_position": self._all_dict_position,
                      "depth_frame": self._depth_frame}
        else:
            kwargs = {}
        self.Aruco.search_aruco(**kwargs)
        self.Aruco.update_marker_dict()
        self.Aruco.transform_to_box_coordinates()
        self.df_aruco_position = self.Aruco.aruco_markers
        return self.df_aruco_position

    def set_aruco_position(self, dict_position: dict = {}, frame=None):
        """
        This function will create the aruco data frame with this values
        Args:
            dict_position: i.e. {1:[10,20],2:[100,200]} -> keys are the ids and the array the position in x and y
            frame: the depth frame, to extract the z value
        Returns:
        """
        self._dict_position = dict_position
        if frame is not None:
            self._depth_frame = frame

    def delete_aruco_position(self, ids = None):
        """If None, delete all positions. If ids match with one aruco only delete that one
        Args:
            ids: aruco id to delete
        """
        if ids:
            if ids in self.dict_position.keys():
                self.dict_position.pop(ids)
            else:
                logger.info("id: ", ids, " not found")
        else:
            self._dict_position = {}

    def _set_widget_position(self, dict_position: dict = {}):
        self._widget_position = {**self._widget_position, **dict_position}

    @property
    def _all_dict_position(self):
        return {**self._dict_position, **self._widget_position}

    def calibrate_aruco(self, move_x, move_y):
        self.Aruco.set_xy_correction(move_x, move_y)

    def plot_aruco(self, ax, df_position=None):
        if self._scat is not None and self._scat() not in ax.collections:
            self.scat = None
        if self._lin is not None and self._lin() not in ax.lines:
            self.lines = None
        if len(df_position) > 0:
            df = df_position.loc[df_position.is_inside_box, ("box_x", "box_y")]
            if self.aruco_scatter:
                if self.scat is None:
                    self.scat = ax.scatter(df.box_x.values,
                                           df.box_y.values,
                                           s=350, facecolors='none', edgecolors=self.aruco_color, linewidths=2,
                                           zorder=5000)
                    self._scat = weakref.ref(self.scat)

                else:
                    self.scat.set_offsets(numpy.c_[df.box_x.values, df.box_y.values])
                    self.scat.set_edgecolor(self.aruco_color)

                if self.aruco_annotate:
                    if self.anot is not None:
                        [ax.texts.remove(anot) for anot in self.anot if anot in ax.texts]
                        self.anot = None
                    self.anot = [ax.annotate(str(df.index[i]),
                                             (df.box_x.values[i], df.box_y.values[i]),
                                             c=self.aruco_color,
                                             fontsize=20,
                                             textcoords='offset pixels',
                                             xytext=(20, 20),
                                             zorder=5001) for i in range(len(df))]

                else:
                    if self.anot is not None:
                        [ax.texts.remove(anot) for anot in self.anot if anot in ax.texts]
                        self.anot = None
            else:
                if self.scat is not None:
                    self.scat.remove()
                    self.scat = None

            if self.aruco_connect:
                if self.lines is None:
                    self.lines, = ax.plot(df_position[df_position['is_inside_box']]['box_x'].values,
                                          df_position[df_position['is_inside_box']]['box_y'].values,
                                          linestyle='solid',
                                          color=self.aruco_color,
                                          zorder=5002)
                    self._lin = weakref.ref(self.lines)

                else:
                    self.lines.set_data(df_position[df_position['is_inside_box']]['box_x'].values,
                                        df_position[df_position['is_inside_box']]['box_y'].values)
                    self.lines.set_color(self.aruco_color)
            else:
                if self.lines is not None:
                    self.lines.remove()
                self.lines = None
        else:
            if self.lines is not None:
                self.lines.remove()
                self.lines = None
            if self.scat is not None:
                self.scat.remove()
                self.scat = None
            if self.anot is not None:
                [ax.texts.remove(anot) for anot in self.anot if anot in ax.texts]
                self.anot = None

        return ax

    @property
    def legend_elements(self):
        """Usefull method to get the labels and handles of the arucos in frame """
        if len(self.df_aruco_position) > 0:
            df = self.df_aruco_position.loc[self.df_aruco_position.is_inside_box, ("box_x", "box_y")]

            legend_elements = [Line2D([0], [0], marker='o', color=self.aruco_color, label='id %s'% str(df.index[i]),
                              markerfacecolor='none') for i in range(len(df))]

            return legend_elements

    # Widgets for aruco plotting

    def widgets_aruco(self):
        self._create_aruco_widgets()
        if self.Aruco.kinect == "dummy":
            pane = self._create_dummy_aruco()
        else:
            pane = None
        widgets = pn.WidgetBox(self._widget_aruco_scatter,
                               self._widget_aruco_annotate,
                               self._widget_aruco_connect,
                               self._widget_aruco_color)

        panel = pn.Column("<b> Dashboard for aruco Visualization </b>", pn.Row(widgets, pane))
        return panel

    def _create_aruco_widgets(self):
        self._widget_aruco_scatter = pn.widgets.Checkbox(name='Show aruco location', value=self.aruco_scatter)
        self._widget_aruco_scatter.param.watch(self._callback_aruco_scatter, 'value',
                                               onlychanged=False)

        self._widget_aruco_annotate = pn.widgets.Checkbox(name='Show aruco id', value=self.aruco_annotate)
        self._widget_aruco_annotate.param.watch(self._callback_aruco_annotate, 'value',
                                                onlychanged=False)

        self._widget_aruco_connect = pn.widgets.Checkbox(name='Show line connecting arucos',
                                                         value=self.aruco_connect)
        self._widget_aruco_connect.param.watch(self._callback_aruco_connect, 'value',
                                               onlychanged=False)

        self._widget_aruco_color = pn.widgets.ColorPicker(name='Color', value=self.aruco_color)
        self._widget_aruco_color.param.watch(self._callback_aruco_color, 'value', onlychanged=False)

    def _create_dummy_aruco(self):
        self._widget_aruco_id = pn.widgets.Spinner(name='id', value=1, step=1, width=70)
        self._widget_aruco_x = pn.widgets.Spinner(name="x coordinate", value=50, step=1, width=70)
        self._widget_aruco_y = pn.widgets.Spinner(name="y coordinate", value=50, step=1, width=70)

        self._widget_aruco_marker = pn.widgets.Button(name="Add dummy aruco dict", button_type="success")
        self._widget_aruco_marker.on_click(self._callback_set_aruco)

        self._widget_clear_marker = pn.widgets.Button(name="Clear aruco dict", button_type="warning")
        self._widget_clear_marker.on_click(self._callback_clear_aruco)

        pane = pn.WidgetBox("<b> Dummy aruco </b>",
                            pn.Row(self._widget_aruco_id, self._widget_aruco_x, self._widget_aruco_y),
                            self._widget_aruco_marker,
                            self._widget_clear_marker)
        return pane

    def _callback_aruco_scatter(self, event): self.aruco_scatter = event.new

    def _callback_aruco_annotate(self, event): self.aruco_annotate = event.new

    def _callback_aruco_connect(self, event): self.aruco_connect = event.new

    def _callback_aruco_color(self, event): self.aruco_color = event.new

    def _callback_clear_aruco(self, event): self._widget_position = {}

    def _callback_set_aruco(self, event):
        x = self._widget_aruco_x.value
        y = self._widget_aruco_y.value
        arucoid = self._widget_aruco_id.value
        self._set_widget_position(dict_position={arucoid: [x, y]})



================================================
FILE: sandbox/modules/__init__.py
================================================
from .gradients import GradientModule
from .landslides import LandslideSimulation
from .load_save_topography import LoadSaveTopoModule
from .topography import TopoModule
from .prototyping import PrototypingModule
from .search_methods import SearchMethodsModule


if __name__ == '__main__':
    pass


================================================
FILE: sandbox/modules/gradients.py
================================================
import matplotlib.pyplot as plt
import matplotlib
from matplotlib.colors import LightSource
import numpy
import panel as pn
from .template import ModuleTemplate
from sandbox import set_logger
logger = set_logger(__name__)


class GradientModule(ModuleTemplate):
    """
    Module to display the gradient of the topography and the topography as a vector field.
    """
    def __init__(self, extent: list = None):
        # call parents' class init, use greyscale colormap as standard and extreme color labeling
        pn.extension()
        if extent is not None:
            self.vmin = extent[4]
            self.vmax = extent[5]

        self.extent = extent
        self.frame = None
        # all possible type of gradient plots
        self.grad_type = ['Original',
                          'Gradient dx',
                          'Gradient dy',
                          'Gradient all',
                          'Laplacian',
                          'Lightsource',
                          'White background'
                          ]

        self.active_stream = False
        self.active_vector = False
        self.vector = None
        self.stream = None
        self.current_grad = self.grad_type[0]

        # lightsource parameter
        self.azdeg = 315
        self.altdeg = 4
        self.ve = 0.25
        self.set_lightsource()

        logger.info("GradientModule loaded successfully")

    def update(self, sb_params: dict):
        frame = sb_params.get('frame')
        extent = sb_params.get('extent')
        ax = sb_params.get('ax')
        cmap = sb_params.get("cmap")

        frame, ax, cmap, extent, contour = self.plot(frame, ax, cmap, extent, self.current_grad)

        sb_params['frame'] = frame
        sb_params['ax'] = ax
        sb_params['cmap'] = cmap
        sb_params['extent'] = extent
        if cmap is None:
            sb_params['active_cmap'] = False
            sb_params['active_shading'] = False
        else:
            sb_params['active_cmap'] = True
            sb_params['active_shading'] = False
        if contour is None:
            sb_params['active_contours'] = False
        else:
            sb_params['active_contours'] = True
        return sb_params

    def delete_quiver_ax(self, ax):
        [quiver.remove() for quiver in reversed(ax.collections) if isinstance(quiver, matplotlib.quiver.Quiver)]
        self.vector = None

    def delete_stream_ax(self, ax):
        [arrow.remove() for arrow in reversed(ax.patches) if isinstance(arrow, matplotlib.patches.FancyArrowPatch)]
        [lines.remove() for lines in reversed(ax.collections) if isinstance(lines, matplotlib.collections.LineCollection)]
        self.stream = None

    def plot(self, frame, ax, cmap, extent, current_grad):
        contour = True
        dx, dy = numpy.gradient(frame)
        # Delete everything to plot it new
        if self.vector is not None:  # quiver plot
            self.delete_quiver_ax(ax)
        if self.stream is not None:  # stream plot
            self.delete_stream_ax(ax)

        if self.active_vector:
            _ = self._quiver(frame, dx, dy, ax)

        if self.active_stream:
            _ = self._stream(frame, dx, dy, ax)
            contour = None

        if current_grad == self.grad_type[0]:
            pass
        elif current_grad == self.grad_type[1]:
            frame, extent, cmap = self._dx(dx, extent)
            frame = numpy.clip(frame, extent[-2], extent[-1])
        elif current_grad == self.grad_type[2]:
            frame, extent, cmap = self._dy(dy, extent)
            frame = numpy.clip(frame, extent[-2], extent[-1])
        elif current_grad == self.grad_type[3]:
            frame, extent, cmap = self._dxdy(dx,  dy, extent)
            frame = numpy.clip(frame, extent[-2], extent[-1])
        elif current_grad == self.grad_type[4]:
            frame, extent, cmap = self._laplacian(dx,  dy, extent)
            frame = numpy.clip(frame, extent[-2], extent[-1])
        elif current_grad == self.grad_type[5]:
            frame, cmap = self._lightsource(frame)
            frame = numpy.clip(frame, extent[-2], extent[-1])
        elif current_grad == self.grad_type[6]:
            cmap = None
        else:
            raise NotImplementedError
        return frame, ax, cmap, extent, contour

    def _dx(self, dx, extent):
        extent[-2] = -2
        extent[-1] = 2
        cmap = plt.get_cmap('viridis')
        return dx, extent, cmap

    def _dy(self, dy, extent):
        extent[-2] = -2
        extent[-1] = 2
        cmap = plt.get_cmap('viridis')
        return dy, extent, cmap

    def _dxdy(self, dx, dy, extent):
        dxdy = numpy.sqrt(dx**2 + dy**2)
        extent[-2] = 0
        extent[-1] = 4
        cmap = plt.get_cmap('viridis')
        return dxdy, extent, cmap

    def _laplacian(self, dx, dy, extent):
        dxdx, dxdy = numpy.gradient(dx)
        dydx, dydy = numpy.gradient(dy)
        laplacian = dxdx + dydy
        extent[-2] = -1
        extent[-1] = 1
        cmap = plt.get_cmap('RdBu_r')
        return laplacian, extent, cmap

    def _lightsource(self, frame):
        # Note: 180 degrees are subtracted because visualization in Sandbox is upside-down
        ls = LightSource(azdeg=self.azdeg - 180, altdeg=self.altdeg)
        cmap = plt.cm.copper
        rgb = ls.shade(frame, cmap=cmap, vert_exag=self.ve, blend_mode='hsv')
        return rgb, cmap

    def _quiver(self, frame, dx, dy, ax, spacing=10):
        xx, yy = frame.shape
        if self.vector is None:
            self.vector = ax.quiver(numpy.arange(spacing, yy - spacing, spacing),
                                    numpy.arange(spacing, xx - spacing, spacing),
                                    dy[spacing:-spacing:spacing, spacing:-spacing:spacing]*-1,
                                    dx[spacing:-spacing:spacing, spacing:-spacing:spacing]*-1,
                                    zorder=3)
        else:
            self.vector.set_UVC(dy[spacing:-spacing:spacing, spacing:-spacing:spacing]*-1,
                                dx[spacing:-spacing:spacing, spacing:-spacing:spacing]*-1)
        cmap = None
        return frame, cmap

    def _stream(self, frame, dx, dy, ax, spacing=10):
        xx, yy = frame.shape
        self.stream = ax.streamplot(numpy.arange(spacing, yy - spacing, spacing),
                                    numpy.arange(spacing, xx - spacing, spacing),
                                    dy[spacing:-spacing:spacing, spacing:-spacing:spacing]*-1,
                                    dx[spacing:-spacing:spacing, spacing:-spacing:spacing]*-1,
                                    zorder=3,
                                    color='blue')
        cmap = None
        contour = None
        return frame, cmap, contour

    def set_gradient(self, i):
        """
        Change implicit between all gradient types.
        Args:
            i: string indicating the number to run.
        Returns:

        """
        self.current_grad = i

    def set_lightsource(self, azdeg=315, altdeg=4, ve=0.25):
        """
        modify the azimuth, altitude and vertical exageration for the lightsource mode
        Args:
            azdeg: 0 - North, 90- East, 180 - south, 270 - West, 360 - North
            altdeg: degree of the sun . 0 - 180 - being 90 the vertical position of the sun
            ve: float, vertical exageration

        Returns:
        """
        self.azdeg = azdeg
        self.altdeg = altdeg
        self.ve = ve

    def widget_lightsource(self):
        self._widget_azdeg = pn.widgets.FloatSlider(name='Azimuth',
                                                    value=self.azdeg,
                                                    start=0.0,
                                                    end=360.0)
        self._widget_azdeg.param.watch(self._callback_lightsource_azdeg, 'value')

        self._widget_altdeg = pn.widgets.FloatSlider(name='Altitude',
                                                     value=self.altdeg,
                                                     start=0.0,
                                                     end=90.0)
        self._widget_altdeg.param.watch(self._callback_lightsource_altdeg, 'value')

        widgets = pn.WidgetBox('<b>Azimuth</b>',
                               self._widget_azdeg,
                               '<b>Altitude</b>',
                               self._widget_altdeg)

        panel = pn.Column("### Lightsource ", widgets)
        return panel


    def widget_gradient(self):
        self._widget_gradient = pn.widgets.RadioBoxGroup(name='Plotting options',
                                                         options=self.grad_type,
                                                         inline=False)
        self._widget_gradient.param.watch(self._callback_gradient, 'value', onlychanged=False)

        self._widget_active_vector = pn.widgets.Checkbox(name='Show vector field', value=self.active_vector)
        self._widget_active_vector.param.watch(self._callback_active_vector, 'value',
                                               onlychanged=False)

        self._widget_active_stream = pn.widgets.Checkbox(name='Show stream plot', value=self.active_stream)
        self._widget_active_stream.param.watch(self._callback_active_stream, 'value',
                                               onlychanged=False)

        column = pn.Column("### Plot gradient model",
                           self._widget_gradient,
                           "### Show direction of gradient",
                           self._widget_active_vector,
                           self._widget_active_stream)
        return column

    def show_widgets(self):
        """
           Create and show the widgets associated to this module
           Returns:
               widget
           """
        panel = pn.Row(self.widget_gradient(), self.widget_lightsource())
        return panel

    def _callback_active_vector(self, event):
        self.active_vector = event.new

    def _callback_active_stream(self, event):
        self.active_stream = event.new

    def _callback_lightsource_altdeg(self, event):
        self.altdeg = event.new

    def _callback_lightsource_azdeg(self, event):
        self.azdeg = event.new

    def _callback_gradient(self, event):
        self.set_gradient(event.new)



================================================
FILE: sandbox/modules/landslides.py
================================================
import os
import panel as pn
import time
import numpy
import matplotlib.pyplot as plt
import matplotlib
from matplotlib.figure import Figure
from .template import ModuleTemplate
from .load_save_topography import LoadSaveTopoModule
from sandbox import _test_data
from sandbox import set_logger
logger = set_logger(__name__)


class LandslideSimulation(ModuleTemplate):
    """
    Module to show the results of landslides simulations
    """
    #TODO: set the vmix and vmax of the landslides frames constant
    def __init__(self, *args, extent: list = None, **kwargs):
        pn.extension()
        if extent is not None:
            self.vmin = extent[4]
            self.vmax = extent[5]

        self.release_area = None
        self.release_area_all = None
        self._patch = None
        self._lan = None

        self._start = None #For the real time simulations
        self._end = None

        self.height_flow = None
        self.velocity_flow = None

        self.flow_selector = None
        self.frame_selector = 0
        self.counter = 1
        self.simulation_frame = 0
        self.running_simulation = False
        self.real_time = False

        self.simulation_folder = _test_data['landslide_simulation']
        self.release_folder = _test_data['landslide_release']
        self.topo_folder = _test_data['landslide_topo']

        self.release_options = None
        self.release_id = None
        self.release_id_all = ['None']
        self.box_release_area = False

        self.Load_Area = LoadSaveTopoModule(*args, extent=extent, **kwargs)
        self.Load_Area.data_path = self.topo_folder

        self.figure = Figure()
        self.ax1 = self.figure.add_subplot(211)
        self.ax2 = self.figure.add_subplot(212)
        self.plot_flow_frame = pn.pane.Matplotlib(self.figure, tight=False, height=500)
        plt.close(self.figure)  # close figure to prevent inline display
        logger.info("LandslideSimulation loaded successfully")
        #self.widget_all = self.show_widgets()

    def update(self, sb_params: dict):
        frame = sb_params.get('frame')
        ax = sb_params.get('ax')
        #self.Load_Area.frame = frame
        #self.Load_Area.plot(frame, ax)
        sb_params = self.Load_Area.update(sb_params)
        self.plot(frame, ax)

        return sb_params

    def plot(self, frame, ax):
        self.delete_polygon()
        self.delete_land()
        if self.box_release_area:
            self.show_box_release(ax, self.release_area)
        self.plot_landslide_frame(ax)

    def delete_polygon(self):
        if self._patch is not None:
            self._patch.remove()
            self._patch = None

    def delete_land(self):
        if self._lan is not None:
            self._lan.remove()
            self._lan = None

    def plot_landslide_frame(self, ax):
        """
        Plot from the current landslide frame depending of the type of flow (Height or velocity)
        Args:
            ax: The image to plot the frame
        Returns:
        """
        if self.running_simulation:

            if self.real_time:
                if self._start is None:
                    self._start = time.time()
                self._end = time.time()
                if (self._end - self._start) >= 5:
                    self.simulation_frame += 1
                    self._start = None
            else:
                self.simulation_frame += 1

                #3plt.pause(5) #TODO: maybe find a better way to stop the time but not the thread

            if self.simulation_frame == (self.counter+1):
                self.simulation_frame = 0

        if self.flow_selector == 'Height':
            if self.height_flow is None:
                return
            if self.running_simulation:
                move = self.height_flow[..., self.simulation_frame]
            else:
                move = self.height_flow[..., self.frame_selector]
            move = numpy.round(move, decimals=1)
            move = numpy.ma.masked_where(move <= 0, move)
            if self._lan is None:
                self._lan = ax.imshow(move, cmap='hot', aspect='auto', origin='lower',
                                      extent=self.Load_Area.to_box_extent, zorder=10)
            else:
                self._lan.set_data(move)

            #move = self.Load_Area.modify_to_box_coordinates(move)
            #self._lan = ax.pcolormesh(move, cmap='hot', shading='gouraud')

        elif self.flow_selector == 'Velocity':
            if self.velocity_flow is None:
                return
            if self.running_simulation:
                move = self.velocity_flow[..., self.simulation_frame]
            else:
                move = self.velocity_flow[..., self.frame_selector]
            move = numpy.round(move, decimals=1)
            move = numpy.ma.masked_where(move <= 0, move)
            if self._lan is None:
                self._lan = ax.imshow(move, cmap='hot', aspect='auto', origin='lower',
                                      extent=self.Load_Area.to_box_extent, zorder=10)
            else:
                self._lan.set_data(move)

        else:
            if self._lan is not None:
                self._lan.remove()
                self._lan = None
            #move = numpy.round(move, decimals=1)
            #move[move == 0] = numpy.nan
            #move = self.Load_Area.modify_to_box_coordinates(move)
            #self._lan = ax.pcolormesh(move, cmap='hot', shading='gouraud')

    def plot_frame_panel(self):
        """Update the current frame to be displayed in the panel server"""
        if self.height_flow is not None and self.velocity_flow is not None:
            self.ax1.cla()
            self.ax2.cla()

            x_move = numpy.round(self.height_flow[..., self.frame_selector], decimals=1)
            x_move = numpy.ma.masked_where(x_move <= 0, x_move)
            hor = self.ax1.imshow(x_move, cmap='hot', origin="lower")
            self.ax1.axis('equal')
            self.ax1.set_axis_off()
            self.ax1.set_title('Flow Height')
            cb1 = self.figure.colorbar(hor, ax=self.ax1, label='meter')

            y_move = numpy.round(self.velocity_flow[..., self.frame_selector], decimals=1)
            y_move = numpy.ma.masked_where(y_move <= 0, y_move)
            ver = self.ax2.imshow(y_move, cmap='hot', origin="lower")
            self.ax2.axis('equal')
            self.ax2.set_axis_off()
            self.ax2.set_title('Flow Velocity')
            cb2 =self.figure.colorbar(ver, ax=self.ax2, label='meter/sec')

            self.plot_flow_frame.param.trigger('object')

            cb1.remove()
            cb2.remove()

    def load_simulation_data_npz(self, infile):
        """Load landslide simulation from a .npz file """
        files = numpy.load(infile)
        self.velocity_flow = files['arr_0']
        self.height_flow = files['arr_1']
        self.counter = self.height_flow.shape[2] - 1
        logger.info('Load successful')

    def load_release_area(self, data_path):
        """load all possible release areas from the same topography to show the simulation"""
        self.release_options = []
        self.release_id_all = []
        self.release_area_all = []
        list_files = os.listdir(data_path)
        for i in list_files:
            temp = [str(s) for s in i if s.isdigit()]
            if len(temp) > 0:
                try:
                    if temp[-2] == self.Load_Area.file_id:
                        self.release_options.append(i)
                        self.release_id_all.append(temp[-1])
                        self.release_area_all.append(numpy.load(data_path+i))
                except:
                    logger.warning("file %s is not compatible with the loading format" % i, exc_info=True)

    def show_box_release(self, ax, xy):
        """Show the options for painting release areas at origin xy """
        self._patch = matplotlib.patches.Polygon(xy, fill=False, edgecolor='white')
        ax.add_patch(self._patch)

    def select_simulation_data(self, simulation_path, release_id):
        """Make sure that the simulation data corresponds to the loaded topography"""
        list_files = os.listdir(simulation_path)
        for i in list_files:
            temp = [str(s) for s in i if s.isdigit()]
            if len(temp) > 0:
                if temp[0] == self.Load_Area.file_id and temp[2] == release_id:
                    file_name = i
        file_location = simulation_path + file_name
        self.load_simulation_data_npz(file_location)

    def modify_to_box_coordinates(self, id):
        """Move the origin of the release areas to be correctly displayed in the sandbox"""
        temp = self.release_area_all[int(id) - 1]
        self.release_area = numpy.vstack((temp[:,0]+self.Load_Area.box_origin[0], temp[:,1]+self.Load_Area.box_origin[1])).T

    # Widgets
    def show_widgets(self):
        tabs = pn.Tabs(('Load and Save Module', self.Load_Area.show_widgets()),
                       ('Landslide simulation module', self.show_landslide_widgets()))
        self.Load_Area._widget_npz_filename.value = self.topo_folder + "Topography1.npz"

        return tabs

    def show_landslide_widgets(self):
        tabs = pn.Tabs(('Load Simulation', self.widgets_load_simulation()),
                       ('Controllers', self.widgets_controller_simulation())
                       )
        return tabs

    def widgets_controller_simulation(self):
        self._widget_show_release = pn.widgets.Checkbox(name='Show release area', value=self.box_release_area,
                                                        disabled=True)
        self._widget_show_release.param.watch(self._callback_show_release, 'value',
                                              onlychanged=False)

        self._widget_select_direction = pn.widgets.RadioButtonGroup(
            name='Flow history selector',
            options=['None', 'Height', 'Velocity'],
            value=['None'],
            button_type='success'
        )
        self._widget_select_direction.param.watch(self._callback_set_direction, 'value', onlychanged=False)

        self._widget_frame_selector = pn.widgets.IntSlider(
            name='5 seconds time step',
            value=self.frame_selector,
            start=0,
            end=self.counter
        )
        self._widget_frame_selector.param.watch(self._callback_select_frame, 'value', onlychanged=False)

        self._widget_simulation = pn.widgets.RadioButtonGroup(
            name='Run or stop simulation',
            options=['Run', 'Stop'],
            value=['Stop'],
            button_type='success'
        )
        self._widget_simulation.param.watch(self._callback_simulation, 'value', onlychanged=False)

        self._widget_real_time = pn.widgets.Checkbox(name='Show simulation in real time', value=self.real_time)
        self._widget_real_time.param.watch(self._callback_real_time, 'value',
                                              onlychanged=False)

        widgets = pn.Column("### Interaction widgets",
                            self._widget_show_release,
                            '<b>Select Flow </b>',
                            self._widget_select_direction,
                            '<b>Select Frame </b>',
                            self._widget_frame_selector,
                            '<b>Run Simulation</b>',
                            self._widget_simulation,
                            self._widget_real_time
                            )
        panel = pn.Row(widgets, self.plot_flow_frame)
        return panel

    def widgets_load_simulation(self):
        self._widget_simulation_folder = pn.widgets.TextInput(name='Specify the folder path to load the simulation:')
        self._widget_simulation_folder.value = self.simulation_folder
        self._widget_available_release_areas = pn.widgets.RadioBoxGroup(name='Available release areas',
                                                                        options=self.release_id_all,
                                                                        inline=False,
                                                                        value=None)
        self._widget_load = pn.widgets.Button(name='Refresh list', button_type='warning')
        self._widget_load_release_area = pn.widgets.Button(name='Load selected release area',
                                                           button_type="success")
        self._widget_simulation_folder.param.watch(self._callback_filename, 'value', onlychanged=False)
        self._widget_available_release_areas.param.watch(self._callback_available_release_areas, 'value',
                                                         onlychanged=False)
        self._widget_load.param.watch(self._callback_load_files_folder, 'clicks', onlychanged=False)

        self._widget_load_release_area.param.watch(self._callback_load_release_area, 'clicks',
                                                   onlychanged=False)
        col1 = pn.Column("## Load widget",
                            '<b>File path</b>',
                            self._widget_simulation_folder,
                            '<b> Load possible release areas</b>',
                            self._widget_load)
        col2 = pn.Column('<b>Load Simulation</b>',
                          self._widget_load_release_area,
                          '<b>Select a release area</b>',
                          pn.WidgetBox(self._widget_available_release_areas))
        panel = pn.Row(col1, col2)
        return panel

    def _callback_set_direction(self, event):
        self.flow_selector = event.new
        self.plot_frame_panel()

    def _callback_filename(self, event):
        self.simulation_folder = event.new

    def _callback_load_files_folder(self, event):
        if self.simulation_folder is not None:
            self.load_release_area(self.release_folder)
            self._widget_available_release_areas.options = self.release_id_all
            self._widget_available_release_areas.sizing_mode = "scale_both"

    def _callback_select_frame(self, event):
        self.frame_selector = event.new
        #self.plot_landslide_frame()
        self.plot_frame_panel()

    def _callback_simulation(self, event):
        if event.new == 'Run':
            self.running_simulation = True
        else:
            self.running_simulation = False

    def _callback_available_release_areas(self, event):
        if event.new is not None:
            self.release_id = event.new
            self.modify_to_box_coordinates(self.release_id)
            self.box_release_area = True
            self._widget_show_release.disabled = False
            self._widget_show_release.value = self.box_release_area

    def _callback_load_release_area(self, event):
        if self.simulation_folder is not None:
            self.select_simulation_data(self.simulation_folder, self.release_id)
            self._widget_frame_selector.end = self.counter + 1
            self.plot_frame_panel()

    def _callback_show_release(self, event):
        self.box_release_area = event.new

    def _callback_real_time(self, event):
        self.real_time = event.new


================================================
FILE: sandbox/modules/landslides_raw_data.py
================================================
import numpy

class Raw_landslides_simulation:
    def __init__(self):
        self.folder_dir_out = None

        self.ncols = None
        self.nrows = None
        self.xllcorner = None
        self.yllcorner = None
        self.cellsize = None
        self.NODATA_value = None
        self.asc_data = None

        self.a_line = None
        self.b_line = None
        self.xyz_data = None

        self.release_area = None
        self.hazard_map = None
        self.max_height = None
        self.max_velocity = None

        self.domain = None
        self.absolute_topo = None
        self.relative_topo = None

        self.horizontal_flow = None
        self.vertical_flow = None

        self.flow_selector = None
        self.frame_selector = 0
        self.counter = 1
        self.simulation_frame = 0
        self.running_simulation = False

        self.widget = None

        self.npz_filename = None

    def _load_data_asc(self, infile):
        f = open(infile, "r")
        self.ncols = int(f.readline().split()[1])
        self.nrows = int(f.readline().split()[1])
        self.xllcorner = float(f.readline().split()[1])
        self.yllcorner = float(f.readline().split()[1])
        self.cellsize = float(f.readline().split()[1])
        self.NODATA_value = float(f.readline().split()[1])
        self.asc_data = numpy.reshape(numpy.array([float(i) for i in f.read().split()]), (self.nrows, self.ncols))
        return self.asc_data


    def _load_data_xyz(self, infile):
        f = open(infile, "r")
        self.ncols, self.nrows = map(int, f.readline().split())
        self.a_line = numpy.array([float(i) for i in f.readline().split()])
        self.b_line = numpy.array([float(i) for i in f.readline().split()])
        self.xyz_data = numpy.reshape(numpy.array([float(i) for i in f.read().split()]), (self.nrows, self.ncols))
        return self.xyz_data


    def _load_release_area_rel(self, infile):
        f = open(infile, "r")
        data = numpy.array([float(i) for i in f.read().split()])
        self.release_area = numpy.reshape(data[1:], (int(data[0]), 2))
        return self.release_area


    def _load_out_hazard_map_asc(self, infile):
        f = open(infile, "r")
        data = numpy.array([float(i) for i in f.read().split()])
        self.hazard_map = numpy.reshape(data, (data.shape[0] / 3, 3))
        return self.hazard_map


    def _load_out_maxheight_asc(self, infile):
        f = open(infile, "r")
        self.max_height = numpy.array([float(i) for i in f.read().split()])
        return self.max_height


    def _load_out_maxvelocity_asc(self, infile):
        f = open(infile, "r")
        self.max_velocity = numpy.array([float(i) for i in f.read().split()])
        return self.max_velocity


    def _load_domain_dom(self, infile):
        f = open(infile, "r")
        self.domain = numpy.array([float(i) for i in f.read().split()])
        return self.domain


    def _load_npz(self, infile):
        files = numpy.load(infile)
        self.absolute_topo = files['arr_0']
        self.relative_topo = files['arr_1']
        return self.absolute_topo, self.relative_topo


    def _load_vertical_npy(self, infile):
        self.vertical_flow = numpy.load(infile)
        self.counter = self.vertical_flow.shape[2] - 1
        return self.vertical_flow


    def _load_horizontal_npy(self, infile):
        self.horizontal_flow = numpy.load(infile)
        self.counter = self.horizontal_flow.shape[2] - 1
        return self.horizontal_flow


================================================
FILE: sandbox/modules/load_save_topography.py
================================================
import os
import panel as pn
import numpy
import matplotlib.pyplot as plt
import matplotlib
import pandas as pd
import skimage.transform

from .template import ModuleTemplate
from sandbox import _test_data
from matplotlib.figure import Figure
from sandbox import set_logger
logger = set_logger(__name__)


class LoadSaveTopoModule(ModuleTemplate):
    """
    Module to save the current topography in a subset of the sandbox
    and recreate it at a later time
    two different representations are saved to the numpy file:

    absolute Topography:
    deviation from the mean height inside the bounding box in millimeter

    relative Height:
    height of each pixel relative to the vmin and vmax of the currently used calibration.
    use relative height with the gempy module to get the same geologic map with different calibration settings.
    """

    def __init__(self, extent: list = None, **kwargs):
        # call parents' class init, use greyscale colormap as standard and extreme color labeling
        pn.extension()
        if extent is not None:
            self.vmin = extent[4]
            self.vmax = extent[5]
            self.extent = extent
        else:
            self.extent = None
        # location of bottom left corner of the box in the sandbox. values refer to pixels of the kinect sensor
        self.box_origin = [40, 40]
        self.box_width = 200
        self.box_height = 150
        self.absolute_topo = None
        self.relative_topo = None

        self.is_loaded = False  # Flag to know if a file have been loaded or not

        self.current_show = 'None'
        self.difference_types = ['None', 'Show topography', 'Show difference', 'Show gradient difference']

        self.cmap_difference = self._cmap_difference()

        self.difference = None
        self.loaded = None

        self.transparency_difference = 1

        self.npz_filename = None

        self.release_width = 10
        self.release_height = 10
        self.release_area = None
        self.release_area_origin = None
        self.aruco_release_area_origin = None

        self.data_filenames = ['None']
        self.file_id = None
        self.data_path = _test_data['topo']

        self.figure = Figure()
        self.ax = plt.Axes(self.figure, [0., 0., 1., 1.])
        self.figure.add_axes(self.ax)

        self.snapshot_frame = pn.pane.Matplotlib(self.figure, tight=False, height=500)
        plt.close(self.figure)  # close figure to prevent inline display

        # Stores the axes
        self._lod = None
        # self._dif = None
        self.frame = None
        # contour lines
        self.deactivate_main_contour = False
        self.contours_on = False
        # create the widgets if used from another module
        _ = self.widgets_box()
        logger.info("LoadSaveTopoModule loaded successfully")

    def update(self, sb_params: dict):
        frame = sb_params.get('frame')
        ax = sb_params.get('ax')
        marker = sb_params.get('marker')
        self.extent = sb_params.get('extent')
        self.frame = frame
        if len(marker) > 0:
            self.aruco_release_area_origin = marker.loc[marker.is_inside_box, ('box_x', 'box_y')]
            self.add_release_area_origin()
        self.plot(frame, ax)
        sb_params['active_contours'] = not self.deactivate_main_contour

        return sb_params

    def delete_rectangles_ax(self, ax):
        [rec.remove() for rec in reversed(ax.patches) if isinstance(rec, matplotlib.patches.Rectangle)]
        # ax.patches = []

    def delete_im_ax(self, ax):
        # [quad.remove() for quad in reversed(ax.collections) if isinstance(quad, matplotlib.collections.QuadMesh)]
        # if self._dif is not None:
        #    self._dif.remove()
        #    self._dif = None
        if self._lod is not None:
            self._lod.remove()
            self._lod = None

    def set_show(self, i: str):
        self.current_show = i

    def plot(self, frame, ax):
        self.delete_rectangles_ax(ax)
        self.delete_im_ax(ax)

        if self.current_show == self.difference_types[0]:
            self.delete_im_ax(ax)
        elif self.current_show == self.difference_types[1]:
            self.showLoadedTopo(ax)
        elif self.current_show == self.difference_types[2]:
            self.showDifference(ax)
        elif self.current_show == self.difference_types[3]:
            self.showGradDifference(ax)

        # Show contour lines of the plot
        self.delete_contourns(ax)
        if self.contours_on:
            self.showContourTopo(ax)
        else:
            if self.deactivate_main_contour:
                self.delete_contourns(ax)
                self.deactivate_main_contour = False

        self.showBox(ax, self.box_origin, self.box_width, self.box_height)
        self.plot_release_area(ax, self.release_area_origin, self.release_width, self.release_height)

    def moveBox_possible(self, x, y, width, height):
        """
        Dinamicaly modify the size of the box when the margins extend more than frame
        Args:
            x: x coordinte of the box origin
            y: y coordinate of the box origin
            width: of the box
            height: of the box
        Returns:
        """

        if (x + width) >= self.extent[1]:
            self.box_width = self.extent[1] - x
        else:
            self.box_width = width

        if (y + height) >= self.extent[3]:
            self.box_height = self.extent[3] - y
        else:
            self.box_height = height

        self.box_origin = [x, y]

    def add_release_area_origin(self, x=None, y=None):
        """
        Add a box origin [x,y] to highlight a zone on the image.
        This method also manages the aruco release areas if detected
        Args:
            x: x coordinte of origin
            y: y coordinte of origin
        Returns:

        """
        if self.release_area_origin is None:
            self.release_area_origin = pd.DataFrame(columns=('box_x', 'box_y'))
        if self.aruco_release_area_origin is None:
            self.aruco_release_area_origin = pd.DataFrame(columns=('box_x', 'box_y'))
        self.release_area_origin = pd.concat((self.release_area_origin,
                                              self.aruco_release_area_origin)).drop_duplicates()
        if x is not None and y is not None:
            self.release_area_origin = self.release_area_origin.append({'box_x': x, 'box_y': y}, ignore_index=True)

    def plot_release_area(self, ax, origin: pd.DataFrame, width: int, height: int):
        """
        Plot small boxes in the frame according to the dataframe origin and width, height specifiend.
        Args:
            ax: matplotlib axes to plot
            origin: pandas dataframe indicating the x and y coordintes of the boxes to plot
            width: width of the box to plot
            height: height of the box to plot
        Returns:
        """
        if origin is not None:
            x_pos = origin.box_x
            y_pos = origin.box_y
            x_origin = x_pos.values - width / 2
            y_origin = y_pos.values - height / 2
            self.release_area = numpy.array([[x_origin - self.box_origin[0], y_origin - self.box_origin[1]],
                                             [x_origin - self.box_origin[0], y_origin + height - self.box_origin[1]],
                                             [x_origin + width - self.box_origin[0],
                                              y_origin + height - self.box_origin[1]],
                                             [x_origin + width - self.box_origin[0], y_origin - self.box_origin[1]]])
            for i in range(len(x_pos)):
                self.showBox(ax, [x_origin[i], y_origin[i]], width, height)

    @staticmethod
    def showBox(ax, origin: tuple, width: int, height: int):
        """
        Draws a wide rectangle outline in the live view
        Args:
            ax: the axes where the patch will be drawed on
            origin: relative position from bottom left in sensor pixel space
            width: width of box in sensor pixels
            height: height of box in sensor pixels
        Returns:
        """
        box = matplotlib.patches.Rectangle(origin, width, height, fill=False, edgecolor='white')
        ax.add_patch(box)
        return True

    def getBoxFrame(self, frame: numpy.ndarray):
        """
        Get the absolute and relative topography of the current.
        Crop frame image to dimensions of box
        Args:
            frame: frame of the actual topography
        Returns:
            absolute_topo, the cropped frame minus the mean value and relative_topo,
            the absolute topo normalized to the extent of the sandbox
        """
        cropped_frame = frame[self.box_origin[1]:self.box_origin[1] + self.box_height,
                        self.box_origin[0]:self.box_origin[0] + self.box_width]

        mean_height = cropped_frame.mean()
        absolute_topo = cropped_frame - mean_height
        relative_topo = absolute_topo / (self.vmax - self.vmin)
        return absolute_topo, relative_topo

    def extractTopo(self):
        """
        Extract the topography of the current frame and stores the value internally
        Returns:
            absolute topography and relative topography
        """
        self.is_loaded = True
        self.absolute_topo, self.relative_topo = self.getBoxFrame(self.frame)
        return self.absolute_topo, self.relative_topo

    def saveTopo(self, filename="00_savedTopography.npz"):
        """Save the absolute topography and relative topography in a .npz file"""
        numpy.savez(filename,
                    self.absolute_topo,
                    self.relative_topo)
        logger.info('Save topo successful')

    def save_release_area(self, filename="00_releaseArea.npy"):
        """Save the release areas as a .npy file """
        numpy.save(filename, self.release_area)
        logger.info('Save area successful')

    def loadTopo(self, filename="00_savedTopography.npz"):
        """Load the absolute topography and relative topography from a .npz file.
        If usinng a single .npy is assumed to be an outside DEM """
        self.is_loaded = True
        files = numpy.load(filename, allow_pickle=True)
        if filename.split(".")[-1] == "npz":
            self.absolute_topo = files['arr_0']
            self.relative_topo = files['arr_1']
            logger.info('Load sandbox topography successfully')
        elif filename.split(".")[-1] == "npy":
            target = [0, self.box_width, 0, self.box_height, self.extent[-2], self.extent[-1]]
            self.absolute_topo, self.relative_topo = self.normalize_topography(files, target)

        self._get_id(filename)

    def showLoadedTopo(self, ax):
        """
        If a topography is saved internally, display the saved topograhy on the sandbox
        Args:
            ax: axes to plot the saved topography
        Returns:
        """
        if self.is_loaded:
            shape_frame = self.getBoxShape()
            # self.loaded = self.modify_to_box_coordinates(self.absolute_topo[:shape_frame[0],
            #                                             :shape_frame[1]])
            self.loaded = self.absolute_topo[:shape_frame[0], :shape_frame[1]]
            # if self._lod is None:

            self._lod = ax.imshow(self.loaded, cmap='gist_earth', origin="lower",
                                  # TODO: data is inverted, need to fix this for all the landsladides topography data
                                  zorder=2, extent=self.to_box_extent, aspect="auto")
            # else:
            # self._lod.set_array(self.loaded[:-1,:-1].ravel())
        else:
            # if self._lod is not None:
            # self._lod.remove()
            # self._lod = None
            logger.warning("No Topography loaded, please load a Topography")

    def showContourTopo(self, ax):
        """
         If a topography is saved internally, display the saved topograhy on the sandbox
        Args:
            ax: axes to plot the saved topography
        Returns:
        """
        if self.is_loaded:
            self.deactivate_main_contour = True
            shape_frame = self.getBoxShape()

            self.loaded = self.absolute_topo[:shape_frame[0], :shape_frame[1]]
            self._cont = ax.contour(self.loaded,
                                    zorder=1000,
                                    extent=self.to_box_extent,
                                    colors="k"
                                    )
            self._label = ax.clabel(self._cont,
                                    inline=True,
                                    fontsize=15,
                                    fmt='%3.0f')

        else:
            self.delete_contourns(ax)
            self.deactivate_main_contour = False
            logger.warning("No Topography loaded, please load a Topography to display contour lines")

    def delete_contourns(self, ax):
        if self.deactivate_main_contour:
            [coll.remove() for coll in reversed(ax.collections) if isinstance(coll,
                                                                              matplotlib.collections.LineCollection)]
            [text.remove() for text in reversed(ax.artists) if isinstance(text, matplotlib.text.Text)]

    @staticmethod
    def normalize_topography(dem, target_extent):
        """
        Normalize any size of numpy array to fit the sandbox frame.
        Useful when passing DEM with resolution bigger than sandbox sensor.
        Args:
            dem:
            target_extent: [minx, maxx, miny, maxy, vmin, vmax] ->
            [0, frame_width, 0, frame_height, vmin_sensor, vmax_sensor]
        Returns:
             normalized frame
        """
        # Change shape of numpy array to desired shape
        topo_changed = skimage.transform.resize(dem,
                                                (target_extent[3], target_extent[1]),
                                                order=3,
                                                mode='edge',
                                                anti_aliasing=True,
                                                preserve_range=False)

        topo_min = topo_changed.min()
        topo_max = topo_changed.max()
        # when the min value is not 0
        if topo_min != 0:
            displ = 0 - topo_min
            topo_changed = topo_changed - displ

        topo_changed = topo_changed * (target_extent[-1] - target_extent[-2]) / (topo_max - topo_min)
        mean_height = topo_changed.mean()
        absolute_topo = topo_changed - mean_height
        relative_topo = topo_changed / (target_extent[-1] - target_extent[-2])

        return absolute_topo, relative_topo

    def modify_to_box_coordinates(self, frame):
        """
        Since the box is not in the origin of the frame,
        this will correctly display the loaded topography inside the box
        Args:
            frame: the frame that need to be modified to box coordintes
        Returns:
            The modified frame
        """
        width = frame.shape[0]
        left = numpy.ones((self.box_origin[0], width))
        left[left == 1] = numpy.nan
        frame = numpy.insert(frame, 0, left, axis=1)

        height = frame.shape[1]
        bot = numpy.ones((self.box_origin[1], height))
        bot[bot == 1] = numpy.nan
        frame = numpy.insert(frame, 0, bot, axis=0)
        # frame = numpy.ma.array(frame, mask=numpy.nan)
        return frame

    def saveTopoVector(self):  # TODO:
        """
        saves a vector graphic of the contour map to disk
        """
        pass

    def _cmap_difference(self):
        """Creates a custom made color map"""
        blues = plt.cm.RdBu(numpy.linspace(0, 0.5, 256))
        reds = plt.cm.RdBu(numpy.linspace(0.5, 1, 256))
        blues_reds = numpy.vstack((blues, reds))
        cmap = matplotlib.colors.LinearSegmentedColormap.from_list('difference_map', blues_reds)
        return cmap

    @property
    def norm_difference(self):
        """Creates a custom made norm"""
        norm = matplotlib.colors.TwoSlopeNorm(vmin=self.absolute_topo.min(),
                                              vcenter=0,
                                              vmax=self.absolute_topo.max())
        return norm

    def getBoxShape(self):
        """This will return the shape of the current saved topography"""
        current_absolute_topo, current_relative_topo = self.getBoxFrame(self.frame)
        x_dimension, y_dimension = current_absolute_topo.shape
        x_saved, y_saved = self.absolute_topo.shape
        shape_frame = [numpy.min((x_dimension, x_saved)), numpy.min((y_dimension, y_saved))]
        return shape_frame

    def extractDifference(self):
        """This will return a numpy array comparing the difference between the current frame and the saved frame """
        current_absolute_topo, _ = self.getBoxFrame(self.frame)
        shape_frame = self.getBoxShape()
        diff = self.absolute_topo[:shape_frame[0],
                                  :shape_frame[1]] - current_absolute_topo[:shape_frame[0], :shape_frame[1]]

        # paste diff array at right location according to box coordinates
        # difference = self.modify_to_box_coordinates(diff)
        return diff

    @property
    def to_box_extent(self):
        """When using imshow to plot data over the image. pass this as extent argumment to display the
        image in the correct area of the sandbox box-area"""
        return (self.box_origin[0], self.box_width + self.box_origin[0],
                self.box_origin[1], self.box_height + self.box_origin[1])

    def showDifference(self, ax):
        """
        Displays the calculated difference of the previous frame with the actual frame
        Args:
            ax: Axes to plot the difference
        Returns:
        """
        if self.is_loaded:
            difference = self.extractDifference()
            # plot
            # if self._dif is None:
            self._lod = ax.imshow(difference,
                                  cmap=self.cmap_difference,
                                  alpha=self.transparency_difference,
                                  norm=self.norm_difference,
                                  origin="lower",
                                  zorder=1,
                                  extent=self.to_box_extent,
                                  aspect="auto"
                                  )
            # else:
            #   self._dif.set_array(difference[:-1, :-1].ravel())
        else:
            # if self._dif is not None:
            #    self._dif.remove()
            #   self._dif = None
            logger.warning('No topography to show difference')

    def showGradDifference(self, ax):
        """
        Displays the calculated gradient difference of the previous frame with the actual frame
        Args:
            ax: Axes to plot the difference
        Returns:
        """
        if self.is_loaded:
            grad = self.extractGradDifference()
            # plot
            # if self._dif is None:
            self._lod = ax.imshow(grad,
                                  vmin=-5,
                                  vmax=5,
                                  cmap=self.cmap_difference,
                                  alpha=self.transparency_difference,
                                  norm=self.norm_difference,
                                  origin="lower",
                                  zorder=1,
                                  extent=self.to_box_extent,
                                  aspect="auto"
                                  )
            # else:
            #   self._dif.set_array(difference[:-1, :-1].ravel())
        else:
            # if self._dif is not None:
            #    self._dif.remove()
            #   self._dif = None
            logger.warning('No topography to show gradient difference')

    def extractGradDifference(self):
        """This will return a numpy array comparing the difference of second degree (gradients)
        between the current frame and the saved frame """
        current_absolute_topo, _ = self.getBoxFrame(self.frame)
        dx_current, dy_current = numpy.gradient(current_absolute_topo)
        dxdy_current = numpy.sqrt(dx_current ** 2 + dy_current ** 2)
        dxdy_current = numpy.clip(dxdy_current, -5, 5)

        dx_lod, dy_lod = numpy.gradient(self.absolute_topo)
        dxdy_lod = numpy.sqrt(dx_lod ** 2 + dy_lod ** 2)
        dxdy_lod = numpy.clip(dxdy_lod, -5, 5)

        shape_frame = self.getBoxShape()
        gradDiff = dxdy_current[:shape_frame[0], :shape_frame[1]] - dxdy_lod[:shape_frame[0], :shape_frame[1]]

        # paste diff array at right location according to box coordinates
        # difference = self.modify_to_box_coordinates(diff)
        return gradDiff * -1

    def snapshotFrame(self):
        """This will display the saved topography and display it in the panel bokeh"""
        self.ax.cla()
        self.ax.imshow(self.absolute_topo, cmap='gist_earth', origin="lower", aspect='auto')
        self.ax.axis('equal')
        self.ax.set_axis_off()
        self.ax.set_title('Loaded Topography')
        self.snapshot_frame.param.trigger('object')

    def _search_all_data(self, data_path):
        self.data_filenames = os.listdir(data_path)

    def _get_id(self, filename):
        ids = [str(s) for s in filename if s.isdigit()]
        if len(ids) > 0:
            self.file_id = ids[-1]
        else:
            logger.warning("Unknown file id")

    def show_widgets(self):
        tabs = pn.Tabs(('Box widgets', self.widgets_box()),
                       ('Release area widgets', self.widgets_release_area()),
                       ('Load Topography', self.widgets_load()),
                       ('Save Topography', self.widgets_save())
                       )
        return tabs

    def widgets_release_area(self):
        # Release area widgets
        self._widget_release_width = pn.widgets.IntSlider(name='Release area width',
                                                          value=self.release_width,
                                                          start=1,
                                                          end=50)
        self._widget_release_width.param.watch(self._callback_release_width, 'value', onlychanged=False)

        self._widget_release_height = pn.widgets.IntSlider(name='Release area height',
                                                           value=self.release_height,
                                                           start=1,
                                                           end=50)
        self._widget_release_height.param.watch(self._callback_release_height, 'value', onlychanged=False)

        self._widget_show_release = pn.widgets.RadioButtonGroup(name='Show or erase the areas',
                                                                options=['Show', 'Erase'],
                                                                value=['Erase'],
                                                                button_type='success')
        self._widget_show_release.param.watch(self._callback_show_release, 'value', onlychanged=False)

        widgets = pn.WidgetBox('<b>Modify the size and shape of the release area </b>',
                               self._widget_release_width,
                               self._widget_release_height,
                               self._widget_show_release)
        panel = pn.Column("### Shape release area", widgets)

        return panel

    def widgets_box(self):
        # Box widgets
        self._widget_show_type = pn.widgets.RadioBoxGroup(name='Show in sandbox',
                                                          options=self.difference_types,
                                                          value=self.difference_types[0],
                                                          inline=False)
        self._widget_show_type.param.watch(self._callback_show, 'value', onlychanged=False)

        self._widget_move_box_horizontal = pn.widgets.IntSlider(name='x box origin',
                                                                value=self.box_origin[0],
                                                                start=0,
                                                                end=self.extent[1])
        self._widget_move_box_horizontal.param.watch(self._callback_move_box_horizontal, 'value', onlychanged=False)

        self._widget_move_box_vertical = pn.widgets.IntSlider(name='y box origin',
                                                              value=self.box_origin[1],
                                                              start=0,
                                                              end=self.extent[3])
        self._widget_move_box_vertical.param.watch(self._callback_move_box_vertical, 'value', onlychanged=False)

        self._widget_box_width = pn.widgets.IntSlider(name='box width',
                                                      value=self.box_width,
                                                      start=0,
                                                      end=self.extent[1])
        self._widget_box_width.param.watch(self._callback_box_width, 'value', onlychanged=False)

        self._widget_box_height = pn.widgets.IntSlider(name='box height',
                                                       value=self.box_height,
                                                       start=0,
                                                       end=self.extent[3])
        self._widget_box_height.param.watch(self._callback_box_height, 'value', onlychanged=False)

        # Snapshots
        self._widget_snapshot = pn.widgets.Button(name="Snapshot", button_type="success")
        self._widget_snapshot.param.watch(self._callback_snapshot, 'clicks',
                                          onlychanged=False)

        self._widget_plot_contours = pn.widgets.Checkbox(name='Show contours', value=self.contours_on)
        self._widget_plot_contours.param.watch(self._callback_plot_contours, 'value',
                                               onlychanged=False)

        widgets = pn.Column('<b>Modify box size </b>',
                            self._widget_move_box_horizontal,
                            self._widget_move_box_vertical,
                            self._widget_box_width,
                            self._widget_box_height,
                            '<b>Take snapshot</b>',
                            self._widget_snapshot,
                            '<b>Show in sandbox</b>',
                            self._widget_show_type,
                            '<b>Show contour lines of target topography</b>',
                            self._widget_plot_contours
                            )

        rows = pn.Row(widgets, self.snapshot_frame)
        panel = pn.Column("### Interaction widgets", rows)

        return panel

    def widgets_save(self):
        self._widget_npz_filename = pn.widgets.TextInput(
            name='Choose a filename to save the current topography snapshot:')
        self._widget_npz_filename.param.watch(self._callback_filename_npz, 'value', onlychanged=False)
        self._widget_npz_filename.value = _test_data['topo'] + '/savedTopography.npz'

        self._widget_save = pn.widgets.Button(name='Save')
        self._widget_save.param.watch(self._callback_save, 'clicks', onlychanged=False)

        panel = pn.Column("### Save widget",
                          '<b>Filename</b>',
                          self._widget_npz_filename,
                          '<b>Safe Topography</b>',
                          self._widget_save
                          )
        return panel

    def widgets_load(self):
        self._widget_data_path = pn.widgets.TextInput(
            name='Choose a folder to load the available topography snapshots:')
        self._widget_data_path.value = self.data_path
        self._widget_data_path.param.watch(self._callback_filename, 'value', onlychanged=False)

        self._widget_load = pn.widgets.Button(name='Load Files in folder')
        self._widget_load.param.watch(self._callback_load, 'clicks', onlychanged=False)

        self._widget_available_topography = pn.widgets.RadioBoxGroup(name='Available Topographies',
                                                                     options=self.data_filenames,
                                                                     inline=False)
        self._widget_available_topography.param.watch(self._callback_available_topography, 'value',
                                                      onlychanged=False)

        # self._widget_other_topography = pn.widgets.FileInput(name="Load calibration (Note yet working)")
        self._widget_other_topography = pn.widgets.FileSelector('~')
        # self._widget_other_topography.param.watch(self._callback_other_topography, 'value')
        self._widget_load_other = pn.widgets.Button(name='Load other', button_type='success')
        self._widget_load_other.param.watch(self._callback_load_other, 'clicks', onlychanged=False)

        panel = pn.Column("### Load widget",
                          '<b>Directory path</b>',
                          self._widget_data_path,
                          '<b>Load Topography</b>',
                          self._widget_load,
                          '<b>Load available Topography</b>',
                          pn.WidgetBox(self._widget_available_topography),
                          '<b>Select another Topography file</b>',
                          self._widget_other_topography,
                          self._widget_load_other
                          )

        return panel

    def _callback_plot_contours(self, event):
        self.contours_on = event.new

    def _callback_show(self, event):
        self.set_show(event.new)

    def _callback_show_release(self, event):
        if event.new == 'Show':
            self.add_release_area_origin()
        else:
            self.release_area_origin = None

    def _callback_release_width(self, event):
        self.release_width = event.new

    def _callback_release_height(self, event):
        self.release_height = event.new

    def _callback_filename_npz(self, event):
        self.npz_filename = event.new

    def _callback_filename(self, event):
        self.data_path = event.new

    def _callback_save(self, event):
        if self.npz_filename is not None:
            self.saveTopo(filename=self.npz_filename)

    def _callback_load(self, event):
        if self.data_path is not None:
            # self.loadTopo(filename=self.npz_filename)
            # self.snapshotFrame()
            self._search_all_data(data_path=self.data_path)
            self._widget_available_topography.options = self.data_filenames
            self._widget_available_topography.sizing_mode = "scale_both"

    def _callback_move_box_horizontal(self, event):
        self.moveBox_possible(x=event.new,
                              y=self.box_origin[1],
                              width=self.box_width,
                              height=self.box_height)

    def _callback_move_box_vertical(self, event):
        self.moveBox_possible(x=self.box_origin[0],
                              y=event.new,
                              width=self.box_width,
                              height=self.box_height)

    def _callback_box_width(self, event):
        self.moveBox_possible(x=self.box_origin[0],
                              y=self.box_origin[1],
                              width=event.new,
                              height=self.box_height)

    def _callback_box_height(self, event):
        self.moveBox_possible(x=self.box_origin[0],
                              y=self.box_origin[1],
                              width=self.box_width,
                              height=event.new)

    def _callback_snapshot(self, event):
        self.extractTopo()
        self.snapshotFrame()

    def _callback_available_topography(self, event):
        if event.new is not None:
            self.loadTopo(filename=self.data_path + event.new)
            self.snapshotFrame()

    def _callback_load_other(self, event):
        self.loadTopo(filename=self._widget_other_topography.value[0])
        self.snapshotFrame()



================================================
FILE: sandbox/modules/prototyping.py
================================================
import traceback
from .template import ModuleTemplate


class PrototypingModule(ModuleTemplate):
    """
    Class for the connectivity between Notebook plotting and sandbox image in live thread
    """
    def __init__(self, *args, **kwargs):
        # call parents' class init, use greyscale colormap as standard and extreme color labeling
        super().__init__(*args, contours=True, cmap='gist_earth_r', over='k', under='k', **kwargs)

        self.function_to_run = None
        self.active_connection = False

    def setup(self):
        frame = self.sensor.get_frame()
        if self.crop:
            frame = self.crop_frame(frame)
            frame = self.clip_frame(frame)

        self.plot.render_frame(frame)
        self.projector.frame.object = self.plot.figure

    def update(self):
        frame = self.sensor.get_frame()
        if self.crop:
            frame = self.crop_frame(frame)
            frame = self.clip_frame(frame)

        if self.active_connection:
            self.plot.ax.cla()
            try:
                self.function_to_run()
            except Exception:
                traceback.print_exc()
                self.active_connection = False

        else:
            self.plot.render_frame(frame)

        # if aruco Module is specified: update, plot aruco markers
        if self.ARUCO_ACTIVE:
            self.update_aruco()
            self.plot.plot_aruco(self.Aruco.aruco_markers)

        self.projector.trigger()  # triggers the update of the bokeh plot

    def aruco_inside(self):
        df_position = self.Aruco.aruco_markers
        xy = None
        if len(df_position) > 0:
            xy = df_position.loc[df_position.is_inside_box == True, ('box_x', 'box_y')]
            if len(xy) > 0:
                xy = xy.values[0]
            else:
                xy =None

        return xy

    def plot_sandbox(self, func):
        """
        Pass as an argument the function to run in the thread
        Args:
            func: see notebook in tutorials fro example

        Returns:

        """
        def inner1(*args, **kwargs):

            frame = self.sensor.get_frame()

            if self.crop:
                frame = self.crop_frame(frame)
                frame = self.clip_frame(frame)
            func(*args, sandbox_ax=self.plot.ax, sandbox_frame=frame, xy=self.aruco_inside(), **kwargs)

        return inner1



================================================
FILE: sandbox/modules/search_methods.py
================================================
import numpy
import matplotlib.pyplot as plt
import matplotlib
import scipy
import random
import seaborn as sns
import panel as pn
from .template import ModuleTemplate
from sandbox import set_logger
logger = set_logger(__name__)


class SearchMethodsModule(ModuleTemplate):
    """
    Module for visualization of different search techniques based on gradients and
    #TODO: have deterministic and probabilistic search methods and later combine them
    """

    def __init__(self, extent: list = None):

        self.speed_alpha = 2
        self.tolerance = 1e-10

        self.xy = (100, 100)

        self.show_frame = True
        self.search_active = False
        self.sleep = 0.4
        self.plot_contour_xy = False
        self.plot_xy = True
        self.x = None
        self.y = None
        self.x_list = []
        self.y_list = []
        self.mesh = None
        self.mesh_dx = None
        self.mesh_dy = None
        self.ymax, self.xmax = (extent[3], extent[1])
        self.margins_crop = 20
        self.step_variance = 400
        self.init_search = (100, 100)
        self.x_grad = []
        self.y_grad = []

        self.number_samples = 5000
        self.burn_in_period = 10
        self.counter_t = 0
        self.start_plotting = False
        self.point_color = "red"
        self.marker = "*"
        self.linestyle = "None"
        self.marker_size = 10
        self.direction_search = "Maximum"
        self.xy_aruco = []
        self.bins = 100

        self.activate_frame_capture = False

        self.init_variance = [self.step_variance]
        # self.init_variance = [150]
        self.step_search_covariance = 100  # step for generate a new cov
        self.memory_steps = 10  # memory steps, per 100 steps, calculate the accept again

        self.p_sample = []  # ratio of acceptance of samples
        self.counter_total = 0
        self.active_gradient_descend = True

        self.hamiltonian = True
        self.frame_hm = None
        self.mesh_hm = None
        self.mesh_dx_hm = None
        self.mesh_dy_hm = None
        self.leapfrog_step = 0.08
        self.leapfrog_points = 30

        self.options = ['None',
                        'Random walk',
                        'Random walk step',
                        'Adaptive HM',
                        'Adaptive HM step',
                        'Hamiltonian MC',
                        'Hamiltonian MC step']
        self.method = 'None'

        self.histogram = pn.pane.Matplotlib(plt.figure(), tight=False)  # , height=335)
        plt.close()
        self.trigger = None
        self.lock = None

        self.frame = None
        self.frame_norm = None

        self._create_widgets()
        logger.info("SearchMethodsModule loaded successfully")

    def update(self, sb_params: dict):
        self.frame = sb_params.get('frame')
        self.lock = sb_params.get('lock_thread')
        ax = sb_params.get('ax')
        # extent=sb_params.get('extent')
        same_frame = sb_params.get('same_frame')
        self.trigger = sb_params.get('trigger')
        if self.mesh is None:  # create a mesh for the very first time
            self.update_mesh(self.frame, margins_crop=self.margins_crop, fill_value=0)

        if self.activate_frame_capture:
            if not same_frame:
                self.update_mesh(self.frame, margins_crop=self.margins_crop, fill_value=0)
            sb_params['freeze_frame'] = False
        else:
            sb_params['freeze_frame'] = True
        marker = sb_params.get('marker')
        if len(marker) > 0:
            self.xy_aruco = marker.loc[marker.is_inside_box, ('box_x', 'box_y')].values
        else:
            self.xy_aruco = []

        self.plot(ax)

        return sb_params

    def plot(self, ax):
        self.remove_lines(ax)
        if self.active_gradient_descend:
            self.x_grad, self.y_grad = self.gradient_descent(self.xy_aruco,
                                                             self.mesh,
                                                             self.mesh_dx,
                                                             self.mesh_dy,
                                                             self.direction_search)
            for i in range(len(self.x_grad)):
                ax.plot(self.x_grad[i], self.y_grad[i], "r*-")
                ax.plot(self.x_grad[i][-1], self.y_grad[i][-1], "b*", markersize=20)

        if self.search_active:
            self.plot_search(self.method, self.xy, ax)

    def remove_lines(self, ax):
        [lines.remove() for lines in reversed(ax.lines) if isinstance(lines, matplotlib.lines.Line2D)]

    def create_mesh(self, frame, fill_value=numpy.nan, margins_crop: int = 0):
        """
        Create a mseh from the topography that can be evaluated in every point.
        Avoid conflicts between pixels(int) and floats
        Args:
            frame: kinect frame
            fill_value:
            margins_crop:

        Returns:

        """
        if margins_crop != 0:
            frame = frame[margins_crop:-margins_crop, margins_crop:-margins_crop]

        height_i, width_i = frame.shape
        width = numpy.arange(margins_crop, width_i + margins_crop)
        height = numpy.arange(margins_crop, height_i + margins_crop)
        xx, yy = numpy.meshgrid(width, height)

        points = numpy.vstack([xx.ravel(), yy.ravel()]).T
        values = frame.ravel()

        mesh = scipy.interpolate.LinearNDInterpolator(points, values, fill_value=fill_value)

        return mesh

    def update_mesh(self, frame, fill_value=numpy.nan, margins_crop=0):
        """
        create the mesh for the current frame and its derivatives
        Args:
            frame:
            fill_value:
            margins_crop:

        Returns:
        """
        der_y, der_x = numpy.gradient(frame)
        self.mesh_dx = self.create_mesh(der_x, margins_crop=margins_crop, fill_value=fill_value)
        self.mesh_dy = self.create_mesh(der_y, margins_crop=margins_crop, fill_value=fill_value)

        frame = 1.0 / numpy.sum(frame) * frame
        self.mesh = self.create_mesh(frame, margins_crop=margins_crop, fill_value=fill_value)

        hm_frame = (-1) * (numpy.log(frame))
        self.mesh_hm = self.create_mesh(hm_frame, margins_crop=margins_crop, fill_value=fill_value)
        der_y_hm, der_x_hm = numpy.gradient(hm_frame)
        self.mesh_dx_hm = self.create_mesh(der_x_hm, margins_crop=margins_crop, fill_value=fill_value)
        self.mesh_dy_hm = self.create_mesh(der_y_hm, margins_crop=margins_crop, fill_value=fill_value)

        self.frame_norm = frame
        self.frame_hm = hm_frame

        return True

    def plot_search(self, method, xy, ax):
        """
        selected over the possible options a search algorithm
        Args:
            method:
            xy:
            ax:

        Returns:

        """
        if self.plot_contour_xy:
            ax.collections = []  # TODO: Improve this
            ax = sns.kdeplot(self.x_list, self.y_list, ax=ax, color="red")
            self.trigger()

        if self.plot_xy:
            ax.plot(self.x_list,
                    self.y_list,
                    color=self.point_color,
                    marker=self.marker,
                    markersize=self.marker_size,
                    linestyle=self.linestyle)

        if method == self.options[1]:
            # self.activate_frame_capture = True
            self.x_list = []
            self.y_list = []
            self.x_list, self.y_list = self.mcmc_random(xy, self.mesh)

        elif method == self.options[2]:
            # self.activate_frame_capture = False
            if self.x is None and self.y is None:
                self.x_list = []
                self.y_list = []
                if xy is not None:
                    self.x, self.y = xy[0], xy[1]
                else:
                    self.x, self.y = self.init_search

            self.x, self.y = self.mcmc_random_step(self.mesh, self.x, self.y, ax)

        elif method == self.options[3]:
            # self.activate_frame_capture = True
            self.x_list = []
            self.y_list = []
            self.x_list, self.y_list = self.mcmc_adaptiveMH(self.mesh)

        elif method == self.options[4]:
            # self.activate_frame_capture = False
            if self.x is None and self.y is None:
                self.x_list = []
                self.y_list = []
                if xy is not None:
                    self.x, self.y = xy[0], xy[1]
                else:
                    self.x, self.y = self.init_search

            self.x, self.y = self.mcmc_adaptiveMH_step(self.mesh, self.x, self.y, ax)

        elif method == self.options[5]:
            # self.activate_frame_capture = True
            self.x_list = []
            self.y_list = []
            self.x_list, self.y_list = self.mcmc_hamiltonianMC(self.mesh_hm,
                                                               self.mesh_dx_hm,
                                                               self.mesh_dy_hm)
        elif method == self.options[6]:
            # self.activate_frame_capture = False
            if self.x is None and self.y is None:
                self.x_list = []
                self.y_list = []
                if xy is not None:
                    self.x, self.y = xy[0], xy[1]
                else:
                    self.x, self.y = self.init_search

            self.x, self.y = self.mcmc_hamiltonianMC_step(self.mesh_hm,
                                                          self.mesh_dx_hm,
                                                          self.mesh_dy_hm,
                                                          self.x,
                                                          self.y, ax)
        else:
            return False

        return True

    def gradient_descent(self, xy, mesh, dx, dy, direction):
        x_sol = []
        y_sol = []
        for i in range(len(xy)):
            x, y = xy[i]
            z1 = mesh(x, y)
            z2 = 0
            x_list = [x]
            y_list = [y]
            count = 0
            while numpy.abs(z1 - z2) > self.tolerance and count <= self.number_samples:
                z1 = mesh(x, y)
                if direction == "Maximum":
                    x = (x + self.speed_alpha * dx(x, y))
                    y = (y + self.speed_alpha * dy(x, y))
                else:
                    x = (x - self.speed_alpha * dx(x, y))
                    y = (y - self.speed_alpha * dy(x, y))

                z2 = mesh(x, y)
                x_list.append(x)
                y_list.append(y)
                count += 1
            x_sol.append(x_list)
            y_sol.append(y_list)

        return x_sol, y_sol

    def mcmc_random(self, xy, mesh):
        if len(xy) > 0:
            x, y = xy[0], xy[1]
        else:
            x, y = self.init_search

        ax = []
        ay = []

        for t in range(0, self.burn_in_period + self.number_samples):
            x_1, y_1 = numpy.random.multivariate_normal(mean=[x, y],
                                                        cov=[[self.step_variance, 0], [0, self.step_variance]])
            # if self.margins_crop < x_1 < self.xmax - self.margins_crop and
            # self.margins_crop < y_1 < self.ymax - self.margins_crop:
            x_sample = x_1
            y_sample = y_1
            accept_prob = min(1, mesh(x_sample, y_sample) / mesh(x, y) * 1.0)

            u = random.uniform(0, 1)

            if u < accept_prob:  #
                x = x_sample
                y = y_sample

            if t >= self.burn_in_period:
                ax.append(x)
                ay.append(y)

        return ax, ay

    def mcmc_random_step(self, mesh, x, y, ax):
        x_1, y_1 = numpy.random.multivariate_normal(mean=[x, y],
                                                    cov=[[self.step_variance, 0],
                                                         [0, self.step_variance]])

        # if self.margins_crop < x_1 < self.xmax - self.margins_crop and \
        #       self.margins_crop < y_1 < self.ymax - self.margins_crop:
        x_sample = x_1
        y_sample = y_1
        accept_prob = min(1, mesh(x_sample, y_sample) / mesh(x, y) * 1.0)
        u = random.uniform(0, 1)

        if self.start_plotting:
            # point = self.plot.ax.plot(x, y, "r.")
            circle1 = plt.Circle((x, y), numpy.sqrt(self.step_variance), fill=False, linewidth=5)
            circle2 = plt.Circle((x, y), numpy.sqrt(self.step_variance) * 2, fill=False, linewidth=5)
            ax.add_artist(circle1)
            ax.add_artist(circle2)
            arrow = ax.arrow(x, y,
                             (x_sample - x),
                             (y_sample - y),
                             length_includes_head=True,
                             width=1,
                             color="black")
            self.trigger()
            plt.pause(self.sleep)

        if u < accept_prob:  #
            x = x_sample
            y = y_sample
            # green
            if self.start_plotting:
                arrow.set_color("green")
                self.trigger()
                plt.pause(self.sleep)
        else:
            if self.start_plotting:
                arrow.set_color("red")
                self.trigger()
                plt.pause(self.sleep)

        if self.start_plotting:
            circle1.remove()
            circle2.remove()
            arrow.remove()

        if self.counter_t >= self.burn_in_period:
            self.start_plotting = True
            self.x_list.append(x)
            self.y_list.append(y)

        self.counter_t += 1

        return x, y

    def mcmc_adaptiveMH(self, mesh):
        x, y = (100, 100)
        z = mesh
        m = 50  # burn in period
        # n = 5000  # sample numbers, and n/L must be an int
        K_s = 100  # the original cov
        L = 100  # memory steps, per 100 steps, calculate the accept again
        a = 0.23  # resable accept_prob
        epil = 0.01
        K = []
        K.append(K_s)
        step = 100  # step for generate a new cov

        bx_sample = []
        by_sample = []
        P_sample = []  # for the number of accpet probi

        for t in range(0, int(self.number_samples / L)):
            count = 0  # count how many samples have been accept

            if t == 0:
                i = 0
            if t > 0:
                i = m

            while i < L + m:
                x_1, y_1 = numpy.random.multivariate_normal(mean=[x, y], cov=[[K[t], 0], [0, 100]])
                # print(x_1)
                # if self.margins_crop < x_1 < self.xmax - self.margins_crop and
                # self.margins_crop < y_1 < self.ymax - self.margins_crop:
                x_sample = x_1
                y_sample = y_1
                # print(x_sample)

                accept_prob = min(1, z(x_sample, y_sample) / z(x, y) * 1.0)
                # print('accept_prob:',accept_prob)
                u = random.uniform(0, 1)
                # print('u:',u)
                # ax_sample.append(x_sample)
                # ay_sample.append(y_sample)

                if t > 0:  # no burn in period

                    if u < accept_prob:  #
                        x = x_sample
                        y = y_sample
                        count = count + 1

                    bx_sample.append(x)
                    by_sample.append(y)

                if t == 0:  # only the first time has burn in period

                    if u < accept_prob:  #
                        x = x_sample
                        y = y_sample

                        if i >= m:
                            count = count + 1  # after burn in period, the number of acceptance

                    if i >= m:
                        bx_sample.append(x)
                        by_sample.append(y)

                i = i + 1

            P_accept = count * 1.0 / L
            P_sample.append(P_accept)
            tau = len(P_sample)
            K.append(K[t])
            if a - epil < P_accept < a + epil:
                K[t + 1] = K[t]
            else:
                if tau >= 2 and numpy.abs(a - P_sample[tau - 1]) > numpy.abs(a - P_sample[tau - 2]):
                    K[tau - 1] = K[tau - 2]
                K[tau] = numpy.abs(numpy.random.normal(K[tau - 1], step))

        return bx_sample, by_sample

    def mcmc_adaptiveMH_step(self, mesh, x, y, ax):
        a = 0.23  # resable accept_prob
        epil = 0.01

        x_1, y_1 = numpy.random.multivariate_normal(mean=[x, y],
                                                    cov=[[self.init_variance[-1], 0], [0, self.step_variance]])
        # if self.margins_crop < x_1 < self.xmax - self.margins_crop and
        # self.margins_crop < y_1 < self.ymax - self.margins_crop:
        x_sample = x_1
        y_sample = y_1
        accept_prob = min(1, mesh(x_sample, y_sample) / mesh(x, y) * 1.0)

        u = random.uniform(0, 1)

        if self.counter_t == 0:
            if u < accept_prob:  #
                x = x_sample
                y = y_sample

            if self.counter_total >= self.burn_in_period:
                self.x_list.append(x)
                self.y_list.append(y)
                self.counter_t += 1
                self.counter_total = 1

            self.counter_total += 1

        if self.counter_t > 0:
            self.start_plotting = True
            if self.start_plotting:
                ellipse1 = matplotlib.patches.Ellipse((x, y),
                                                      numpy.sqrt(self.init_variance[-1]),
                                                      numpy.sqrt(self.step_variance),
                                                      fill=False,
                                                      linewidth=5)
                ellipse2 = matplotlib.patches.Ellipse((x, y),
                                                      2 * numpy.sqrt(self.init_variance[-1]),
                                                      2 * numpy.sqrt(self.step_variance),
                                                      fill=False,
                                                      linewidth=5)
                ax.add_artist(ellipse1)
                ax.add_artist(ellipse2)
                arrow = ax.arrow(x, y,
                                 (x_sample - x),
                                 (y_sample - y),
                                 length_includes_head=True,
                                 width=1,
                                 color="black")
                self.trigger()
                plt.pause(self.sleep)

            if u < accept_prob:  #
                x = x_sample
                y = y_sample
                self.x_list.append(x)
                self.y_list.append(y)
                self.counter_total += 1
                if self.start_plotting:
                    arrow.set_color("green")
                    self.trigger()
                    plt.pause(self.sleep)
            else:
                if self.start_plotting:
                    arrow.set_color("red")
                    self.trigger()
                    plt.pause(self.sleep)

            self.counter_t += 1

        if self.start_plotting:
            ellipse1.remove()
            ellipse2.remove()
            arrow.remove()

        if self.counter_t >= self.memory_steps:
            p_accept = self.counter_total * 1.0 / self.memory_steps
            self.p_sample.append(p_accept)
            tau = len(self.p_sample)

            if a - epil < p_accept < a + epil:
                self.init_variance.append(self.init_variance[-1])
                self.counter_t = 1
                self.counter_total = 1
            else:
                # TODO: check if is closer to a
                # making sure the  is better than the previous one
                if tau >= 2 and numpy.abs(a - self.p_sample[tau - 1]) > numpy.abs(a - self.p_sample[tau - 2]):
                    self.init_variance[-1] = self.init_variance[-2]

                self.init_variance.append(numpy.abs(numpy.random.normal(self.init_variance[-1],
                                                                        self.step_search_covariance)))
                self.counter_t = 1
                self.counter_total = 1

        return x, y

    def mcmc_hamiltonianMC(self, mesh, dx_mesh, dy_mesh, n=700, l=10):
        x, y = self.init_search
        x_list = [x]
        y_list = [y]
        # for t in range(self.number_samples):
        for t in range(n):
            # sample random momentum
            proposed_momentum_vector = numpy.random.multivariate_normal(mean=[0, 0],
                                                                        cov=[[self.step_variance, 0],
                                                                             [0, self.step_variance]])
            # proposed_momentum_vector = numpy.random.normal(0, self.step_variance, 2)
            # leapfrog
            # if the xStar[,] is inside the frame or not
            # if self.margins_crop < x < self.xmax - self.margins_crop and
            # self.margins_crop < y < self.ymax - self.margins_crop:
            # gradient
            gradient_xy = numpy.array([dx_mesh(x, y), dy_mesh(x, y)])
            # momentum, make a half step for momentum at the beginning
            momentum_vector = proposed_momentum_vector - (self.leapfrog_step * gradient_xy) / 2.0
            # lepfrog steps
            x_sample, y_sample = x, y
            # for j in range(self.leapfrog_points - 1):
            for j in range(l):
                # postion/sample,full step for position/sample
                x_sample, y_sample = numpy.array([x_sample, y_sample]) + self.leapfrog_step * momentum_vector
                #                 #if 0 <= xStar[0] < xmax - 2 and 0 <= xStar[1] < ymax - 2:
                #                 # find new gradient
                gradient_xy = numpy.array([dx_mesh(x_sample, y_sample), dy_mesh(x_sample, y_sample)])
                # momentum,full step of momentum
                momentum_vector = momentum_vector - self.leapfrog_step * gradient_xy
            # last half step
            x_sample, y_sample = numpy.array([x_sample, y_sample]) + self.leapfrog_step * momentum_vector
            # if 0 <= xStar[0] < xmax - 2 and 0 <= xStar[1] < ymax - 2:
            gradient_xy = numpy.array([dx_mesh(x_sample, y_sample), dy_mesh(x_sample, y_sample)])
            momentum_vector = momentum_vector - (self.leapfrog_step * gradient_xy) / 2.0

            # evaluate energy
            # if 0 <= xStar[0] < xmax - 2 and 0 <= xStar[1] < ymax - 2:
            potential_energy = mesh(x_sample, y_sample)
            previous_potential_energy = mesh(x, y)

            #### Kinetic energy function  KE = (p @ p) / 2.0
            previous_kinetic_e = numpy.vdot(proposed_momentum_vector, proposed_momentum_vector) / 2.0
            kinetic_e = numpy.vdot(momentum_vector, momentum_vector) / 2.0

            # acceptance
            accept_prob = min(1, numpy.exp(- potential_energy + previous_potential_energy -
                                           kinetic_e + previous_kinetic_e))
            uc = numpy.random.rand()

            if uc < accept_prob and \
                    self.margins_crop < x_sample < self.xmax - self.margins_crop and \
                    self.margins_crop < y_sample < self.ymax - self.margins_crop:
                x = x_sample
                y = y_sample
                x_list.append(x)
                y_list.append(y)

        return x_list, y_list

    def mcmc_hamiltonianMC_step(self, mesh, dx_mesh, dy_mesh, x, y, ax):
        # for t in range(self.number_samples):
        # sample random momentum
        proposed_momentum_vector = numpy.random.multivariate_normal(mean=[0, 0],
                                                                    cov=[[self.step_variance, 0],
                                                                         [0, self.step_variance]])
        # proposed_momentum_vector = numpy.random.normal(0, self.step_variance, 2)
        # leapfrog
        # if the xStar[,] is inside the frame or not
        # if self.margins_crop < x < self.xmax - self.margins_crop and self.margins_crop < y < self.ymax - self.margins_crop:
        # gradient
        gradient_xy = numpy.array([dx_mesh(x, y), dy_mesh(x, y)])
        # momentum, make a half step for momentum at the beginning
        momentum_vector = proposed_momentum_vector - (self.leapfrog_step * gradient_xy) / 2.0
        # lepfrog steps
        x_sample, y_sample = x, y
        x_temp = [x]
        y_temp = [y]
        # for j in range(self.leapfrog_points - 1):
        for j in range(self.leapfrog_points):
            # postion/sample,full step for position/sample
            x_sample, y_sample = numpy.array([x_sample, y_sample]) + self.leapfrog_step * momentum_vector
            #                 #if 0 <= xStar[0] < xmax - 2 and 0 <= xStar[1] < ymax - 2:
            #                 # find new gradient
            gradient_xy = numpy.array([dx_mesh(x_sample, y_sample), dy_mesh(x_sample, y_sample)])
            # momentum,full step of momentum
            momentum_vector = momentum_vector - self.leapfrog_step * gradient_xy
            x_temp.append(x_sample)
            y_temp.append(y_sample)
        # last half step
        ax.plot(x_temp, y_temp, "k*-")
        self.trigger()
        plt.pause(self.sleep)

        x_sample, y_sample = numpy.array([x_sample, y_sample]) + self.leapfrog_step * momentum_vector
        # if 0 <= xStar[0] < xmax - 2 and 0 <= xStar[1] < ymax - 2:
        gradient_xy = numpy.array([dx_mesh(x_sample, y_sample), dy_mesh(x_sample, y_sample)])
        momentum_vector = momentum_vector - (self.leapfrog_step * gradient_xy) / 2.0

        # evaluate energy
        # if 0 <= xStar[0] < xmax - 2 and 0 <= xStar[1] < ymax - 2:
        potential_energy = mesh(x_sample, y_sample)
        previous_potential_energy = mesh(x, y)

        # Kinetic energy function  KE = (p @ p) / 2.0
        previous_kinetic_e = numpy.vdot(proposed_momentum_vector, proposed_momentum_vector) / 2.0
        kinetic_e = numpy.vdot(momentum_vector, momentum_vector) / 2.0

        # acceptance
        accept_prob = min(1, numpy.exp(- potential_energy + previous_potential_energy - kinetic_e + previous_kinetic_e))
        uc = numpy.random.rand()

        if uc < accept_prob and \
                self.margins_crop < x_sample < self.xmax - self.margins_crop and \
                self.margins_crop < y_sample < self.ymax - self.margins_crop:
            x = x_sample
            y = y_sample
            self.x_list.append(x)
            self.y_list.append(y)
        # step_plot.remove()

        return x, y

    def hist_distribution(self):
        """
        Histogram showing the distribution of the sampled points and the targer
        Returns:

        """
        # x = self.frame_norm.sum(axis=0)
        # y = self.frame_norm.sum(axis=1)

        fig = plt.figure(figsize=(10, 10))
        ax_x = fig.add_subplot(121)
        ax_x = sns.distplot(self.x_list, bins=self.bins, ax=ax_x)
        # ax_x = sns.histplot(self.x_list, bins=self.bins, ax=ax_x)

        # ax_x.hist(self.x_list, bins=self.bins)
        # ax_x.plot(range(len(x)), x, "r--")
        ax_x.set_title('x_direction')

        ax_y = fig.add_subplot(122)
        # ax_y.hist((self.y_list), bins=self.bins)
        # ax_y = sns.histplot(self.y_list, bins=self.bins, ax=ax_y)
        ax_y = sns.distplot(self.y_list, bins=self.bins, ax=ax_y)
        # ax_y.plot(range(len(y)), y, "r--")
        ax_y.set_title('y direction')

        return fig

    # Widgets

    def show_widgets(self):
        widget = pn.Column(self._widget_activate_gradient_descend,
                           self._widget_optimum,
                           self._widget_speed_gradient_descend,
                           "<b>Frame controller</b>",
                           self._widget_activate_frame_capture,
                           self._widget_refresh_frame)

        column = pn.Column("#Simulation options",
                           self._widget_selector,
                           self._widget_search_active,
                           "<b>Controllers</b>",
                           self._widget_sleep,
                           self._widget_margins_crop,
                           "<b>Visualization options</b>",
                           self._widget_plot_points,
                           self._widget_plot_contour,
                           "<b>Modify constants</b> ",
                           self._widget_variance,
                           self._widget_number_samples,
                           "<b>Adaptive options</b>",
                           self._widget_memory_steps,
                           "<b> Hamiltonian options",
                           self._widget_leapfrog_step,
                           self._widget_leapfrog_points
                           )
        histogram = pn.WidgetBox(self._widget_histogram_refresh,
                                 self.histogram)
        row = pn.Row(column, widget)

        tabs = pn.Tabs(('Controllers', row),
                       ("Histogram plot", histogram),
                       )

        return tabs

    def _create_widgets(self):
        self._widget_selector = pn.widgets.Select(
            name='Select search method',
            options=self.options,
            value=self.method
        )
        self._widget_selector.param.watch(self._callback_selector, 'value', onlychanged=False)

        self._widget_search_active = pn.widgets.RadioButtonGroup(name='Start the search', options=['Start', 'Stop'],
                                                                 value='Stop')
        self._widget_search_active.param.watch(self._callback_search_active, 'value',
                                               onlychanged=False)

        self._widget_plot_points = pn.widgets.Checkbox(name='Show the points', value=self.plot_xy)
        self._widget_plot_points.param.watch(self._callback_plot_points, 'value', onlychanged=False)

        self._widget_plot_contour = pn.widgets.Checkbox(name='Show the contours of the points',
                                                        value=self.plot_contour_xy)
        self._widget_plot_contour.param.watch(self._callback_plot_contour, 'value', onlychanged=False)

        self._widget_show_frame = pn.widgets.Checkbox(name='Show the frame', value=self.show_frame)
        self._widget_show_frame.param.watch(self._callback_show_frame, 'value', onlychanged=False)

        self._widget_activate_frame_capture = pn.widgets.Checkbox(name='Update frame realtime',
                                                                  value=self.activate_frame_capture)
        self._widget_activate_frame_capture.param.watch(self._callback_activate_frame_capture, 'value',
                                                        onlychanged=False)

        self._widget_activate_gradient_descend = pn.widgets.Checkbox(name='Activate gradient descend',
                                                                     value=self.active_gradient_descend)
        self._widget_activate_gradient_descend.param.watch(self._callback_active_gradient_descend, 'value',
                                                           onlychanged=False)

        self._widget_refresh_frame = pn.widgets.Button(name="Manually refresh mesh", button_type="success")
        self._widget_refresh_frame.param.watch(self._callback_refresh_frame, 'clicks',
                                               onlychanged=False)

        self._widget_sleep = pn.widgets.FloatSlider(name='Step delay (seconds)',
                                                    value=self.sleep,
                                                    start=0.0,
                                                    end=5.0,
                                                    step=0.05)
        self._widget_sleep.param.watch(self._callback_sleep, 'value', onlychanged=False)

        self._widget_histogram_refresh = pn.widgets.Button(name="Manually refresh histogram", button_type="success")
        self._widget_histogram_refresh.param.watch(self._callbak_histogram_refresh, 'clicks',
                                                   onlychanged=False)

        self._widget_variance = pn.widgets.Spinner(name='Proposed Variance', value=self.step_variance, step=10)
        self._widget_variance.param.watch(self._callback_variance, 'value', onlychanged=False)

        self._widget_speed_gradient_descend = pn.widgets.FloatSlider(name='Speed convergence',
                                                                     start=0.0,
                                                                     end=10.0,
                                                                     value=self.speed_alpha)
        self._widget_speed_gradient_descend.param.watch(self._callback_speed_gradient_descend, 'value',
                                                        onlychanged=False)

        self._widget_number_samples = pn.widgets.Spinner(name='Number of samples', value=self.number_samples)
        self._widget_number_samples.param.watch(self._callback_number_samples, 'value',
                                                onlychanged=False)

        self._widget_memory_steps = pn.widgets.Spinner(name='Memory steps', value=self.memory_steps)
        self._widget_memory_steps.param.watch(self._callback_memory_steps, 'value',
                                              onlychanged=False)

        self._widget_leapfrog_step = pn.widgets.FloatSlider(name='Leapfrog_step',
                                                            start=0.0,
                                                            end=10.0,
                                                            value=self.leapfrog_step)
        self._widget_leapfrog_step.param.watch(self._callback_leapfrog_step, 'value',
                                               onlychanged=False)

        self._widget_leapfrog_points = pn.widgets.Spinner(name='Leapfrog points', value=self.leapfrog_points)
        self._widget_leapfrog_points.param.watch(self._callback_leapfrog_points, 'value',
                                                 onlychanged=False)

        self._widget_optimum = pn.widgets.Select(name='Select convergence to local optimum',
                                                 options=["Maximum", "Minimum"],
                                                 value=self.direction_search
                                                 )
        self._widget_optimum.param.watch(self._callback_optimum, 'value', onlychanged=False)

        self._widget_margins_crop = pn.widgets.Spinner(name='Crop margins to reduce search area',
                                                       value=self.margins_crop)
        self._widget_margins_crop.param.watch(self._callback_margins_crop, 'value',
                                              onlychanged=False)

    def _callback_selector(self, event):
        self.x = None
        self.y = None
        self.x_list = []
        self.y_list = []
        self.method = event.new

    def _callback_search_active(self, event):
        if event.new == 'Start':
            self.search_active = True
        else:
            self.search_active = False

    def _callback_plot_points(self, event):
        self.plot_xy = event.new

    def _callback_plot_contour(self, event):
        self.plot_contour_xy = event.new

    def _callback_show_frame(self, event):
        self.show_frame = event.new

    def _callback_activate_frame_capture(self, event):
        self.activate_frame_capture = event.new

    def _callback_active_gradient_descend(self, event):
        self.active_gradient_descend = event.new

    def _callback_refresh_frame(self, event):
        self.lock.acquire()
        self.update_mesh(self.frame, margins_crop=self.margins_crop, fill_value=0)
        self.lock.release()

    def _callback_sleep(self, event):
        self.sleep = event.new

    def _callbak_histogram_refresh(self, event):
        self.lock.acquire()
        self.histogram.object = self.hist_distribution()
        self.lock.acquire()

    def _callback_variance(self, event):
        self.step_variance = event.new

    def _callback_speed_gradient_descend(self, event):
        self.speed_alpha = event.new

    def _callback_number_samples(self, event):
        self.number_samples = event.new

    def _callback_memory_steps(self, event):
        self.memory_steps = event.new

    def _callback_leapfrog_step(self, event):
        self.leapfrog_step = event.new

    def _callback_leapfrog_points(self, event):
        self.leapfrog_points = event.new

    def _callback_optimum(self, event):
        self.direction_search = event.new

    def _callback_margins_crop(self, event):
        self.margins_crop = event.new



================================================
FILE: sandbox/modules/template.py
================================================
from abc import ABC, abstractmethod


class ModuleTemplate(ABC):

    def __init__(self, extent: list = None):
        self.lock = None
        if extent is not None:
            self.vmin = extent[4]
            self.vmax = extent[5]
        pass

    @abstractmethod
    def update(self, sb_params: dict):
        active_cmap = sb_params.get('active_cmap')
        active_contours = sb_params.get('active_contours')
        frame = sb_params.get('frame')
        extent = sb_params.get('extent')
        ax = sb_params.get('ax')
        cmap = sb_params.get('cmap')
        norm = sb_params.get('norm')
        marker = sb_params.get('marker')

        ### Do all the calculations from the data
        self.plot(frame, ax)
        ### pass the data to the plot to paint in the axes, this will return the axes and a colormap

        return sb_params
        pass

    @abstractmethod
    def plot(self, frame, ax):
        pass

    #only if using panel widgets for the module
    @abstractmethod
    def show_widgets(self):
        pass



================================================
FILE: sandbox/modules/topography.py
================================================
import panel as pn
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import numpy as np
from skimage import measure
import skimage.transform
from matplotlib.patches import Path, PathPatch
from .template import ModuleTemplate
from sandbox import set_logger, _package_dir
logger = set_logger(__name__)


class TopoModule(ModuleTemplate):
    """
    Module for simple Topography visualization without computing a geological model
    """

    def __init__(self, extent: list = None, **kwargs):
        pn.extension()
        self.max_height = 800
        self.center = 0
        self.min_height = -200
        self.sea = False
        self.sea_contour = False
        self.sea_level_patch = None
        self.col = None  # Check if image is loaded
        self.type_fluid = ["water",
                           "lava",
                           "slime"]
        self.name_fluid = self.type_fluid[0]
        self.fluid = None  # Image to create the texture
        self.texture = None  # resultant texture after masking with path
        if extent is not None:
            self.extent = extent
            self.load_fluid()
        self.animate = True
        self._anim = 0  # animation
        # Settings for sea level polygon
        self.path = None
        self.sea_level_polygon_alpha = 0.7
        self.sea_level_polygon_line_thickness = 2.
        self.sea_level_polygon_line_color = mcolors.to_hex("blue")
        self.sea_zorder = 1000
        self.sea_fill = True

        self._marker_contour_val = None
        self.side_flooding = False
        logger.info("TopoModule loaded successfully")

    def update(self, sb_params: dict):
        """
        Acquire the information from th sb_params dict and call the functions to modify
        the frame and/or plot in the axes
        Args:
            sb_params:
        Returns:
        """
        frame = sb_params.get('frame')
        extent = sb_params.get('extent')
        ax = sb_params.get('ax')
        frame, extent = self.normalize_topography(frame, extent,
                                                  min_height=self.min_height,
                                                  max_height=self.max_height)
        marker = sb_params.get('marker')
        if len(marker) > 0:
            self._marker_contour_val = marker.loc[marker.is_inside_box, ('box_x', 'box_y')].values[0]
        else:
            self._marker_contour_val = None

        self.extent = extent
        self.plot(frame, ax, extent)
        sb_params['frame'] = frame
        sb_params['ax'] = ax
        sb_params['extent'] = extent

        return sb_params

    def plot(self, frame, ax, extent):
        """
        Deals with everything related to plotting in the axes
        Args:
            frame: Sandbox frame
            ax: axes of matplotlib figure to paint on
        Returns:

        """
        if self.sea or self.sea_contour:
            self._delete_path()
            #if self._center != self.center:
            # TODO: Avoid unnecessary calculation of new paths
            try:
                if self.side_flooding and self._marker_contour_val is not None:
                    self.path, self.center = self.find_single_path(frame, self._marker_contour_val)
                else:
                    self.path = self.create_paths(frame, self.center)
            except Exception as e:
                logger.error(e, exc_info=True)

            if self.sea and self.path is not None:
                self.set_texture(self.path)
                if self.col is None:
                    self.col = ax.imshow(self.texture, origin='lower', aspect='auto', zorder=self.sea_zorder+1,
                                         alpha=self.sea_level_polygon_alpha)
                else:
                    self.col.set_data(self.texture)
                    self.col.set_alpha(self.sea_level_polygon_alpha)
            else:
                self._delete_image()

            if self.sea_contour and self.path is not None:
                # Add contour polygon of sea level
                self.sea_level_patch = PathPatch(self.path,
                                                 alpha=self.sea_level_polygon_alpha,
                                                 linewidth=self.sea_level_polygon_line_thickness,
                                                 # ec=self.sea_level_polygon_line_color,
                                                 color=self.sea_level_polygon_line_color,
                                                 zorder=self.sea_zorder,
                                                 fill=self.sea_fill)
                # ContourLinesModule
                ax.add_patch(self.sea_level_patch)
        else:
            self._delete_image()
            self._delete_path()

    def _delete_image(self):
        """Remove sea-texture"""
        if self.col:
            self.col.remove()
        self.col = None

    def _delete_path(self):
        """remove sea-level patch, if previously defined"""
        if self.sea_level_patch:
            self.sea_level_patch.remove()
        self.sea_level_patch = None

    def set_texture(self, path):
        x = np.arange(0, self.extent[1] - 1, 1)
        y = np.arange(0, self.extent[3] - 1, 1)
        xx, yy = np.meshgrid(x, y)
        xy = np.vstack((xx.ravel(), yy.ravel())).T
        mask = path.contains_points(xy)
        present = xy[mask]
        self.texture = self.fluid.copy()
        if self.animate:
            self.animate_texture()
        for i in range(len(present)):
            self.texture[present[i][1], present[i][0], -1] = 1

    def animate_texture(self):
        """
        Move the texture image to give the appearance of moving like waves
        Returns:
        """
        A = self.texture.shape[0] / 5
        w = 2.0 / self.texture.shape[1]
        shift = lambda x: A * np.sin(2.0 * np.pi * (x + self._anim) * w)
        for i in range(self.texture.shape[1]):
            vector = np.roll(np.arange(0, self.texture.shape[0]), int(round(shift(i))))
            self.texture[:, i][:] = self.texture[:, i][:][vector]
        self._anim += 1

    @staticmethod
    def normalize_topography(frame, extent, min_height, max_height):
        """
        Change the max an min value of the frame and normalize accordingly
        Args:
            frame: sensor frame
            extent: sensor extent
            max_height: Target max height
            min_height: Target min height

        Returns:
            normalized frame and new extent

        """
        # first position the frame in 0 if the original extent is not in 0
        if extent[-2] != 0:
            displ = 0 - extent[-2]
            frame = frame - displ
        # calculate how much we need to move the frame so the 0 value correspond to the approximate 0 in the frame
        # min_height assuming is under 0.

        if min_height < 0:
            displace = min_height * (-1) * (extent[-1] - extent[-2]) / (max_height - min_height)
            frame = frame - displace
            extent[-1] = extent[-1] - displace
            extent[-2] = extent[-2] - displace
            # now we set 2 regions. One above sea level and one below sea level. So now we can normalize these two
            # regions above 0
            frame[frame > 0] = frame[frame > 0] * (max_height / extent[-1])
            # below 0
            frame[frame < 0] = frame[frame < 0] * (min_height / extent[-2])
        elif min_height > 0:
            frame = frame * (max_height - min_height) / (extent[-1] - extent[-2])
            frame = frame + min_height  # just displace all up to start in min_height
        elif min_height == 0:
            frame = frame * max_height / (extent[-1])
        else:
            raise AttributeError
        extent[-1] = max_height  # self.plot.vmax = max_height
        extent[-2] = min_height  # self.plot.vmin = min_height
        return frame, extent

    @staticmethod
    def reshape(image, shape: tuple):
        """
        Reshape any image to the desired shape. Change shape of numpy array to desired shape
        Args:
            image:
            shape: sandbox shape
        Returns:
             reshaped frame
        """
        return skimage.transform.resize(image, shape,
                                        order=3, mode='edge', anti_aliasing=True, preserve_range=False)

    def load_fluid(self):
        image = plt.imread(_package_dir+'/modules/img/'+self.name_fluid+'.jpg')
        fluid = self.reshape(image, (self.extent[3], self.extent[1]))  # height, width
        # convert RGB image to RGBA
        self.fluid = np.dstack((fluid, np.zeros((self.extent[3], self.extent[1]))))

    @staticmethod
    def create_paths(frame, contour_val):
        """Create compound path for given contour value
        Args:
            frame: sensor frame
            contour_val (float): value of contour
        Returns:
            path: matplotlib.Path object for contour polygon
        """
        # create padding
        frame_padded = np.pad(frame, pad_width=1, mode='constant', constant_values=np.max(frame) + 1)
        contours = measure.find_contours(frame_padded.T, contour_val)

        # combine values
        contour_comb = np.concatenate(contours, axis=0)

        # generate codes to close polygons
        # First: link all
        codes = [Path.LINETO for _ in range(contour_comb.shape[0])]
        # Next: find ends of each contour and close
        index = 0
        for contour in contours:
            codes[index] = Path.MOVETO
            index += len(contour)
            codes[index - 1] = Path.CLOSEPOLY
        path = Path(contour_comb, codes)
        return path

    @staticmethod
    def find_single_path(frame: tuple, point: tuple):
        """
        From a frame, find the point that contains the point and start changing the contour val excluding isolated
        contours
        Args:
            frame: frame of sandbox
            point: Aruco point coordinate (x, y)
        Returns:
            path:
            contour_val:
        """
        # create padding
        contour_val = frame[int(point[1]), int(point[0])]  # To be sure that there will be a contour in that point
        frame_padded = np.pad(frame, pad_width=1, mode='constant', constant_values=np.max(frame) + 1)
        contours = measure.find_contours(frame_padded.T, contour_val)
        # Look 5 pixels in the surrounding (2 each side) if a path contains any of those points
        surrounding_points = [(point[0]-2 + i, point[1]-2 + j) for i in range(5) for j in range(5)]
        for con in contours:
            codes = [Path.LINETO for _ in range(len(con))]
            codes[0] = Path.MOVETO
            codes[-1] = Path.CLOSEPOLY
            path = Path(con, codes)

            if True in path.contains_points(surrounding_points):
                return path, contour_val
        logger.warning("No path includes the point %s" % point)
        return None, None

    def show_widgets(self):
        self._create_widgets()
        panel = pn.Column("### Widgets for Topography normalization",
                          pn.Row(pn.Column(self._widget_min_height,
                                           self._widget_max_height,
                                           self._widget_sea,
                                           pn.Row(self._widget_sea_contour,
                                                  self._widget_fill),
                                           self._widget_sea_level),
                                 pn.Column(self._widget_animation,
                                           self._widget_type_fluid,
                                           self._widget_transparency,
                                           self._widget_color
                                           )
                                 ),
                          " #### Use aruco marker for local filling",
                          self._widget_aruco
                          )
        return panel

    def _create_widgets(self):
        self._widget_min_height = pn.widgets.Spinner(name="Minimum height of topography", value=self.min_height,
                                                     step=20)
        self._widget_min_height.param.watch(self._callback_min_height, 'value', onlychanged=False)

        self._widget_max_height = pn.widgets.Spinner(name="Maximum height of topography", value=self.max_height,
                                                     step=20)
        self._widget_max_height.param.watch(self._callback_max_height, 'value', onlychanged=False)

        self._widget_sea_level = pn.widgets.IntSlider(name="Set sea level height",
                                                      start=self.min_height,
                                                      end=self.max_height,
                                                      step=5,
                                                      value=self.center,)
        self._widget_sea_level.param.watch(self._callback_sea_level, 'value',
                                           onlychanged=False)

        self._widget_sea = pn.widgets.Checkbox(name='Show sea level',
                                               value=self.sea)
        self._widget_sea.param.watch(self._callback_see, 'value',
                                     onlychanged=False)

        self._widget_sea_contour = pn.widgets.Checkbox(name='Show sea level contour',
                                                       value=self.sea_contour, width_policy='min' )
        self._widget_sea_contour.param.watch(self._callback_see_contour, 'value',
                                             onlychanged=False)

        self._widget_fill = pn.widgets.Checkbox(name='Fill contour', value=self.sea_fill, width_policy='min')
        self._widget_fill.param.watch(self._callback_fill, 'value', onlychanged=False)

        self._widget_type_fluid = pn.widgets.Select(name='Select type of texture for the fluid',
                                                    options=self.type_fluid,
                                                    size=3,
                                                    value=self.name_fluid)
        self._widget_type_fluid.param.watch(self._callback_select_fluid, 'value',
                                            onlychanged=False)

        self._widget_transparency = pn.widgets.Spinner(name="Select transparency", value=self.sea_level_polygon_alpha,
                                                       step=0.05)
        self._widget_transparency.param.watch(self._callback_transparency, 'value', onlychanged=False)

        self._widget_color = pn.widgets.ColorPicker(name='Color level contour', value=self.sea_level_polygon_line_color)
        self._widget_color.param.watch(self._callback_color, 'value', onlychanged=False)

        self._widget_animation = pn.widgets.Checkbox(name='Animate wave movement', value=self.animate)
        self._widget_animation.param.watch(self._callback_animation, 'value', onlychanged=False)

        self._widget_aruco = pn.widgets.Checkbox(name='Local level', value=self.side_flooding)
        self._widget_aruco.param.watch(self._callback_aruco, 'value', onlychanged=False)

    def _callback_aruco(self, event):
        self.side_flooding = event.new
        self._widget_sea_level.disabled = event.new

    def _callback_fill(self, event): self.sea_fill = event.new

    def _callback_transparency(self, event): self.sea_level_polygon_alpha = event.new

    def _callback_color(self, event): self.sea_level_polygon_line_color = event.new

    def _callback_animation(self, event): self.animate = event.new

    def _callback_select_fluid(self, event):
        self.name_fluid = event.new
        self.load_fluid()

    def _callback_min_height(self, event):
        self.min_height = event.new
        if self.center < self.min_height:
            self.center = self.min_height + 1
            self._widget_sea_level.value = self.center + 1
        self._widget_sea_level.start = event.new + 1

    def _callback_max_height(self, event):
        self.max_height = event.new
        if self.center > self.max_height:
            self.center = self.max_height - 1
            self._widget_sea_level.value = self.center - 1
        self._widget_sea_level.end = event.new - 1

    def _callback_sea_level(self, event):
        self.center = event.new

    def _callback_see(self, event):
        self.sea = event.new

    def _callback_see_contour(self, event):
        self.sea_contour = event.new



================================================
FILE: sandbox/modules/block_module/__init__.py
================================================
from .block_module import BlockModule
from .rms_grid import RMS_Grid

if __name__ == '__main__':
    pass


================================================
FILE: sandbox/modules/block_module/block_module.py
================================================
import numpy
import pickle
import matplotlib
import skimage
import panel as pn
from sandbox.modules.template import ModuleTemplate

class BlockModule(ModuleTemplate):
    # child class of Model

    def __init__(self, calibrationdata, sensor, projector, crop=True, **kwarg):
        super().__init__(calibrationdata, sensor, projector, crop, **kwarg)  # call parent init
        self.block_dict = {}
        self.cmap_dict = {}
        self.displayed_dataset_key = "mask"  # variable to choose displayed dataset in runtime
        self.rescaled_block_dict = {}
        self.reservoir_topography = None
        self.rescaled_reservoir_topography = None
        self.show_reservoir_topo = False
        self.num_contours_reservoir_topo = 10  # number of contours in
        self.reservoir_topography_topo_levels = None  # set in setup and in widget.
        self.result = None  # stores the output array of the current frame

        # #rescaled Version of Livecell information. masking has to be done after scaling because the scaling does not support masked arrays
        # self.rescaled_data_mask = None
        self.index = None  # index to find the cells in the rescaled block modules, corresponding to the topography in the sandbox
        self.widget = None  # widget to change models in runtime
        self.min_sensor_offset = 0
        self.max_sensor_offset = 0
        self.minmax_sensor_offset = 0
        self.original_sensor_min = 0
        self.original_sensor_max = 0
        self.mask_threshold = 0.5  # set the threshold for the mask array, interpolated between 0.0 and 1.0 #obsolete!

        self.num_contour_steps = 20

    def setup(self):
        if self.block_dict is None:
            print("No model loaded. Load a model first with load_module_vip(infile)")
            pass
        elif self.cmap_dict is None:
            self.set_colormaps()
        self.rescale_blocks()
        # self.rescale_mask() #nearest neighbour? obsolete! mask is now part of the block_dict

        self.displayed_dataset_key = list(self.block_dict)[1]

        self.plot.contours_color = 'w'  # Adjust default contour color

        self.projector.frame.object = self.plot.figure  # Link figure to projector

        self.calculate_reservoir_contours()

    def update(self):
        # with self.lock:
        frame = self.sensor.get_frame()

        if self.crop is True:
            frame = self.crop_frame(frame)
        depth_mask = self.depth_mask(frame)

        ###workaround:resize depth mask
        # depth_mask = skimage.transform.resize(
        #    depth_mask,
        #    (
        #    self.block_dict[self.displayed_dataset_key].shape[0], self.block_dict[self.displayed_dataset_key].shape[1]),
        #    order=0
        # )

        frame = self.clip_frame(frame)

        ##workaround: reshape frame to array size, not the other way around!
        #  frame = skimage.transform.resize(
        #          frame,
        #          (self.block_dict[self.displayed_dataset_key].shape[0], self.block_dict[self.displayed_dataset_key].shape[1]),
        #          order=1
        #  )

        if self.displayed_dataset_key is 'mask':  # check if there is a data_mask, TODO: try except key error
            data = self.rescaled_block_dict[self.displayed_dataset_key]
        #  data = self.block_dict[self.displayed_dataset_key]
        else:  # apply data mask

            data = numpy.ma.masked_where(self.rescaled_block_dict['mask'] < self.mask_threshold,
                                         self.rescaled_block_dict[self.displayed_dataset_key]
                                         )

        zmin = self.calib.s_min
        zmax = self.calib.s_max

        index = (frame - zmin) / (zmax - zmin) * (data.shape[2] - 1.0)  # convert the z dimension to index
        index = index.round()  # round to next integer
        self.index = index.astype('int')

        # querry the array:
        i, j = numpy.indices(data[..., 0].shape)  # create arrays with the indices in x and y
        self.result = data[i, j, self.index]

        self.result = numpy.ma.masked_array(self.result, mask=depth_mask)  # apply the depth mask

        self.plot.ax.cla()

        self.plot.vmin = zmin
        self.plot.vmax = zmax
        cmap = self.cmap_dict[self.displayed_dataset_key][0]
        cmap.set_over('black')
        cmap.set_under('black')
        cmap.set_bad('black')

        norm = self.cmap_dict[self.displayed_dataset_key][1]
        min = self.cmap_dict[self.displayed_dataset_key][2]
        max = self.cmap_dict[self.displayed_dataset_key][3]
        self.plot.cmap = cmap
        self.plot.norm = norm
        self.plot.render_frame(self.result, contourdata=frame, vmin=min, vmax=max)  # plot the current frame

        if self.show_reservoir_topo is True:
            self.plot.ax.contour(self.rescaled_reservoir_topography, levels=self.reservoir_topography_topo_levels)
        # render and display
        # self.plot.ax.axis([0, self.calib.s_frame_width, 0, self.calib.s_frame_height])
        # self.plot.ax.set_axis_off()

        self.projector.trigger()
        # return True

    def load_model(self, model_filename):
        """
        loads a regular grid dataset parsed and prepared with the RMS Grid class.
        the pickled list contains 2 entries:
        1.  The regridded Block dictionary
        2.  a 2d array of the lateral size of the blocks with the z values of the uppermost layer
            (= the shape of the reservoir top surface)
        Args:
            model_filename: string with the path to the file to load

        Returns: nothing, changes in place the

        """
        data_list = pickle.load(open(model_filename, "rb"))
        self.block_dict = data_list[0]
        self.reservoir_topography = data_list[1]
        print('Datasets loaded: ', self.block_dict.keys())

    def create_cmap(self, clist):
        """
        create a matplotlib colormap object from a list of discrete colors
        :param clist: list of colors
        :return: colormap
        """

        cmap = matplotlib.colors.LinearSegmentedColormap.from_list('default', clist, N=256)
        return cmap

    def create_norm(self, vmin, vmax):
        norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)
        return norm

    def set_colormap(self, key=None, cmap='jet', norm=None):
        min = numpy.nanmin(self.block_dict[key].ravel())  # find min ignoring NaNs
        max = numpy.nanmax(self.block_dict[key].ravel())

        if isinstance(cmap, str):  # get colormap by name
            cmap = matplotlib.cm.get_cmap(name=cmap, lut=None)

        if norm is None:
            norm = self.create_norm(min, max)

        self.cmap_dict[key] = [cmap, norm, min, max]

    def set_colormaps(self, cmap=None, norm=None):
        """
        iterates over all datasets and checks if a colormap has been set. if no colormaps exists it creates one.
        default colormap: jet
        :param cmap:
        :param norm:
        :return:
        """
        for key in self.block_dict.keys():
            if key not in self.cmap_dict.keys():  # add entry if not already in cmap_dict
                self.set_colormap(key)

    def rescale_blocks(self):  # scale the blocks xy Size to the cropped size of the sensor
        for key in self.block_dict.keys():
            rescaled_block = skimage.transform.resize(
                self.block_dict[key],
                (self.calib.s_frame_height, self.calib.s_frame_width),
                order=0
            )

            self.rescaled_block_dict[key] = rescaled_block

        if self.reservoir_topography is not None:  # rescale the topography map
            self.rescaled_reservoir_topography = skimage.transform.resize(
                self.reservoir_topography,
                (self.calib.s_frame_height, self.calib.s_frame_width),
                order=0  # nearest neighbour
            )

    def rescale_mask(self):  # scale the blocks xy Size to the cropped size of the sensor
        rescaled_mask = skimage.transform.resize(
            self.data_mask,
            (self.calib.s_frame_height, self.calib.s_frame_width),
            order=0
        )
        self.rescaled_data_mask = rescaled_mask

    def clear_models(self):
        self.block_dict = {}

    def clear_rescaled_models(self):
        self.rescaled_block_dict = {}

    def clear_cmaps(self):
        self.cmap_dict = {}

    def calculate_reservoir_contours(self):
        min = numpy.nanmin(self.rescaled_reservoir_topography.ravel())
        max = numpy.nanmax(self.rescaled_reservoir_topography.ravel())
        step = (max - min) / float(self.num_contours_reservoir_topo)
        print(min, max, step)
        self.reservoir_topography_topo_levels = numpy.arange(min, max, step=step)

    def widget_mask_threshold(self):
        """
        displays a widget to adjust the mask threshold value

        """
        pn.extension()
        widget = pn.widgets.FloatSlider(name='mask threshold (values smaller than the set threshold will be masked)',
                                        start=0.0, end=1.0, step=0.01, value=self.mask_threshold)

        widget.param.watch(self._callback_mask_threshold, 'value', onlychanged=False)

        return widget

    def _callback_mask_threshold(self, event):
        """
        callback function for the widget to update the self.
        :return:
        """
        # used to be with self.lock:
        self.pause()
        self.mask_threshold = event.new
        self.resume()

    def show_widgets(self):
        self.original_sensor_min = self.calib.s_min  # store original sensor values on start
        self.original_sensor_max = self.calib.s_max

        widgets = pn.WidgetBox(self._widget_model_selector(),
                               self._widget_sensor_top_slider(),
                               self._widget_sensor_bottom_slider(),
                               self._widget_sensor_position_slider(),
                               self._widget_show_reservoir_topography(),
                               self._widget_reservoir_contours_num(),
                               self._widget_contours_num()
                               )

        panel = pn.Column("### Interaction widgets", widgets)
        self.widget = panel
        return panel

    def _widget_model_selector(self):
        """
        displays a widget to toggle between the currently active dataset while the sandbox is running
        Returns:

        """
        pn.extension()
        widget = pn.widgets.RadioButtonGroup(name='Model selector',
                                             options=list(self.block_dict.keys()),
                                             value=self.displayed_dataset_key,
                                             button_type='success')

        widget.param.watch(self._callback_selection, 'value', onlychanged=False)

        return widget

    def _callback_selection(self, event):
        """
        callback function for the widget to update the self.
        :return:
        """
        # used to be with self.lock:
        self.pause()
        self.displayed_dataset_key = event.new
        self.resume()

    def _widget_sensor_top_slider(self):
        """
        displays a widget to toggle between the currently active dataset while the sandbox is running
        Returns:

        """
        pn.extension()
        widget = pn.widgets.IntSlider(name='offset top of the model ', start=-250, end=250, step=1, value=0)

        widget.param.watch(self._callback_top_slider, 'value', onlychanged=False)

        return widget

    def _callback_top_slider(self, event):
        """
        callback function for the widget to update the self.
        :return:
        """
        # used to be with self.lock:
        self.pause()
        self.min_sensor_offset = event.new
        self._update_sensor_calib()
        self.resume()

    def _widget_sensor_bottom_slider(self):
        """
        displays a widget to toggle between the currently active dataset while the sandbox is running
        Returns:

        """
        pn.extension()
        widget = pn.widgets.IntSlider(name='offset bottom of the model ', start=-250, end=250, step=1, value=0)

        widget.param.watch(self._callback_bottom_slider, 'value', onlychanged=False)

        return widget

    def _callback_bottom_slider(self, event):
        """
        callback function for the widget to update the self.
        :return:
        """
        # used to be with self.lock:
        self.pause()
        self.max_sensor_offset = event.new
        self._update_sensor_calib()
        self.resume()

    def _widget_sensor_position_slider(self):
        """
        displays a widget to toggle between the currently active dataset while the sandbox is running
        Returns:

        """
        pn.extension()
        widget = pn.widgets.IntSlider(name='offset the model in vertical direction ', start=-250, end=250, step=1,
                                      value=0)

        widget.param.watch(self._callback_position_slider, 'value', onlychanged=False)

        return widget

    def _callback_position_slider(self, event):
        """
        callback function for the widget to update the self.
        :return:
        """
        # used to be with self.lock:
        self.pause()
        self.minmax_sensor_offset = event.new
        self._update_sensor_calib()
        self.resume()

    def _update_sensor_calib(self):
        self.calib.s_min = self.original_sensor_min + self.min_sensor_offset + self.minmax_sensor_offset
        self.calib.s_max = self.original_sensor_max + self.max_sensor_offset + self.minmax_sensor_offset

    def _widget_show_reservoir_topography(self):
        widget = pn.widgets.Toggle(name='show reservoir top contours',
                                   value=self.show_reservoir_topo,
                                   button_type='success')
        widget.param.watch(self._callback_show_reservoir_topography, 'value', onlychanged=False)

        return widget

    def _callback_show_reservoir_topography(self, event):
        self.pause()
        self.show_reservoir_topo = event.new
        self._update_sensor_calib()
        self.resume()

    def _widget_reservoir_contours_num(self):
        """ Shows a widget that allows to change the contours step size"""

        widget = pn.widgets.IntSlider(name='number of contours in the reservoir topography',
                                      start=0,
                                      end=100,
                                      step=1,
                                      value=round(self.num_contours_reservoir_topo))

        widget.param.watch(self._callback_reservoir_contours_num, 'value', onlychanged=False)
        return widget

    def _callback_reservoir_contours_num(self, event):
        self.pause()
        self.num_contours_reservoir_topo = event.new
        self.calculate_reservoir_contours()
        self.resume()

    def _widget_contours_num(self):
        """ Shows a widget that allows to change the contours step size"""

        widget = pn.widgets.IntSlider(name='number of contours in the sandbox',
                                      start=0,
                                      end=100,
                                      step=1,
                                      value=self.num_contour_steps)

        widget.param.watch(self._callback_contours_num, 'value', onlychanged=False)
        return widget

    def _callback_contours_num(self, event):
        self.pause()
        self.plot.vmin = self.calib.s_min
        self.plot.vmax = self.calib.s_max
        self.num_contour_steps = event.new
        self.plot.contours_step = (self.plot.vmax - self.plot.vmin) / float(self.num_contour_steps)
        self.resume()



================================================
FILE: sandbox/modules/block_module/rms_grid.py
================================================
import numpy
import scipy
import pickle

class RMS_Grid():

    def __init__(self):
        """ Class to load RMS grids and convert them to a regular grid to use them in the Block module
        """

        self.nx = None
        self.ny = None
        self.nz = None
        self.block_dict = {}
        self.regular_grid_dict = {}
        # default resolution for the regriding. default is kinect v2 resolution and 100 depth levels
        self.regriding_resolution = [424, 512, 100]
        self.coords_x = None  # arrays to store coordinates of cells
        self.coords_y = None
        self.coords_z = None
        self.data_mask = None  # stores the Livecell information from the VIP  File
        self.reservoir_topography = None
        self.method = 'nearest'
        self.mask_method = 'nearest'

    def load_model_vip(self, infile):
        # parse the file
        f = open(infile, "r")

        while True:  # skip header
            l = f.readline().split()
            if len(l) > 2 and l[1] == "Size":
                break

        # n cells
        l = f.readline().split()
        self.nx = int(l[1])
        self.ny = int(l[2])
        self.nz = int(l[3])
        print('nx ny, nz:')
        print(self.nx, self.ny, self.nz)

        while True:  # skip to coordinates
            l = f.readline().split()
            if len(l) > 0 and l[0] == "CORP":
                print("loading cell points")
                self.parse_coordinates(f, self.nx, self.ny, self.nz)
                print("coordinates loaded")
                break

        while True:  # skip to Livecell
            l = f.readline().split()
            if len(l) > 0 and l[0] == "LIVECELL":
                self.parse_livecells_vip(f, self.nx, self.ny, self.nz)
                print("Livecells loaded")
                break

        # parse the data
        while True:  # skip to key
            line = f.readline()
            l = line.split()
            if line == '':  # check if the end of file was reached and exit the loop if this is the case
                print('end of file reached')
                break

            elif len(l) >= 2 and l[1] == "VALUE":
                key = l[0]
                try:
                    # parse one block of data and store irt under the given key in the dictionary
                    self.parse_block_vip(f, self.block_dict, key, self.nx, self.ny, self.nz)
                except:
                    print('loading block "' + key + "' failed: not a valid VALUE Format")
                    break

        f.close()  # close the file

    def parse_coordinates(self, current_file, nx, ny, nz):
        f = current_file

        self.coords_x = numpy.empty((nx, ny, nz))
        self.coords_y = numpy.empty((nx, ny, nz))
        self.coords_z = numpy.empty((nx, ny, nz))

        for z in range(nz):

            print('processing coordinates in layer ' + str(z))
            for i in range(3):  # skip Layer(nz)
                f.readline()

            for y in range(ny):
                # print(y)
                for x in range(nx):

                    # skip cell header (each cell)
                    l = f.readline().split()
                    while l[0] == 'C':  # skip header
                        l = f.readline().split()

                    px = []
                    py = []
                    pz = []
                    for i in range(4):
                        # read the corner points
                        px.append(float(l[0]))
                        py.append(float(l[1]))
                        pz.append(float(l[2]))

                        px.append(float(l[3]))
                        py.append(float(l[4]))
                        pz.append(float(l[5]))
                        l = f.readline().split()  # read in next line

                    # calculate the arithmetic mean of all 4 corners elementwise:
                    self.coords_x[x, y, z] = numpy.mean(numpy.array(px))
                    self.coords_y[x, y, z] = numpy.mean(numpy.array(py))
                    self.coords_z[x, y, z] = numpy.mean(numpy.array(pz))

    def parse_livecells_vip(self, current_file, nx, ny, nz):
        data_np = numpy.empty((nx, ny, nz))

        # store pointer position to come back to after the values per line were determined
        pointer = current_file.tell()
        line = current_file.readline().split()
        values_per_line = len(line)
        # print(values_per_line)
        current_file.seek(pointer)  # go back to pointer position

        for z in range(nz):
            for y in range(ny):
                x = 0
                for n in range(nx // values_per_line):  # read values in full lines
                    l = current_file.readline().split()
                    if len(l) < values_per_line:  # if there is an empty line, skip to the next
                        l = current_file.readline().split()
                    for i in range(values_per_line):  # iterate values in the line
                        value = l[i]
                        data_np[x, y, z] = float(value)
                        x = x + 1  # iterate x

                if nx % values_per_line > 0:
                    l = current_file.readline().split()
                    for i in range(nx % values_per_line):  # read values in the last not full line
                        value = l[i]
                        data_np[x, y, z] = float(value)
                        x = x + 1

        self.block_dict['mask'] = data_np

    def parse_block_vip(self, current_file, value_dict, key, nx, ny, nz):
        data_np = numpy.empty((nx, ny, nz))

        f = current_file

        pointer = f.tell()  # store pointer position to come back to after the values per line were determined
        for i in range(3):  # skip header
            f.readline()

        l = f.readline().split()
        values_per_line = len(l)
        # print('values per line: ' + str(values_per_line))
        blocklength = nx // values_per_line
        f.seek(pointer)  # go back to pointer position

        # read block data
        if (nx % values_per_line) != 0:
            blocklength = blocklength + 1

        for z in range(nz):
            for i in range(3):
                l = f.readline().split()
            for y in range(ny):
                x = 0

                for line in range(blocklength):
                    l = f.readline().split()
                    if len(l) < 1:
                        l = f.readline().split()  # skip empty line that occurs if value is dividable by 8
                    while l[0] == "C":
                        l = f.readline().split()  # skip the header lines(can vary from file to file)
                    for i in range(len(l)):
                        try:
                            value = l[i]
                            # data.loc[x,y,z] = value
                            # values.append(value)
                            data_np[x, y, z] = float(value)
                            x = x + 1
                        except:
                            print('failed to parse value ', x, y, z)
                            print(l)
                            x = x + 1
        # print(x, y + 1, z + 1)  # to check if all cells are loaded

        print(key + ' loaded')
        value_dict[key] = data_np

        return True

    def convert_to_regular_grid(self, method=None, mask_method=None):
        # prepare the cell coordinates of the original grid
        x = self.coords_x.ravel()
        y = self.coords_y.ravel()
        z = self.coords_z.ravel()

        # prepare the coordinates of the regular grid cells:
        # define extent:
        xmin = x.min()
        xmax = x.max()
        ymin = y.min()
        ymax = y.max()
        zmin = z.min()
        zmax = z.max()

        # prepare the regular grid:
        gx = numpy.linspace(xmin, xmax, num=self.regriding_resolution[0])
        gy = numpy.linspace(ymin, ymax, num=self.regriding_resolution[1])
        gz = numpy.linspace(zmin, zmax, num=self.regriding_resolution[2])

        a, b, c = numpy.meshgrid(gx, gy, gz)

        grid = numpy.stack((a.ravel(), b.ravel(), c.ravel()), axis=1)

        # iterate over all loaded datasets:
        for key in self.block_dict.keys():
            print("processing grid: ", key)
            if key == 'mask':
                self.block_dict[key][:, :, 0] = 0.0
                self.block_dict[key][0, :,
                :] = 0.0  # exchange outer limits of the box so that nearest neighbour returns zeros outside the box
                self.block_dict[key][-1, :, :] = 0.0
                self.block_dict[key][:, -1, :] = 0.0
                self.block_dict[key][:, 0, :] = 0.0
                self.block_dict[key][:, :, -1] = 0.0
                self.block_dict[key][:, :, 0] = 0.0

            data = self.block_dict[key].ravel()

            if key == 'mask':  # for the mask, fill NaN values with 0.0
                if mask_method == None:
                    mask_method = self.mask_method  # 'linear' or 'nearest'
                data = numpy.nan_to_num(data)  # this does not work with nearest neighbour!

                interp_grid = scipy.interpolate.griddata((x, y, z), data, grid, method=mask_method)

            else:
                if method == None:
                    method = self.method
                interp_grid = scipy.interpolate.griddata((x, y, z), data, grid, method=method)

            # save to dictionary:
            # reshape to originasl dimension BUT WITH X AND Y EXCHANGEND
            self.regular_grid_dict[key] = interp_grid.reshape([self.regriding_resolution[1],
                                                               self.regriding_resolution[0],
                                                               self.regriding_resolution[2]]
                                                              )
            print("done!")

    def create_reservoir_topo(self):
        """
        creates a 2d array with the z values of the reservoir top (the z coordinate of the top layer in the array
        """
        # create 2d grid for lookup:
        x = self.coords_x.ravel()
        y = self.coords_y.ravel()

        # prepare the coordinates of the regular grid cells:
        # define extent:
        xmin = x.min()
        xmax = x.max()
        ymin = y.min()
        ymax = y.max()

        # prepare the regular grid:
        gx = numpy.linspace(xmin, xmax, num=self.regriding_resolution[0])
        gy = numpy.linspace(ymin, ymax, num=self.regriding_resolution[1])
        a, b = numpy.meshgrid(gx, gy)

        grid2d = numpy.stack((a.ravel(), b.ravel()), axis=1)

        top_x = self.coords_x[:, :, 0].ravel()
        top_y = self.coords_y[:, :, 0].ravel()
        top_z = self.coords_z[:, :, 0].ravel()

        topo = scipy.interpolate.griddata((top_x, top_y), top_z, grid2d)  # this has to be done with the linear method!
        self.reservoir_topography = topo.reshape([self.regriding_resolution[1], self.regriding_resolution[0]])

    def save(self, filename):
        """
    saves a list with two entries to a pickle:

        [0] the regridded data blocks in a dictionary
        [1] the reservoir topography map

        """
        pickle.dump([self.regular_grid_dict, self.reservoir_topography], open(filename, "wb"))




================================================
FILE: sandbox/modules/devito/__init__.py
================================================
from sandbox import set_logger
logger = set_logger(__name__)
try:
    from .seismic_sandbox import SeismicModule
except:
    logger.warning("Devito dependencies not installed")


================================================
FILE: sandbox/modules/devito/model.py
================================================
#######################################
#Script taken  from https://github.com/devitocodes/devito/tree/master/examples/seismic
#######################################
import numpy as np
from sympy import sin, Abs, finite_diff_weights as fd_w

from devito import (Grid, SubDomain, Function, Constant, warning,
                    SubDimension, Eq, Inc, Operator, div)
from devito.builtins import initialize_function, gaussian_smooth, mmax, mmin
from devito.tools import as_tuple

__all__ = ['SeismicModel', 'Model', 'ModelElastic',
           'ModelViscoelastic', 'ModelViscoacoustic']


def initialize_damp(damp, padsizes, spacing, abc_type="damp", fs=False):
    """
    Initialize damping field with an absorbing boundary layer.

    Parameters
    ----------
    damp : Function
        The damping field for absorbing boundary condition.
    nbl : int
        Number of points in the damping layer.
    spacing :
        Grid spacing coefficient.
    mask : bool, optional
        whether the dampening is a mask or layer.
        mask => 1 inside the domain and decreases in the layer
        not mask => 0 inside the domain and increase in the layer
    """

    eqs = [Eq(damp, 1.0 if abc_type == "mask" else 0.0)]
    for (nbl, nbr), d in zip(padsizes, damp.dimensions):
        if not fs or d is not damp.dimensions[-1]:
            dampcoeff = 1.5 * np.log(1.0 / 0.001) / (nbl)
            # left
            dim_l = SubDimension.left(name='abc_%s_l' % d.name, parent=d,
                                      thickness=nbl)
            pos = Abs((nbl - (dim_l - d.symbolic_min) + 1) / float(nbl))
            val = dampcoeff * (pos - sin(2*np.pi*pos)/(2*np.pi))
            val = -val if abc_type == "mask" else val
            eqs += [Inc(damp.subs({d: dim_l}), val/d.spacing)]
        # right
        dampcoeff = 1.5 * np.log(1.0 / 0.001) / (nbr)
        dim_r = SubDimension.right(name='abc_%s_r' % d.name, parent=d,
                                   thickness=nbr)
        pos = Abs((nbr - (d.symbolic_max - dim_r) + 1) / float(nbr))
        val = dampcoeff * (pos - sin(2*np.pi*pos)/(2*np.pi))
        val = -val if abc_type == "mask" else val
        eqs += [Inc(damp.subs({d: dim_r}), val/d.spacing)]

    Operator(eqs, name='initdamp')()


class PhysicalDomain(SubDomain):

    name = 'physdomain'

    def __init__(self, so, fs=False):
        super(PhysicalDomain, self).__init__()
        self.so = so
        self.fs = fs

    def define(self, dimensions):
        map_d = {d: d for d in dimensions}
        if self.fs:
            map_d[dimensions[-1]] = ('middle', self.so, 0)
        return map_d


class FSDomain(SubDomain):

    name = 'fsdomain'

    def __init__(self, so):
        super(FSDomain, self).__init__()
        self.size = so

    def define(self, dimensions):
        """
        Definition of the upper section of the domain for wrapped indices FS.
        """

        return {d: (d if not d == dimensions[-1] else ('left', self.size))
                for d in dimensions}


class GenericModel(object):
    """
    General model class with common properties
    """
    def __init__(self, origin, spacing, shape, space_order, nbl=20,
                 dtype=np.float32, subdomains=(), bcs="damp", grid=None,
                 fs=False):
        self.shape = shape
        self.space_order = space_order
        self.nbl = int(nbl)
        self.origin = tuple([dtype(o) for o in origin])
        self.fs = fs
        # Default setup
        origin_pml = [dtype(o - s*nbl) for o, s in zip(origin, spacing)]
        shape_pml = np.array(shape) + 2 * self.nbl

        # Model size depending on freesurface
        physdomain = PhysicalDomain(space_order, fs=fs)
        subdomains = subdomains + (physdomain,)
        if fs:
            fsdomain = FSDomain(space_order)
            subdomains = subdomains + (fsdomain,)
            origin_pml[-1] = origin[-1]
            shape_pml[-1] -= self.nbl

        # Origin of the computational domain with boundary to inject/interpolate
        # at the correct index
        if grid is None:
            # Physical extent is calculated per cell, so shape - 1
            extent = tuple(np.array(spacing) * (shape_pml - 1))
            self.grid = Grid(extent=extent, shape=shape_pml, origin=origin_pml,
                             dtype=dtype, subdomains=subdomains)
        else:
            self.grid = grid

        self._physical_parameters = set()
        self.damp = None
        self._initialize_bcs(bcs=bcs)

    def _initialize_bcs(self, bcs="damp"):
        # Create dampening field as symbol `damp`
        if self.nbl == 0:
            self.damp = 1 if bcs == "mask" else 0
            return

        # First initialization
        init = self.damp is None
        # Get current Function if alread yinitialized
        self.damp = self.damp or Function(name="damp", grid=self.grid)
        if callable(bcs):
            bcs(self.damp, self.nbl)
        else:
            re_init = ((bcs == "mask" and mmin(self.damp) == 0) or
                       (bcs == "damp" and mmax(self.damp) == 1))
            if init or re_init:
                if re_init and not init:
                    bcs_o = "damp" if bcs == "mask" else "mask"
                    warning("Re-initializing damp profile from %s to %s" % (bcs_o, bcs))
                    warning("Model has to be created with `bcs=\"%s\"`"
                            "for this WaveSolver" % bcs)
                initialize_damp(self.damp, self.padsizes, self.spacing,
                                abc_type=bcs, fs=self.fs)
        self._physical_parameters.update(['damp'])

    @property
    def padsizes(self):
        """
        Padding size for each dimension.
        """
        padsizes = [(self.nbl, self.nbl) for _ in range(self.dim-1)]
        padsizes.append((0 if self.fs else self.nbl, self.nbl))
        return padsizes

    def physical_params(self, **kwargs):
        """
        Return all set physical parameters and update to input values if provided
        """
        known = [getattr(self, i) for i in self.physical_parameters]
        return {i.name: kwargs.get(i.name, i) or i for i in known}

    def _gen_phys_param(self, field, name, space_order, is_param=True,
                        default_value=0):
        if field is None:
            return default_value
        if isinstance(field, np.ndarray):
            function = Function(name=name, grid=self.grid, space_order=space_order,
                                parameter=is_param)
            initialize_function(function, field, self.padsizes)
        else:
            function = Constant(name=name, value=field, dtype=self.grid.dtype)
        self._physical_parameters.update([name])
        return function

    @property
    def physical_parameters(self):
        return as_tuple(self._physical_parameters)

    @property
    def dim(self):
        """
        Spatial dimension of the problem and model domain.
        """
        return self.grid.dim

    @property
    def spacing(self):
        """
        Grid spacing for all fields in the physical model.
        """
        return self.grid.spacing

    @property
    def space_dimensions(self):
        """
        Spatial dimensions of the grid
        """
        return self.grid.dimensions

    @property
    def spacing_map(self):
        """
        Map between spacing symbols and their values for each `SpaceDimension`.
        """
        return self.grid.spacing_map

    @property
    def dtype(self):
        """
        Data type for all assocaited data objects.
        """
        return self.grid.dtype

    @property
    def domain_size(self):
        """
        Physical size of the domain as determined by shape and spacing
        """
        return tuple((d-1) * s for d, s in zip(self.shape, self.spacing))


class SeismicModel(GenericModel):
    """
    The physical model used in seismic inversion processes.

    Parameters
    ----------
    origin : tuple of floats
        Origin of the model in m as a tuple in (x,y,z) order.
    spacing : tuple of floats
        Grid size in m as a Tuple in (x,y,z) order.
    shape : tuple of int
        Number of grid points size in (x,y,z) order.
    space_order : int
        Order of the spatial stencil discretisation.
    vp : array_like or float
        Velocity in km/s.
    nbl : int, optional
        The number of absorbin layers for boundary damping.
    bcs: str or callable
        Absorbing boundary type ("damp" or "mask") or initializer.
    dtype : np.float32 or np.float64
        Defaults to np.float32.
    epsilon : array_like or float, optional
        Thomsen epsilon parameter (0<epsilon<1).
    delta : array_like or float
        Thomsen delta parameter (0<delta<1), delta<epsilon.
    theta : array_like or float
        Tilt angle in radian.
    phi : array_like or float
        Asymuth angle in radian.
    b : array_like or float
        Buoyancy.
    vs : array_like or float
        S-wave velocity.
    qp : array_like or float
        P-wave attenuation.
    qs : array_like or float
        S-wave attenuation.
    """
    _known_parameters = ['vp', 'damp', 'vs', 'b', 'epsilon', 'delta',
                         'theta', 'phi', 'qp', 'qs', 'lam', 'mu']

    def __init__(self, origin, spacing, shape, space_order, vp, nbl=20, fs=False,
                 dtype=np.float32, subdomains=(), bcs="mask", grid=None, **kwargs):
        super(SeismicModel, self).__init__(origin, spacing, shape, space_order, nbl,
                                           dtype, subdomains, grid=grid, bcs=bcs, fs=fs)

        # Initialize physics
        self._initialize_physics(vp, space_order, **kwargs)

        # User provided dt
        self._dt = kwargs.get('dt')
        # Some wave equation need a rescaled dt that can't be infered from the model
        # parameters, such as isoacoustic OT4 that can use a dt sqrt(3) larger than
        # isoacoustic OT2. This property should be set from a wavesolver or after model
        # instanciation only via model.dt_scale = value.
        self._dt_scale = 1

    def _initialize_physics(self, vp, space_order, **kwargs):
        """
        Initialize physical parameters and type of physics from inputs.
        The types of physics supported are:
        - acoustic: [vp, b]
        - elastic: [vp, vs, b] represented through Lame parameters [lam, mu, b]
        - visco-acoustic: [vp, b, qp]
        - visco-elastic: [vp, vs, b, qs]
        - vti: [vp, epsilon, delta]
        - tti: [epsilon, delta, theta, phi]
        """
        params = []
        # Buoyancy
        b = kwargs.get('b', 1)

        # Initialize elastic with Lame parametrization
        if 'vs' in kwargs:
            vs = kwargs.pop('vs')
            self.lam = self._gen_phys_param((vp**2 - 2. * vs**2)/b, 'lam', space_order,
                                            is_param=True)
            self.mu = self._gen_phys_param(vs**2 / b, 'mu', space_order, is_param=True)
        else:
            # All other seismic models have at least a velocity
            self.vp = self._gen_phys_param(vp, 'vp', space_order)
        # Initialize rest of the input physical parameters
        for name in self._known_parameters:
            if kwargs.get(name) is not None:
                field = self._gen_phys_param(kwargs.get(name), name, space_order)
                setattr(self, name, field)
                params.append(name)

    @property
    def _max_vp(self):
        if 'vp' in self._physical_parameters:
            return mmax(self.vp)
        else:
            return np.sqrt(mmin(self.b) * (mmax(self.lam) + 2 * mmax(self.mu)))

    @property
    def _thomsen_scale(self):
        # Update scale for tti
        if 'epsilon' in self._physical_parameters:
            return np.sqrt(1 + 2 * mmax(self.epsilon))
        return 1

    @property
    def dt_scale(self):
        return self._dt_scale

    @dt_scale.setter
    def dt_scale(self, val):
        self._dt_scale = val

    @property
    def _cfl_coeff(self):
        """
        Courant number from the physics and spatial discretization order.
        The CFL coefficients are described in:
        - https://doi.org/10.1137/0916052 for the elastic case
        - https://library.seg.org/doi/pdf/10.1190/1.1444605 for the acoustic case
        """
        # Elasic coefficient (see e.g )
        if 'lam' in self._physical_parameters or 'vs' in self._physical_parameters:
            coeffs = fd_w(1, range(-self.space_order//2+1, self.space_order//2+1), .5)
            c_fd = sum(np.abs(coeffs[-1][-1])) / 2
            return np.sqrt(self.dim) / self.dim / c_fd
        a1 = 4  # 2nd order in time
        coeffs = fd_w(2, range(-self.space_order, self.space_order+1), 0)[-1][-1]
        return np.sqrt(a1/float(self.grid.dim * sum(np.abs(coeffs))))

    @property
    def critical_dt(self):
        """
        Critical computational time step value from the CFL condition.
        """
        # For a fixed time order this number decreases as the space order increases.
        #
        # The CFL condtion is then given by
        # dt <= coeff * h / (max(velocity))
        dt = self._cfl_coeff * np.min(self.spacing) / (self._thomsen_scale*self._max_vp)
        dt = self.dtype("%.3e" % (self.dt_scale * dt))
        if self._dt:
            assert self._dt <= dt
            return self._dt
        return dt

    def update(self, name, value):
        """
        Update the physical parameter param.
        """
        try:
            param = getattr(self, name)
        except AttributeError:
            # No physical parameter with tha name, create it
            setattr(self, name, self._gen_phys_param(name, value, self.space_order))
            return
        # Update the square slowness according to new value
        if isinstance(value, np.ndarray):
            if value.shape == param.shape:
                param.data[:] = value[:]
            elif value.shape == self.shape:
                initialize_function(param, value, self.nbl)
            else:
                raise ValueError("Incorrect input size %s for model" % value.shape +
                                 " %s without or %s with padding" % (self.shape,
                                                                     param.shape))
        else:
            param.data = value

    @property
    def m(self):
        """
        Squared slowness.
        """
        return 1 / (self.vp * self.vp)

    @property
    def dm(self):
        """
        Create a simple model perturbation from the velocity as `dm = div(vp)`.
        """
        dm = Function(name="dm", grid=self.grid, space_order=self.space_order)
        Operator(Eq(dm, div(self.vp)), subs=self.spacing_map)()
        return dm

    def smooth(self, physical_parameters, sigma=5.0):
        """
        Apply devito.gaussian_smooth to model physical parameters.

        Parameters
        ----------
        physical_parameters : string or tuple of string
            Names of the fields to be smoothed.
        sigma : float
            Standard deviation of the smoothing operator.
        """
        model_parameters = self.physical_params()
        for i in physical_parameters:
            gaussian_smooth(model_parameters[i], sigma=sigma)
        return


# For backward compatibility
Model = SeismicModel
ModelElastic = SeismicModel
ModelViscoelastic = SeismicModel
ModelViscoacoustic = SeismicModel



================================================
FILE: sandbox/modules/devito/seismic_sandbox.py
================================================
from sandbox.modules.template import ModuleTemplate
import matplotlib.pyplot as plt
from matplotlib.figure import Figure
from matplotlib.axes import Axes
from mpl_toolkits.axes_grid1 import make_axes_locatable
import numpy as np
from scipy import ndimage
from matplotlib import cm
import panel as pn
from sandbox.modules.load_save_topography import LoadSaveTopoModule
from .model import Model
from .source import RickerSource, TimeAxis, Receiver
from sandbox import set_logger
logger = set_logger(__name__)
try:
    from devito import TimeFunction, Eq, solve, Operator
except ImportError:
    logger.warning("Devito not installed. SeismicModule will not work", exc_info=True)


class SeismicModule(ModuleTemplate):
    """ Follow the link to see the code that inspired the module
    https://nbviewer.jupyter.org/github/devitocodes/devito/blob/master/examples/seismic/tutorials/01_modelling.ipynb"""
    def __init__(self, extent: list = None, **kwargs):
        """Importing packages and setting correctly the path to the devito package, this beacuse we need the examples"""
        self.Load_Area = LoadSaveTopoModule(extent=extent, **kwargs)
        self.vp = None  # Normalized or smoothed or None topography to be the velocity model
        self.model: Model = None  # the model
        self.time_range = None  # the time of the simulation
        self.src = None  # the ricker source
        self.u = None  # wavefield time function
        self.pde = None  # PDE to solve. Wave equation with corresponding discretizations
        self.stencil = None  # a time marching updating equation known as a stencil using customized SymPy functions
        self.src_coordinates = []
        self.src_term = []  # all sources together
        self.rec = None
        self.rec_term = []  # all receivers

        # After constructing all the necessary expressions for updating the wavefield,
        # injecting the source term and interpolating onto the receiver points, we can now create the Devito operator
        self.op = None
        self.n_frames_speed = 10
        self.frequency = 0.025  # Source peak frequency is 25Hz (0.025 kHz)
        # self.aruco_sources_coord = []
        # For the cropping, because when normalizing the velocities dont work
        self.crop = True
        self.xy_aruco = []
        # for the plotting
        self.timeslice = 0
        self.threshold = 0.03
        self.field = None

        self.p_velocity = True
        self.ready_velocity = False
        self.p_wave = True
        self.ready_wave = False

        self.framerate = 10
        self._vp = None
        self._w = None
        self.real_time = False
        self.model_extent = None
        self.frame = None
        self.extent = None
        self.max_wave_frame = 1

        # Widgets
        self.lock = None
        self.figure = Figure()
        self.axes = Axes(self.figure, [0., 0., 1., 1.])
        self.figure.add_axes(self.axes)
        self.panel_figure = pn.pane.Matplotlib(self.figure, tight=True)
        plt.close(self.figure)  # close figure to prevent inline display
        logger.info("SeismicModule loaded successfully")

    def update(self, sb_params: dict):
        frame = sb_params.get('frame')
        ax = sb_params.get('ax')
        marker = sb_params.get('marker')
        self.extent = sb_params.get('extent')[:4]
        self.lock = sb_params.get("lock_thread")
        sb_params = self.Load_Area.update(sb_params)
        if self.crop:
            self.frame = np.transpose(self.crop_frame(frame))
        else:
            self.frame = np.transpose(frame)

        if len(marker) > 0:
            self.xy_aruco = marker.loc[marker.is_inside_box, ('box_x', 'box_y')].values
        else:
            self.xy_aruco = []

        self.plot(ax)
        return sb_params

    def plot(self, ax):
        if self.p_velocity and self.ready_velocity:
            self.plot_seismic_velocity(ax)
        else:
            self.delete_seismic_velocity()
        if self.p_wave and self.ready_wave:
            self.plot_wavefield(ax)
        else:
            self.delete_wavefield()
        ax.set_axis_off()
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)

    def plot_seismic_velocity(self, ax):
        if self.field is not None:
            if self._vp is None:
                self._vp = ax.imshow(self.field, cmap=plt.get_cmap("jet"),
                                     vmin=np.min(self.field), vmax=np.max(self.field),
                                     extent=self.Load_Area.to_box_extent if self.crop else self.extent,
                                     origin="lower", zorder=2)
            else:
                self._vp.set_data(self.field)

    def delete_seismic_velocity(self):
        if self._vp is not None:
            self._vp.remove()
            self._vp = None

    def plot_wavefield(self, ax):
        if self.u is not None and self.model is not None:
            if self._w is None:
                self._w = ax.imshow(self.wavefield(self.timeslice),
                                    vmin=-1e0, vmax=1e0,
                                    cmap=plt.get_cmap('seismic'),
                                    aspect=1,
                                    extent=self.Load_Area.to_box_extent if self.crop else self.extent,
                                    interpolation='none', origin="lower", zorder=3)
            else:
                self._w.set_data(self.wavefield(self.timeslice))

            if self.real_time:
                self.timeslice += self.framerate
                if self.timeslice >= self.time_range.num:
                    self.timeslice = 0

    def delete_wavefield(self):
        if self._w is not None:
            self._w.remove()
            self._w = None

    def run_simulation(self, vmin=2, vmax=4, nbl=40, **kwargs):
        if self.model is None:
            self.init_model(vmin=vmin, vmax=vmax, frame=self.frame, nbl=nbl, **kwargs)
        if len(self.src_coordinates) == 0:
            logger.warning("Put an aruco marker as a source or manually specify a source term")
            return
        self.insert_aruco_source()
        self.operator_and_solve()
        logger.info("Simulation succesfull")

    def init_model(self, vmin, vmax, frame=None, **kwargs):
        if frame is None:
            frame = self.frame
        self.create_velocity_model(frame,
                                   vmax=vmax,
                                   vmin=vmin,
                                   **kwargs)
        self.create_time_axis(**kwargs)
        self.create_time_function()
        self.solve_PDE()

    def insert_aruco_source(self):
        if self.model is None:
            logger.warning("Create the velocity model first")
            return

        if len(self.xy_aruco) > 0:
            self.src_term = []
            for counter, aru in enumerate(self.xy_aruco):
                # Modify to the simulation area
                aru_mod = (aru[0] - self.Load_Area.box_origin[0], aru[1] - self.Load_Area.box_origin[1])
                src = self.create_source(name="src%i" % counter, f0=self.frequency,
                                         source_coordinates=(aru_mod[0]*self.model.spacing[0],
                                                             aru_mod[1]*self.model.spacing[1]),
                                         show_wavelet=False, show_model=False)
                self.inject_source(src)
        else:
            logger.warning("No arucos founded")
            return

    def crop_frame(self, frame):
        return frame[self.Load_Area.box_origin[1]:self.Load_Area.box_origin[1] + self.Load_Area.box_height,
                     self.Load_Area.box_origin[0]:self.Load_Area.box_origin[0] + self.Load_Area.box_width]

    def scale_linear(self, topo: np.ndarray, high: float, low: float):
        """
        scale the frame data according to the highest and lowest value desired
        Args:
            topo: topo frame
            high: max value
            low: min value
        Returns:
            Normalized frame
        """
        mins = np.amin(topo)
        maxs = np.amax(topo)
        rng = maxs - mins
        return high - (((high - low) * (maxs - topo)) / rng)

    def smooth_topo(self, topo: np.ndarray, sigma_x: int, sigma_y: int):
        """
        Smoothing  the topography...
        Args:
            topo: topo frame
            sigma_x: smooth in x direction
            sigma_y: smooth in y direction
        Returns:
            Smothed array
        """
        return ndimage.filters.gaussian_filter(topo, [sigma_y, sigma_x], mode='nearest')

    def create_velocity_model(self, topo: np.ndarray, norm: bool=True, vmax: float = 5.0,
                              vmin: float = 2.0, smooth: bool = False, sigma_x: int = 2, sigma_y: int = 2,
                              spacing: tuple = (10, 10), origin=(0, 0),
                              nbl: int = 40, show_velocity: bool = False, **kwargs):
        """
        takes the topography and creates a velocity model from the topography
        Args:
            topo: topo array
            norm: to normalize the topo according to vmax and vmin
            vmax: maximum velocity for normalization
            vmin: minimum velocity for normalization
            smooth: to apply a gaussian filter to the topo
            sigma_x: smooth in x direction
            sigma_y: smooth in y_direction
            spacing: Grid spacing in m
            origin: What is the location of the top left corner. This is necessary to define the absolute location of
            the source and receivers
            nbl: size of the absorbing layer
            show_velocity: plot of the velocity model
        Returns:
            model

        """
        if topo is None:
            # Make a simple 2 layered velocity model
            vp = np.empty((101, 101), dtype=np.float32)
            vp[:, :51] = 1.5
            vp[:, 51:] = 2.5
            topo = vp
        topo = topo.astype(np.float32)
        if norm:
            topo = self.scale_linear(topo, vmax, vmin)
        if smooth:
            topo = self.smooth_topo(topo, sigma_x, sigma_y)
        self.vp = np.transpose(topo)
        self.model = Model(vp=topo, origin=origin, shape=topo.shape, spacing=spacing,
                           space_order=2, nbl=nbl, bcs="damp")
        slices = tuple(slice(self.model.nbl, -self.model.nbl) for _ in range(2))
        if getattr(self.model, 'vp', None) is not None:
            self.field = self.model.vp.data[slices]
        else:
            self.field = self.model.lam.data[slices]
        self.field = np.transpose(self.field)
        self.ready_velocity = True

        domain_size = 1.e-3 * np.array(self.model.domain_size)  # To express in kilometers
        self.model_extent = [self.model.origin[0], self.model.origin[0] + domain_size[0],
                             self.model.origin[1], self.model.origin[1] + domain_size[1]]

        if show_velocity:
            self.show_velocity(self.model)
        return self.model

    def create_time_axis(self, t0: int = 0, tn: int = 1000):
        """
        Time duration of our model. This takes the start, and end with the time-step-size provided by the model
        Args:
            t0:  Simulation starts a t=0
            tn:  Simulation last 1 second (1000 ms)
        Returns:
            Time_range
        """
        dt = self.model.critical_dt
        self.time_range = TimeAxis(start=t0, stop=tn, step=dt)
        self.max_wave_frame = self.time_range.num - 1
        return self.time_range

    @property
    def _src_coords(self):
        """gives the source coordinates of the richter waveletet in the middle of the model"""
        return np.multiply([int(self.model.domain_size[0]/2), int(self.model.domain_size[1]/2/2)], [10, 10])

    def create_source(self, name: str = 'src', f0: float = 0.025, source_coordinates: tuple = None,
                      show_wavelet: bool = False, show_model: bool = False):
        """
        RickerSource positioned at a depth of "depth_source"
        Args:
            name: assign a name to the source, so we can distinguish if more sources
            f0: # Source peak frequency is 25Hz (0.025 kHz)
            source_coordinates: position (x, y) for the source. Scale is in meters
            show_wavelet: Plot the time signature to see the wavelet
            show_model: plot the velocity model and the location of the source
        Returns:
        """
        if source_coordinates is None:
            source_coordinates = self._src_coords

        src = RickerSource(name=name, grid=self.model.grid, f0=f0,
                           npoint=1, time_range=self.time_range, coordinates=source_coordinates)
        # First, position source centrally in all dimensions, then set depth
        # src.coordinates.data[0, :] = np.array(model.domain_size) * .5
        # src.coordinates.data[0, -1] = 20.  # Depth is 20m
        if show_wavelet:  # We can plot the time signature to see the wavelet
            src.show()
        if show_model:
            self.show_velocity(self.model, source=src.coordinates.data)
        return src

    def create_time_function(self):
        """
        second order time discretization: This derivative is represented in Devito by u.dt2
        where u is a TimeFunction object.

        Spatial discretization: This derivative is represented in Devito by u.laplace where u is a
        TimeFunction object.

        With space and time discretization defined, we can fully discretize the wave-equation
        with the combination of time and space discretizations
        Returns:

        """
        # Define the wavefield with the size of the model and the time dimension
        self.u = TimeFunction(name="u", grid=self.model.grid,
                              time_order=2, space_order=2,
                                   save=self.time_range.num)
        # We can now write the PDE
        self.pde = self.model.m * self.u.dt2 - self.u.laplace + self.model.damp * self.u.dt
        return self.pde

    def solve_PDE(self):
        """This discrete PDE can be solved in a time-marching way updating u(t+dt) from the previous time step"""
        self.stencil = Eq(self.u.forward, solve(self.pde, self.u.forward))
        return self.stencil

    def inject_source(self, source):
        """
        For every RickerSource we need to add it to the numerical scheme in order to solve the homogenous
        wave equation, in order to implement the measurement operator and interpolator operator.
        Args:
            source: from the self.create_source()
        Returns:
        """
        src_term = source.inject(field=self.u.forward, expr=source * self.model.critical_dt ** 2 / self.model.m)
        # TODO: offset=model.nbl))
        if self.src_term == []:
            self.src_term = src_term
        else:
            self.src_term += src_term

        self.src_coordinates.append(source.coordinates.data)
        logger.info("Source registered")
        return self.src_term

    def create_receivers(self, name: str = 'rec', n_receivers: int = 50, depth_receivers: int = 20,
                         show_receivers: bool = False):
        """
        Interpolate the values of the receivers horizontaly at a depth
        Args:
            name: name to the receivers
            n_receivers: amount of points/receivers
            depth_receivers: to plot the receivers along the x axis of the coordinate
            show_receivers: show a plot with receiver data
        Returns:
        """
        x_locs = np.linspace(0, self.model.shape[0]*self.model.spacing[0], n_receivers)
        rec_coords = [(x, depth_receivers) for x in x_locs]
        rec = Receiver(name=name, npoint=n_receivers, time_range=self.time_range,
                       grid=self.model.grid, coordinates=rec_coords)
        if show_receivers:
            self.show_velocity(self.model, receiver=rec.coordinates.data[::4, :])
        return rec

    def interpolate_receiver(self, rec):
        """obtain the receivers information"""
        self.rec_term = rec.interpolate(expr=self.u.forward)
        return self.rec_term

    def operator_and_solve(self):
        """
        After constructing all the necessary expressions for updating the wavefield, injecting the source term and
        interpolating onto the receiver points, we can now create the Devito operator that will generate the C code
        at runtime.
        Returns:

        """
        self.op = Operator([self.stencil] + self.src_term + self.rec_term)  # , subs=self.model.spacing_map)
        self.op(dt=self.model.critical_dt)
        self.ready_wave = True

    def wavefield(self, timeslice):
        """get rid of the sponge that attenuates the waves"""
        if timeslice >= self.time_range.num:
            logger.info('timeslice not valid for value %i, setting values of %i' % (timeslice, self.time_range.num-1))
            timeslice = self.time_range.num-1

        wf_data = self.u.data[timeslice, self.model.nbl:-self.model.nbl, self.model.nbl:-self.model.nbl]
        wf_data_normalize = wf_data / np.amax(wf_data)
        waves = np.ma.masked_where(np.abs(wf_data_normalize) <= self.threshold, wf_data_normalize)
        return np.transpose(waves)

    def show_wavefield(self, timeslice: int):
        """
        Gives a plot of the wavefield in time (ms)
        Args:
            timeslice: value in ms
        Returns:

        """

        fig, ax = plt.subplots()
        model_param = dict(vmin=self.vp.max(), vmax=self.vp.min(), cmap=plt.get_cmap('jet'), aspect=1,
                           extent=self.model_extent, origin="lower")
        data_param = dict(vmin=-1e0, vmax=1e0, cmap=plt.get_cmap('seismic'), aspect=1, extent=self.model_extent,
                          interpolation='none', origin="lower")

        _vp = plt.imshow(self.vp, **model_param)
        _wave = plt.imshow(self.wavefield(timeslice), **data_param)
        ax.set_ylabel('Depth (km)', fontsize=20)
        ax.set_xlabel('x position (km)', fontsize=20)

        ax.set_title("t = {:.0f} ms".format(timeslice*self.time_range.step))
        divider = make_axes_locatable(ax)
        cax = divider.append_axes("right", size="5%", pad=0.05)
        fig.colorbar(_vp, cax=cax, ax=ax, label="Velocity (km/s)")
        fig.show()

    def show_velocity(self, model, source=None, receiver=None, cmap="jet"):
        """
        Function modified from DEVITO example codes
        Plot a two-dimensional velocity field from a seismic `Model`
        object. Optionally also includes point markers for sources and receivers.

        Parameters
        ----------
        model : Model
            Object that holds the velocity model.
        source : array_like or float
            Coordinates of the source point.
        receiver : array_like or float
            Coordinates of the receiver points.
        cmap : "jet"
        """
        slices = tuple(slice(model.nbl, -model.nbl) for _ in range(2))
        if getattr(model, 'vp', None) is not None:
            field = model.vp.data[slices]
        else:
            field = model.lam.data[slices]
        field = np.transpose(field)
        fig, ax = plt.subplots()
        plot = ax.imshow(field, animated=True, cmap=cmap,
                         vmin=np.min(field), vmax=np.max(field),
                         extent=self.model_extent, origin="lower")
        ax.set_xlabel('X position (km)')
        ax.set_ylabel('Depth (km)')

        # Plot receiver points, if provided
        if receiver is not None:
            ax.scatter(1e-3 * receiver[:, 0], 1e-3 * receiver[:, 1],
                       s=25, c='green', marker='D')

        # Plot source points, if provided
        if source is not None:
            if not isinstance(source, list):
                source = [source]
            for sou in source:
                ax.scatter(1e-3 * sou[:, 0], 1e-3 * sou[:, 1],
                           s=25, c='red', marker='o')

        # Ensure axis limits
        ax.set_xlim(self.model_extent[0], self.model_extent[1])
        ax.set_ylim(self.model_extent[2], self.model_extent[3])
        divider = make_axes_locatable(ax)
        cax = divider.append_axes("right", size="5%", pad=0.05)
        fig.colorbar(plot, cax=cax, ax=ax, label="Velocity (km/s)")
        fig.show()

    def update_panel_plot(self):
        self.figure.clf()
        self.axes.cla()
        self.figure.add_axes(self.axes)
        model_param = dict(vmin=self.vp.max(), vmax=self.vp.min(), cmap=plt.get_cmap('jet'), aspect=1,
                           extent=self.model_extent, origin="lower")

        _vp = self.axes.imshow(self.vp, **model_param)
        self.axes.set_ylabel('Depth (km)')
        self.axes.set_xlabel('x position (km)')
        if self.p_wave and self.ready_wave:
            data_param = dict(vmin=-1e0, vmax=1e0, cmap=plt.get_cmap('seismic'), aspect=1, extent=self.model_extent,
                              interpolation='none', origin="lower")
            _wave = self.axes.imshow(self.wavefield(self.timeslice), **data_param)
            self.axes.set_title("t = {:.0f} ms".format(self.timeslice*self.time_range.step))

        # Plot source points, if provided
        if self.src_coordinates is not None and len(self.src_coordinates) > 0:
            for sou in self.src_coordinates:
                self.axes.scatter(1e-3 * sou[:, 0], 1e-3 * sou[:, 1],
                                  s=25, c='red', marker='o')

        # Ensure axis limits
        self.axes.set_xlim(self.model_extent[0], self.model_extent[1])
        self.axes.set_ylim(self.model_extent[2], self.model_extent[3])
        divider = make_axes_locatable(self.axes)
        cax = divider.append_axes("right", size="5%", pad=0.05)
        self.figure.colorbar(_vp, cax=cax, ax=self.axes, label="Velocity (km/s)")
        self.panel_figure.param.trigger("object")

    def show_shotrecord(self, rec, model, t0, tn):
        """
        function modified from DEVITO example codes
        Plot a shot record (receiver values over time).

        Parameters
        ----------
        rec :
            Receiver data with shape (time, points).
        model : Model
            object that holds the velocity model.
        t0 : int
            Start of time dimension to plot.
        tn : int
            End of time dimension to plot.
        """
        scale = np.max(rec) / 10.
        extent = [model.origin[0], model.origin[0] + 1e-3 * model.domain_size[1],
                  1e-3 * tn, t0]
        fig, ax = plt.subplots()
        plot = ax.imshow(rec, vmin=-scale, vmax=scale, cmap=cm.gray, extent=extent)
        ax.set_xlabel('X position (km)')
        ax.set_ylabel('Time (s)')
        divider = make_axes_locatable(ax)
        cax = divider.append_axes("right", size="5%", pad=0.05)
        fig.colorbar(plot, cax=cax, ax=ax)
        fig.show()

    def show_widgets(self):
        panel = pn.Row(self.show_simulation_widgets(),
                       self.show_plotting_widgets())
        tabs = pn.Tabs(("Seismic", panel),
                       ("LoadSaveModule", self.Load_Area.show_widgets()))
        return tabs

    def show_plotting_widgets(self):
        self._widget_real_time = pn.widgets.Checkbox(name='Real time', value=self.real_time)
        self._widget_real_time.param.watch(self._callback_real_time, 'value', onlychanged=False)

        self._widget_framerate = pn.widgets.Spinner(name='Framerate', value=self.framerate, step=1)
        self._widget_framerate.param.watch(self._callback_framerate, 'value', onlychanged=False)

        self._widget_wave_selector = pn.widgets.IntSlider(name='Wavefield in frame',
                                                          value=self.timeslice,
                                                          start=0,
                                                          end=self.max_wave_frame)
        self._widget_wave_selector.param.watch(self._callback_select_wave, 'value', onlychanged=False)

        self._widget_p_velocity = pn.widgets.Checkbox(name='Velocity Model', value=self.p_velocity)
        self._widget_p_velocity.param.watch(self._callback_p_velocity, 'value', onlychanged=False)

        self._widget_p_wavefield = pn.widgets.Checkbox(name='Wavefield', value=self.p_wave)
        self._widget_p_wavefield.param.watch(self._callback_p_wavefield, 'value', onlychanged=False)

        self._widget_threshold = pn.widgets.Spinner(name='Wavefield threshold', value=self.threshold, step=0.01)
        self._widget_threshold.param.watch(self._callback_threshold, 'value', onlychanged=False)

        panel = pn.Column("### <b>Controllers</b>",
                          self.panel_figure,
                          "<b>Show Seismic wave in real time</b>",
                          self._widget_real_time,
                          self._widget_framerate,
                          self._widget_threshold,
                          "<b>Visualize single seismic wave</b> (First deactivate real time)",
                          self._widget_wave_selector,
                          "<b>Hide or show velocity model and wavefield</b>",
                          self._widget_p_velocity,
                          self._widget_p_wavefield
                          )
        return panel

    def show_simulation_widgets(self):
        self._widget_vmin = pn.widgets.Spinner(name="vmin", value=2.0, step=0.1)
        self._widget_vmax = pn.widgets.Spinner(name="vmax", value=5.0, step=0.1)
        self._widget_nbl = pn.widgets.Spinner(name="Damping thickness", value=40, step=1)

        self._widget_create_model = pn.widgets.Button(name="Create velocity model", button_type="success")
        self._widget_create_model.param.watch(self._callback_velocity_model, 'clicks', onlychanged=False)

        self._widget_t0 = pn.widgets.Spinner(name="t0", value=0, step=1)
        self._widget_tn = pn.widgets.Spinner(name="tn", value=800, step=1)
        self._widget_create_time = pn.widgets.Button(name="Create time axis", button_type="success")
        self._widget_create_time.param.watch(self._callback_create_time, 'clicks', onlychanged=False)

        self._widget_frequency = pn.widgets.Spinner(name="Frequency (Hz)", value=self.frequency*1000, step=1)

        self._widget_insert_aruco = pn.widgets.Button(name="Insert sources", button_type="warning")
        self._widget_insert_aruco.param.watch(self._callback_insert_aruco, 'clicks', onlychanged=False)

        self._widget_solve = pn.widgets.Button(name="Solve PDE", button_type="success")
        self._widget_solve.param.watch(self._callback_solve, 'clicks', onlychanged=False)

        column = pn.Column("### <b>Simulation</b>",
                           "<b>1) Costruct velocity model</b>",
                           self._widget_vmax,
                           self._widget_vmin,
                           self._widget_nbl,
                           self._widget_create_model,
                           "<b>2) Create time axis and functions</b>",
                           self._widget_t0,
                           self._widget_tn,
                           self._widget_create_time,
                           "<b>3) Insert source terms</b>",
                           "Place aruco markers in position and click the button",
                           self._widget_frequency,
                           self._widget_insert_aruco,
                           "<b>4) Solve",
                           self._widget_solve)
        return column

    def _callback_threshold(self, event):
        self.threshold = event.new

    def _callback_velocity_model(self, event):
        self.lock.acquire()
        vmin = self._widget_vmin.value
        vmax = self._widget_vmax.value
        nbl = self._widget_nbl.value
        _ = self.create_velocity_model(topo=self.frame, vmax=vmax, vmin=vmin, nbl=nbl)
        self.update_panel_plot()
        self.lock.release()

    def _callback_create_time(self, event):
        self.lock.acquire()
        t0 = self._widget_t0.value
        tn = self._widget_tn.value
        _ = self.create_time_axis(t0, tn)
        self._widget_wave_selector.end = self.max_wave_frame
        _ = self.create_time_function()
        _ = self.solve_PDE()
        self.lock.release()

    def _callback_insert_aruco(self, event):
        self.lock.acquire()
        self.frequency = self._widget_frequency.value/1000  # (to put in kHz)
        self.insert_aruco_source()
        self.update_panel_plot()
        self.lock.release()

    def _callback_solve(self, event):
        self.lock.acquire()
        self.operator_and_solve()
        self.update_panel_plot()
        self.lock.release()

    def _callback_real_time(self, event):
        self.real_time = event.new

    def _callback_framerate(self, event):
        self.framerate = event.new

    def _callback_select_wave(self, event):
        self.lock.acquire()
        self.timeslice = event.new
        self.update_panel_plot()
        self.lock.release()

    def _callback_p_velocity(self, event):
        self.p_velocity = event.new

    def _callback_p_wavefield(self, event):
        self.p_wave = event.new



================================================
FILE: sandbox/modules/devito/source.py
================================================
#######################################
#Script taken  from https://github.com/devitocodes/devito/tree/master/examples/seismic
#######################################

from scipy import interpolate
from cached_property import cached_property
import numpy as np
try:
    import matplotlib.pyplot as plt
except:
    plt = None

from devito.types import SparseTimeFunction

__all__ = ['PointSource', 'Receiver', 'Shot', 'WaveletSource',
           'RickerSource', 'GaborSource', 'DGaussSource', 'TimeAxis']


class TimeAxis(object):
    """
    Data object to store the TimeAxis. Exactly three of the four key arguments
    must be prescribed. Because of remainder values it is not possible to create
    a TimeAxis that exactly adhears to the inputs therefore start, stop, step
    and num values should be taken from the TimeAxis object rather than relying
    upon the input values.

    The four possible cases are:
    start is None: start = step*(1 - num) + stop
    step is None: step = (stop - start)/(num - 1)
    num is None: num = ceil((stop - start + step)/step);
                 because of remainder stop = step*(num - 1) + start
    stop is None: stop = step*(num - 1) + start

    Parameters
    ----------
    start : float, optional
        Start of time axis.
    step : float, optional
        Time interval.
    num : int, optional
        Number of values (Note: this is the number of intervals + 1).
        Stop value is reset to correct for remainder.
    stop : float, optional
        End time.
    """
    def __init__(self, start=None, step=None, num=None, stop=None):
        try:
            if start is None:
                start = step*(1 - num) + stop
            elif step is None:
                step = (stop - start)/(num - 1)
            elif num is None:
                num = int(np.ceil((stop - start + step)/step))
                stop = step*(num - 1) + start
            elif stop is None:
                stop = step*(num - 1) + start
            else:
                raise ValueError("Only three of start, step, num and stop may be set")
        except:
            raise ValueError("Three of args start, step, num and stop may be set")

        if not isinstance(num, int):
            raise TypeError("input argument must be of type int")

        self.start = start
        self.stop = stop
        self.step = step
        self.num = num

    def __str__(self):
        return "TimeAxis: start=%g, stop=%g, step=%g, num=%g" % \
               (self.start, self.stop, self.step, self.num)

    def _rebuild(self):
        return TimeAxis(start=self.start, stop=self.stop, num=self.num)

    @cached_property
    def time_values(self):
        return np.linspace(self.start, self.stop, self.num)


class PointSource(SparseTimeFunction):
    """Symbolic data object for a set of sparse point sources

    Parameters
    ----------
    name : str
        Name of the symbol representing this source.
    grid : Grid
        The computational domain.
    time_range : TimeAxis
        TimeAxis(start, step, num) object.
    npoint : int, optional
        Number of sparse points represented by this source.
    data : ndarray, optional
        Data values to initialise point data.
    coordinates : ndarray, optional
        Point coordinates for this source.
    space_order : int, optional
        Space discretization order.
    time_order : int, optional
        Time discretization order (defaults to 2).
    dtype : data-type, optional
        Data type of the buffered data.
    dimension : Dimension, optional
        Represents the number of points in this source.
    """

    @classmethod
    def __args_setup__(cls, *args, **kwargs):
        kwargs['nt'] = kwargs['time_range'].num

        # Either `npoint` or `coordinates` must be provided
        npoint = kwargs.get('npoint')
        if npoint is None:
            coordinates = kwargs.get('coordinates', kwargs.get('coordinates_data'))
            if coordinates is None:
                raise TypeError("Need either `npoint` or `coordinates`")
            kwargs['npoint'] = coordinates.shape[0]

        return args, kwargs

    def __init_finalize__(self, *args, **kwargs):
        time_range = kwargs.pop('time_range')
        data = kwargs.pop('data', None)

        kwargs.setdefault('time_order', 2)
        super(PointSource, self).__init_finalize__(*args, **kwargs)

        self._time_range = time_range._rebuild()

        # If provided, copy initial data into the allocated buffer
        if data is not None:
            self.data[:] = data

    @cached_property
    def time_values(self):
        return self._time_range.time_values

    @property
    def time_range(self):
        return self._time_range

    def resample(self, dt=None, num=None, rtol=1e-5, order=3):
        # Only one of dt or num may be set.
        if dt is None:
            assert num is not None
        else:
            assert num is None

        start, stop = self._time_range.start, self._time_range.stop
        dt0 = self._time_range.step

        if dt is None:
            new_time_range = TimeAxis(start=start, stop=stop, num=num)
            dt = new_time_range.step
        else:
            new_time_range = TimeAxis(start=start, stop=stop, step=dt)

        if np.isclose(dt, dt0):
            return self

        nsamples, ntraces = self.data.shape

        new_traces = np.zeros((new_time_range.num, ntraces))

        for i in range(ntraces):
            tck = interpolate.splrep(self._time_range.time_values,
                                     self.data[:, i], k=order)
            new_traces[:, i] = interpolate.splev(new_time_range.time_values, tck)

        # Return new object
        return PointSource(name=self.name, grid=self.grid, data=new_traces,
                           time_range=new_time_range, coordinates=self.coordinates.data)

    # Pickling support
    _pickle_kwargs = SparseTimeFunction._pickle_kwargs + ['time_range']
    _pickle_kwargs.remove('nt')  # `nt` is inferred from `time_range`


Receiver = PointSource
Shot = PointSource


class WaveletSource(PointSource):

    """
    Abstract base class for symbolic objects that encapsulate a set of
    sources with a pre-defined source signal wavelet.

    Parameters
    ----------
    name : str
        Name for the resulting symbol.
    grid : Grid
        The computational domain.
    f0 : float
        Peak frequency for Ricker wavelet in kHz.
    time_values : TimeAxis
        Discretized values of time in ms.
    a : float, optional
        Amplitude of the wavelet (defaults to 1).
    t0 : float, optional
        Firing time (defaults to 1 / f0)
    """

    @classmethod
    def __args_setup__(cls, *args, **kwargs):
        kwargs.setdefault('npoint', 1)

        return super(WaveletSource, cls).__args_setup__(*args, **kwargs)

    def __init_finalize__(self, *args, **kwargs):
        super(WaveletSource, self).__init_finalize__(*args, **kwargs)

        self.f0 = kwargs.get('f0')
        self.a = kwargs.get('a')
        self.t0 = kwargs.get('t0')
        for p in range(kwargs['npoint']):
            self.data[:, p] = self.wavelet

    @property
    def wavelet(self):
        """
        Return a wavelet with a peak frequency ``f0`` at time ``t0``.
        """
        raise NotImplementedError('Wavelet not defined')

    def show(self, idx=0, wavelet=None):
        """
        Plot the wavelet of the specified source.

        Parameters
        ----------
        idx : int
            Index of the source point for which to plot wavelet.
        wavelet : ndarray or callable
            Prescribed wavelet instead of one from this symbol.
        """
        wavelet = wavelet or self.data[:, idx]
        plt.figure()
        plt.plot(self.time_values, wavelet)
        plt.xlabel('Time (ms)')
        plt.ylabel('Amplitude')
        plt.tick_params()
        plt.show()

    # Pickling support
    _pickle_kwargs = PointSource._pickle_kwargs + ['f0', 'a', 'f0']


class RickerSource(WaveletSource):

    """
    Symbolic object that encapsulate a set of sources with a
    pre-defined Ricker wavelet:

    http://subsurfwiki.org/wiki/Ricker_wavelet

    Parameters
    ----------
    name : str
        Name for the resulting symbol.
    grid : Grid
        The computational domain.
    f0 : float
        Peak frequency for Ricker wavelet in kHz.
    time : TimeAxis
        Discretized values of time in ms.

    Returns
    ----------
    A Ricker wavelet.
    """

    @property
    def wavelet(self):
        t0 = self.t0 or 1 / self.f0
        a = self.a or 1
        r = (np.pi * self.f0 * (self.time_values - t0))
        return a * (1-2.*r**2)*np.exp(-r**2)


class GaborSource(WaveletSource):

    """
    Symbolic object that encapsulate a set of sources with a
    pre-defined Gabor wavelet:

    https://en.wikipedia.org/wiki/Gabor_wavelet

    Parameters
    ----------
    name : str
        Name for the resulting symbol.
    grid : Grid
        defining the computational domain.
    f0 : float
        Peak frequency for Ricker wavelet in kHz.
    time : TimeAxis
        Discretized values of time in ms.

    Returns
    -------
    A Gabor wavelet.
    """

    @property
    def wavelet(self):
        agauss = 0.5 * self.f0
        tcut = self.t0 or 1.5 / agauss
        s = (self.time_values - tcut) * agauss
        a = self.a or 1
        return a * np.exp(-2*s**2) * np.cos(2 * np.pi * s)


class DGaussSource(WaveletSource):

    """
    Symbolic object that encapsulate a set of sources with a
    pre-defined 1st derivative wavelet of a Gaussian Source.

    Notes
    -----
    For visualizing the second or third order derivative
    of Gaussian wavelets, the convention is to use the
    negative of the normalized derivative. In the case
    of the second derivative, scaling by -1 produces a
    wavelet with its main lobe in the positive y direction.
    This scaling also makes the Gaussian wavelet resemble
    the Mexican hat, or Ricker, wavelet. The validity of
    the wavelet is not affected by the -1 scaling factor.

    Parameters
    ----------
    name : str
        Name for the resulting symbol.
    grid : Grid
        The computational domain.
    f0 : float
        Peak frequency for wavelet in kHz.
    time : TimeAxis
        Discretized values of time in ms.

    Returns
    -------
    The 1st order derivative of the Gaussian wavelet.
    """

    @property
    def wavelet(self):
        t0 = self.t0 or 1 / self.f0
        a = self.a or 1
        time = (self.time_values - t0)
        return -2 * a * time * np.exp(- a * time**2)



================================================
FILE: sandbox/modules/gempy/__init__.py
================================================
from warnings import warn
try:
    from .gempy_module import GemPyModule
except:
    warn("Gempy module will not work. Gempy dependencies not found")


if __name__ == '__main__':
    pass


================================================
FILE: sandbox/modules/gempy/example_models.py
================================================
import os
import gempy as gp
from sandbox import _test_data

os.environ["THEANO_FLAGS"] = "mode=FAST_RUN"
all_models = ['Horizontal_layers',
              'Recumbent_fold',
              'Anticline',
              'Pinchout',
              'Fault',
              'Unconformity']
# Not used since some devices are made to be used offline
# data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
# path_to_data = data_path + "/data/input_data/jan_models/"

path_to_data = _test_data.get('gempy_example_data')

def create_model_dict(model_name: list = all_models, **kwargs):
    """
    Create all the example models for the gempy module and stores them in a dictionary
    Returns:
        Dictionary with all the gempy models
    """
    model_dict = {}
    for model in model_name:
        model_dict.update({model: create_example_model(model, **kwargs)})
    return model_dict


def create_example_model(name, extent=[0, 1000, 0, 1000, 0, 1800], do_sections=False,
                         change_color=False, data_path=path_to_data, resolution=[20, 20, 20],
                         theano_optimizer='fast_compile'):
    # _test_data['gempy_data'], theano_optimizer='fast_compile'):
    """
    Create all the example models
    Args:
        name: Name of the model to create
        extent: extent of the model in model units
        do_sections: False
        change_color: False
        data_path: Path to the .csv files storing the information
        theano_optimizer: 'fast_compile'
    Returns:
        geo_model

    """
    assert name in all_models, 'possible model names are ' + str(all_models)
    if name == 'Horizontal_layers':
        geo_model = gp.create_data(name, extent=extent, resolution=resolution,
                                   path_o=data_path + "model1_orientations.csv",
                                   path_i=data_path + "model1_surface_points.csv")

        gp.map_stack_to_surfaces(geo_model, {"Strat_Series": ('rock2', 'rock1'), "Basement_Series": ('basement')})
        if change_color:
            geo_model.surfaces.colors.change_colors({"rock2": '#9f0052', 'rock1': '#e36746',
                                                     'basement': '#f9f871'})

    elif name == 'Anticline':
        geo_model = gp.create_data(name, extent=extent, resolution=resolution,
                                   path_o=data_path + "model2_orientations.csv",
                                   path_i=data_path + "model2_surface_points.csv")
        gp.map_stack_to_surfaces(geo_model, {"Strat_Series": ('rock2', 'rock1'),
                                             "Basement_Series": ('basement')})

    elif name == 'Recumbent_fold':
        geo_model = gp.create_data(name, extent=extent, resolution=resolution,
                                   path_o=data_path + "model3_orientations.csv",
                                   path_i=data_path + "model3_surface_points.csv")
        gp.map_stack_to_surfaces(geo_model, {"Strat_Series": ('rock2', 'rock1'),
                                             "Basement_Series": ('basement')})
        if change_color:
            geo_model.surfaces.colors.change_colors({"rock2": '#e36746', 'rock1': '#c0539f',
                                                     'basement': '#006fa8'})

    elif name == 'Pinchout':
        geo_model = gp.create_data(name, extent=extent, resolution=resolution,
                                   path_o=data_path + "model4_orientations.csv",
                                   path_i=data_path + "model4_surface_points.csv")
        gp.map_stack_to_surfaces(geo_model, {"Strat_Series": ('rock2', 'rock1'),
                                             "Basement_Series": ('basement')})
        if change_color:
            geo_model.surfaces.colors.change_colors({"rock2": '#a1b455', 'rock1': '#ffbe00',
                                                     'basement': '#006471'})

    elif name == 'Fault':
        geo_model = gp.create_data(name, extent=extent, resolution=resolution,
                                   path_o=data_path + "model5_orientations.csv",
                                   path_i=data_path + "model5_surface_points.csv")
        gp.map_stack_to_surfaces(geo_model, {"Fault_Series": 'fault',
                                             "Strat_Series": ('rock2', 'rock1')})
        geo_model.set_is_fault(['Fault_Series'], change_color=False)
        if change_color:
            geo_model.surfaces.colors.change_colors({"rock2": '#00c2d0', 'rock1': '#a43d00',
                                                     'basement': '#76a237', 'fault': '#000000'})
    elif name == 'Unconformity':
        geo_model = gp.create_data(name, extent=extent, resolution=resolution,
                                   path_o=data_path + "model6_orientations.csv",
                                   path_i=data_path + "model6_surface_points.csv")

        gp.map_stack_to_surfaces(geo_model, {"Strat_Series1": ('rock3'),
                                             "Strat_Series2": ('rock2', 'rock1'),
                                             "Basement_Series": ('basement')})
    else:
        raise NotImplementedError(name, "Not available in example models")

    if do_sections:
        geo_model.set_section_grid({'section' + ' ' + name: ([0, 500], [1000, 500], [30, 30])})

    interp_data = gp.set_interpolator(geo_model,  # compile_theano=True,
                                      theano_optimizer=theano_optimizer)

    sol = gp.compute_model(geo_model, compute_mesh=False)

    if do_sections:
        gp.plot_2d(geo_model, section_names=['section' + ' ' + name], show_data=False)

    return geo_model



================================================
FILE: sandbox/modules/gempy/gempy_module.py
================================================
import matplotlib.pyplot as plt
import numpy
import panel as pn

from sandbox.modules.template import ModuleTemplate
from sandbox.modules.gempy.utils import get_scale, Grid
from sandbox.modules.gempy.plot import plot_gempy
from sandbox.modules.gempy.example_models import create_model_dict, all_models
from sandbox import set_logger
import pandas as pd

logger = set_logger(__name__)
# TODO: SettingWithCopyWarning appears when using LoadTopoModule with arucos
pd.options.mode.chained_assignment = None  # default='warn'

try:
    import pyvista as pv
    import gempy
    from gempy.core.grid_modules.topography import Topography
    from gempy.core.grid_modules import section_utils
except ImportError:
    logger.warning('gempy package not found, GempyModule will not work', exc_info=True)


class GemPyModule(ModuleTemplate):
    def __init__(self, geo_model=None, extent: list = None, box: list = None,
                 load_examples: bool = True, name_example: list = all_models, ** kwargs) -> object:
        # TODO: include save elevation map and export geologic map --self.geo_map
        """

        Args:
            geo_model: Previously constructed geo_model ready for visualization
            extent: sensor extents
            box: physical extends of the sandbox
            load_examples: To load all the example models and switch between them using a dictionary
        Returns:
            None

        """
        pn.extension('vtk')  # TODO: check if all the usages of extensions are actually changing something
        self.lock = None  # For locking the multithreading while using bokeh server
        if load_examples and len(name_example) > 0:
            self.model_dict = create_model_dict(name_example, **kwargs)
            print("Examples loaded in dictionary model_dict")
        else: self.model_dict = None

        if geo_model is None and self.model_dict is not None:
            self.geo_model = self.model_dict[name_example[0]]
            print("Model " + name_example[0] + " loaded as geo_model")
        else:
            self.geo_model = geo_model
            if self.model_dict is None:
                self.model_dict = {}
            self.model_dict[geo_model.meta.project_name] = geo_model

        try:
            self._model_extent = self.geo_model._grid.regular_grid.extent
        except:
            logger.error('Geo model not valid')
            raise AttributeError
        self._sensor_extent = extent
        self._box_dimensions = box

        self.frame = None
        self.vmin = None
        self.vmax = None
        self.cmap = None
        self.grid = None
        self.plot_topography = True
        self.plot_faults = True
        self.cross_section = None
        self.section_dict = {}
        self.borehole_dict = {}
        self.actual_dict = {}
        self._resolution_section = [150, 100]
        self.figsize = (10, 10)

        # 2D images
        self.im_section_traces = None
        self.im_plot_2d = None
        self.im_actual_model = None
        self.im_geo_map = None

        # 3D gempy model
        self.geo_3d = None

        self._plotter_type = 'basic'
        self._notebook = False
        self._param_3d_model = {'show_data': True,
                                'show_results': True,
                                'show_surfaces': True,
                                'show_lith': True,
                                'show_scalar': False,
                                'show_boundaries': True,
                                'show_topography': False}
        self._ve = 0.3

        # Manage panel figure to show current model
        self.panel_section_traces = pn.pane.Matplotlib(plt.figure(), tight=False, height=500)
        plt.close()
        # Manage panel figure to show 2D plots ( Cross-sections or geological maps)
        self.panel_plot_2d = pn.pane.Matplotlib(plt.figure(), tight=False, height=500)
        plt.close()

        self.panel_actual_model = pn.pane.Matplotlib(plt.figure(), tight=False, height=500)
        plt.close()

        self.panel_geo_map = pn.pane.Matplotlib(plt.figure(), tight=False, height=500)
        plt.close()

        p1 = pv.Plotter(notebook=False)
        self.vtk_borehole = pn.panel(p1.ren_win,
                                     sizing_mode='stretch_both',
                                     orientation_widget=True,
                                     enable_keybindings=True)
        p2 = pv.Plotter(notebook=False)
        self.vtk_model = pn.panel(p2.ren_win,
                                  sizing_mode='stretch_both',
                                  orientation_widget=True,
                                  enable_keybindings=True)

        # For the boreholes potting
        self.borehole_tube = []
        self.colors_bh = []
        self.faults_bh = []
        self.faults_color_bh = []
        self._radius_borehole = 20

        # For the new plotting way 'TODO: Create widgets
        self.show_lith = True
        self.show_boundary = True
        self.show_hillshades = False
        self.show_contour = False
        self.show_only_faults = False
        self.show_fill_contour = False

        # dataframe to save Arucos in model Space:
        self.modelspace_arucos = pd.DataFrame()

        dummy_frame = numpy.ones((self._sensor_extent[3], self._sensor_extent[1])) * 1000
        self.setup(dummy_frame)
        logger.info("GemPyModule loaded successfully")

    def setup(self, frame):
        self.frame = frame
        self.vmin = frame.min()
        self.vmax = frame.max()
        self._scale, self._pixel_scale, self._pixel_size = get_scale(
            physical_extent=self._box_dimensions,
            sensor_extent=self._sensor_extent,
            model_extent=self.geo_model._grid.regular_grid.extent)  # prepare the scale object

        self.grid = Grid(physical_extent=self._box_dimensions,
                         sensor_extent=self._sensor_extent,
                         model_extent=self.geo_model._grid.regular_grid.extent,
                         scale=self._scale)
        self.init_topography(frame)

    def init_topography(self, frame):
        self.grid.update_grid(frame)
        self.geo_model._grid.topography = Topography(self.geo_model._grid.regular_grid)
        self.geo_model._grid.topography.extent = self.grid.model_extent[:4]
        self.geo_model._grid.topography.resolution = numpy.asarray((self.grid.sensor_extent[3], self.grid.sensor_extent[1]))
        self.geo_model._grid.topography.values = self.grid.depth_grid
        self.geo_model._grid.topography.values_2d = numpy.dstack(
            [self.grid.depth_grid[:, 0].reshape(self.grid.sensor_extent[3], self.grid.sensor_extent[1]),
             self.grid.depth_grid[:, 1].reshape(self.grid.sensor_extent[3], self.grid.sensor_extent[1]),
             self.grid.depth_grid[:, 2].reshape(self.grid.sensor_extent[3], self.grid.sensor_extent[1])])

        self.geo_model._grid.set_active('topography')
        self.geo_model.update_from_grid()
        self.set_actual_dict()

    def update(self, sb_params: dict):
        frame = sb_params.get('frame')
        extent = sb_params.get('extent')
        ax = sb_params.get('ax')
        marker = sb_params.get('marker')
        self.lock = sb_params.get('lock_thread')
        self.frame = frame  # Store the current frame
        self.vmin = frame.min()
        self.vmax = frame.max()
        scale_frame = self.grid.scale_frame(frame)
        _ = self.grid.update_grid(scale_frame)
        self.geo_model._grid.topography.values = self.grid.depth_grid
        data = self.grid.depth_grid[:, 2].reshape(self.geo_model._grid.topography.resolution)
        self.geo_model._grid.topography.values_2d[:, :, 2] = data
        _= self.geo_model._grid.update_grid_values()
        _= self.geo_model.update_from_grid()

        gempy.compute_model(self.geo_model, compute_mesh=False)
        if len(marker) > 0:
            self.modelspace_arucos = self._compute_modelspace_arucos(marker)
            self.set_aruco_dict(self.modelspace_arucos)

        ax, cmap = self.plot(ax, self.geo_model, self._model_extent)

        sb_params['ax'] = ax
        sb_params['frame'] = scale_frame
        sb_params['cmap'] = cmap
        sb_params['marker'] = self.modelspace_arucos
        # This because we are currently plotting our own cmap and shading
        sb_params['active_cmap'] = False
        sb_params['active_shading'] = False
        sb_params['extent'] = self._model_extent
        sb_params['del_contour'] = not self.show_boundary

        return sb_params

    def plot(self, ax, geo_model, extent):
        # ax, cmap = plot_gempy_topography(ax, geo_model, extent,
        ax, cmap = plot_gempy(ax, geo_model, extent,
                              show_lith=self.show_lith,
                              show_boundary=self.show_boundary,
                              show_hillshade=self.show_hillshades,
                              show_contour=self.show_contour,
                              show_only_faults=self.show_only_faults,
                              show_fill_contour=self.show_fill_contour)
        return ax, cmap

    def change_model(self, geo_model):
        """
        Change a gempy model
        Args:
            geo_model: New gempy model to replace
        Returns:
        """
        self.remove_section_dict('Model: ' + self.geo_model.meta.project_name)
        self.geo_model = geo_model
        self.setup(self.frame)
        logger.info("New gempy model loaded")
        return True

    @property
    def model_sections_dict(self):
        """One time calculation to join dictionaries needed for cross_sections and boreholes"""
        return {**self.section_dict, **self.borehole_dict, **self.actual_dict}

    def _compute_modelspace_arucos(self, marker):
        """Receive a dataframe with the location of the arucos and then conver it to model coordinates.
        Args:
            marker: dataframe with aruco locations
        Returns:
            new dataframe with scaled values
        """
        df = marker.copy()
        if len(df) > 0:
            df = df.loc[df.is_inside_box, ('box_x', 'box_y', 'is_inside_box')]
            # df['box_z'] = self.Aruco.aruco_markers.loc[self.Aruco.aruco_markers.is_inside_box, ['Depth_Z(mm)']]
            df['box_z'] = numpy.nan
            # depth is changing all the time so the coordinate map method becomes old.
            # Workaround: just replace the value from the actual frame
            frame = self.frame
            for i in df.index:
                df.at[i, 'box_z'] = self.grid.scale_frame(frame[int(df.at[i, 'box_y'])][(int(df.at[i, 'box_x']))])
                # the combination below works though it should not! Look into scale again!!
                # pixel scale and pixel size should be consistent!
                df.at[i, 'box_x'] = (self._pixel_scale[0]*marker['box_x'][i])
                df.at[i, 'box_y'] = (self._pixel_scale[1]*marker['box_y'][i])

        return df

    def set_aruco_dict(self, df):
        """
        Receive an aruco dataframe already in the model coordinates and set a cross_section and points for the borehole
        Args:
            df: aruco dataframe

        Returns:
            change in place the section dictionary
        """
        if len(df) > 0:
            # include boreholes
            for i in df.index:
                x = df.at[i, 'box_x']
                y = df.at[i, 'box_y']
                self.set_borehole_dict((x,y), "aruco_"+str(i))
            if len(df) == 2:
                # Obtain the position of the aruco markers (must be 2 aruco markers)
                # to draw a cross-section by updating the section dictionary
                df.sort_values('box_x', ascending=True)
                x = df.box_x.values
                y = df.box_y.values
                p1 = (x[0], y[0])
                p2 = (x[1], y[1])
                self.set_section_dict(p1, p2, "Aruco_section")

    def set_section_dict(self, p1, p2, name):
        """
        Actualize the section dictionary to draw the cross_sections by appending he new points
        Args:
            p1: Point 1 (x,y) coordinates. The most left one
            p2: To point 2 (x,y) coordinates. The most right one
            name: Name of the section dictionary
        Returns:
            change in place the section dictionary
        """
        self.section_dict[name] = ([p1[0], p1[1]], [p2[0], p2[1]], self._resolution_section)
        _ = self.geo_model.set_section_grid(self.model_sections_dict)
        _ = gempy.compute_model(self.geo_model, compute_mesh=False)

    def set_actual_dict(self):
        """
        Actualize the section dictionary to draw the cross_sections of the actual model
        Returns
            change in place the actual dictionary
        """
        self.actual_dict = {}
        self.actual_dict['Model: ' + self.geo_model.meta.project_name] = ([self._model_extent[0],
                                                                           self._model_extent[3]/2],
                                                                          [self._model_extent[1],
                                                                           self._model_extent[3]/2],
                                                                          self._resolution_section)
        _ = self.geo_model.set_section_grid(self.model_sections_dict)
        _ = gempy.compute_model(self.geo_model, compute_mesh=False)

    def remove_section_dict(self, name: str):
        """
        Remove a specific section
        Args:
            name: Key name
        Returns:
        """
        if name in self.section_dict.keys():
            self.section_dict.pop(name)
            _ = self.geo_model.set_section_grid(self.model_sections_dict)
            _ = gempy.compute_model(self.geo_model, compute_mesh=False)
        else:
            logger.warning("No key found with name %s in section_dict" % name)

    def _get_aruco_section_dict(self, df):
        """Obtain the position of the aruco markers (must be 2 aruco markers)
        to draw a cross-section by updating the section dictionary"""
        if len(df) > 0:
            df.sort_values('box_x', ascending=True)
            x = df.box_x.values
            y = df.box_y.values
            p1 = (x[0], y[0])
            p2 = (x[1], y[1])
            self.set_section_dict(p1, p2, "Aruco_section")

    def show_section_traces(self):
        """Show the current location in the sandbox where the cross-section is painted"""
        self.im_section_traces = gempy.plot.plot_section_traces(self.geo_model)
        plt.close()
        self.panel_section_traces.object = self.im_section_traces.fig
        self.panel_section_traces.param.trigger('object')
        return self.im_section_traces.fig

    def show_geological_map(self):
        """Show the geological map from the gempy package"""
        self.im_geo_map = gempy.plot_2d(self.geo_model, section_names=['topography'], show_data=False,
                                        show_topography=True, show=False)
        self.panel_geo_map.object = self.im_geo_map.fig
        self.panel_geo_map.param.trigger('object')
        return self.im_geo_map.fig

    def show_cross_section(self, name: str):
        """
        Show the 2d cross_section or geological map
        Args:
            name: Show the cross section of the
        Returns:
        """
        if name in self.section_dict.keys():
            self.im_plot_2d = gempy.plot_2d(self.geo_model, section_names=[name], show_data=False, show_topography=True,
                                            show=False)
            # self.im_plot_2d.axes[0].set_ylim(self.frame.min(), self.frame.max())
            self.im_plot_2d.axes[0].set_aspect(aspect=0.5)
            self.panel_plot_2d.object = self.im_plot_2d.fig
            self.panel_plot_2d.param.trigger('object')
            return self.im_plot_2d.fig
        else:
            logger.warning("no key in section_dict have the name: %s" %name)

    def show_actual_model(self):
        """Show a cross_section of the actual gempy model"""
        # Get a cross_section in the middle of the model
        self.set_actual_dict()
        self.im_actual_model = gempy.plot_2d(self.geo_model,
                                             section_names=['Model: ' + self.geo_model.meta.project_name],
                                             show_data=False,
                                             show=False,
                                             show_topography=False)
        # self.im_actual_model.axes[0].set_ylim(self.frame.min(), self.frame.max())
        self.im_actual_model.axes[0].set_aspect(aspect=0.5)
        self.panel_actual_model.object = self.im_actual_model.fig
        self.panel_actual_model.param.trigger('object')
        return self.im_actual_model.fig

    def _get_aruco_borehole_dict(self, df):
        """Obtain the position of the aruco markers to update the borehole dictionary"""
        if len(df) > 0:
            # Search in the dataframe for new markers to add or update
            for i in df.index:
                point1 = numpy.array([df.loc[i, 'box_x'], df.loc[i, 'box_y']])
                point2 = numpy.array([df.loc[i, 'box_x'] + 1, df.loc[i, 'box_y']])
                self.borehole_dict['id_'+str(i)] = ([point1[0], point1[1]], [point2[0], point2[1]], [5, 5])
            # after adding the new markers, check for markers that dont exist
            # anymore and remove them from the dictionary
            for i in self.borehole_dict.keys():
                temp = df.loc[df.index == int(i[-1])].index
                if len(temp) > 0 and temp[0] == int(i[-1]):
                    pass
                else:
                    self.remove_borehole_dict(name=i)

    def remove_borehole_dict(self, name: str):
        """
        Remove a specific borehole dict
        Args:
            name: Key name
        Returns:
        """
        if name in self.borehole_dict.keys():
            self.borehole_dict.pop(name)
            _ = self.geo_model.set_section_grid(self.model_sections_dict)
            _ = gempy.compute_model(self.geo_model, compute_mesh=False)
        else:
            logger.warning("No key found with name %s in borehole_dict" % name)

    def set_borehole_dict(self, xy, name):
        """
        Actualize the section dictionary to draw the cross_sections by appending he new points
        Args:
            xy: Point 1 xy[0] coordinates. The most left one To point 2 xy[1] coordinates. The most right one
            name: Name of the section dictionary
        Returns:
            change in place the section dictionary
        """
        self.borehole_dict[name] = ([xy[0], xy[1]], [xy[0]+1, xy[1]], [5, 5])
        _ = self.geo_model.set_section_grid(self.model_sections_dict)
        _ = gempy.compute_model(self.geo_model, compute_mesh=False)

    def _get_polygon_data(self):
        """
        Method that gets the polygondict, cdict and extent of all the borehole points and store them in lines and colors
        """

        self.borehole_tube = []
        self.colors_bh = []
        self.faults_bh = []
        self.faults_color_bh = []
        _ = self.geo_model.set_section_grid(self.model_sections_dict)
        _ = gempy.compute_model(self.geo_model, compute_mesh=False)
        faults = list(self.geo_model.surfaces.df.loc[self.geo_model.surfaces.df['isFault']]['surface'])
        for name in self.borehole_dict.keys():
            polygondict, cdict, extent = section_utils.get_polygon_dictionary(self.geo_model,
                                                                              section_name=name)
            plt.close()  # avoid inline display

            # To get the top point of the model
            x, y = self.borehole_dict[name][0][0], self.borehole_dict[name][0][1]
            _ = self.grid.scale_frame(self.frame[int(y/self._pixel_scale[1]), int(x/self._pixel_scale[0])])
            z = numpy.asarray([_, _])
            color = numpy.asarray([None])
            fault_point = numpy.asarray([])
            fault_color = numpy.asarray([])
            for formation in list(self.geo_model.surfaces.df['surface']):
                 for path in polygondict.get(formation):
                     if path != []:
                        vertices = path.vertices
                        _idx = (numpy.abs(vertices[:, 0] - extent[1]/2)).argmin()
                        _compare = vertices[:, 0][_idx]
                        _mask = numpy.where(vertices[:, 0] == _compare)
                        extremes = vertices[_mask]
                        z_val = extremes[:, 1]
                        if formation in faults:
                            # fault_point = numpy.append(fault_point, z_val)
                            # fault_color = numpy.append(fault_color, cdict.get(formation))
                            self.faults_bh.append(numpy.asarray([x, y, z_val[0]]))
                            self.faults_color_bh.append(cdict.get(formation))
                        else:
                            z = numpy.vstack((z, z_val))
                            color = numpy.append(color, cdict.get(formation))

            mask1 = z[:, 0].argsort()
            mask2 = z[:, 0][mask1] <= z[0, 0]  # This is the first value added to start counting

            z_final = z[:, 0][mask1][mask2]
            color_final = color[mask1][mask2]
            # color_final[-1] = color[mask1][mask2 == False][0] Not needed to replace the color since is already none

            x_final = numpy.ones(len(z_final)) * x
            y_final = numpy.ones(len(z_final)) * y

            borehole_points = numpy.vstack((x_final, y_final, z_final)).T

            line = self._lines_from_points(borehole_points)
            line["scalars"] = numpy.arange(len(color_final))

            # For a single borehole
            self.borehole_tube.append(line.tube(radius=self._radius_borehole))
            self.colors_bh.append(color_final)
            # if len(fault_point) > 0:
            #    self.faults_bh.append(numpy.asarray([x, y, fault_point]))
            #    self.faults_color_bh.append(fault_color)

    def _lines_from_points(self, points):
        """Given an array of points, make a line set.
        See https://docs.pyvista.org/examples/00-load/create-spline.html
        for more information
        Args:
            points: x,y,z coordinates of the points
        """
        poly = pv.PolyData()
        poly.points = points
        cells = numpy.full((len(points) - 1, 3), 2, dtype=numpy.int)
        cells[:, 1] = numpy.arange(0, len(points) - 1, dtype=numpy.int)
        cells[:, 2] = numpy.arange(1, len(points), dtype=numpy.int)
        poly.lines = cells
        return poly

    def plot_boreholes(self, notebook=False, background=False, **kwargs):
        """
        Uses the previously calculated borehole tubes in self._get_polygon_data()
        when a borehole dictionary is available
        This will generate a pyvista object that can be visualized with .show()
        Args:
            notebook: If using in notebook to show inline
            background:
        Returns:
            Pyvista object with all the boreholes
        """
        self._get_polygon_data()
        if background:
            try:
                p = pv.BackgroundPlotter(**kwargs)
            except pv.QtDeprecationError:
                from pyvistaqt import BackgroundPlotter
                p = BackgroundPlotter(**kwargs)
        else:
            p = pv.Plotter(notebook=notebook, **kwargs)
        for i in range(len(self.borehole_tube)):
            cmap = self.colors_bh[i]
            p.add_mesh(self.borehole_tube[i], cmap=[cmap[j] for j in range(len(cmap)-1)], smooth_shading=False)
        # for i in range(len(self.faults_bh)):
        # for plotting the faults
        # TODO: Messing with the colors when faults
        if len(self.faults_bh) > 0:
            point = pv.PolyData(self.faults_bh)
            p.add_mesh(point, render_points_as_spheres=True, point_size=self._radius_borehole)
            # p.add_mesh(point, cmap = self.faults_color_bh[i],
            # render_points_as_spheres=True, point_size=self._radius_borehole)
        extent = numpy.copy(self._model_extent)
        # extent[-1] = numpy.ceil(self.modelspace_arucos.box_z.max()/100)*100
        p.show_bounds(bounds=extent)
        p.show_grid()
        p.set_scale(zscale=self._ve)
        # self.vtk = pn.panel(p.ren_win, sizing_mode='stretch_width', orientation_widget=True)
        # self.vtk = pn.Row(pn.Column(pan, pan.construct_colorbars()), pn.pane.Str(type(p.ren_win), width=500))
        return p

    def show_boreholes_panel(self):
        """This function will show the pyvista object of plot_boreholes in a panel server"""
        pl = self.plot_boreholes(notebook = False)
        pan = pn.panel(pl.ren_win, orientation_widget=True, enable_keybindings=True, sizing_mode='scale_both')
        axes = dict(
            origin=[self._model_extent[0], self._model_extent[2], self._model_extent[4]],
            xticker={'ticks': numpy.linspace(self._model_extent[0], self._model_extent[1], 5)},
            yticker={'ticks': numpy.linspace(self._model_extent[2], self._model_extent[3], 5)},
            zticker={'ticks': numpy.linspace(self._model_extent[4], self._model_extent[5], 5),
                     'labels': [''] + [str(int(item)) for item in numpy.linspace(self._model_extent[4],
                                                                                 self._model_extent[5], 5)[1:]]},
            fontsize=12,
            digits=1,
            grid_opacity=0.5,
            show_grid=True)
        pan.axes = axes
        widget = pn.Row(pn.Column(pan, pan.construct_colorbars()), pn.pane.Str(type(pl.ren_win)))  # , width=500))

        self.vtk_borehole = widget
        # self.vtk.object = pan.object
        # self.vtk.param.trigger('object')
        return self.vtk_borehole

    def plot_3d_model(self):
        """Generate a 3D gempy model and return a the pyvista object"""
        self.geo_3d = gempy.plot_3d(self.geo_model,
                                    plotter_type=self._plotter_type,
                                    show_data=self._param_3d_model['show_data'],
                                    show_results=self._param_3d_model['show_results'],
                                    show_surfaces=self._param_3d_model['show_surfaces'],
                                    show_lith=self._param_3d_model['show_lith'],
                                    show_scalar=self._param_3d_model['show_scalar'],
                                    show_boundaries=self._param_3d_model['show_boundaries'],
                                    show_topography=self._param_3d_model['show_topography'],
                                    notebook=self._notebook,
                                    image=False,
                                    off_screen=False,
                                    ve=self._ve
                                    )
        return self.geo_3d

    def show_3d_model_panel(self): #TODO: NOT WORKING
        """This function will show the pyvista object of plot_3d_model in a panel server"""
        pl = self.plot_3d_model()
        pan = pn.panel(pl.p.ren_win, width=700, sizing_mode='stretch_both', orientation_widget=True,
                       enable_keybindings=True)
        axes = dict(
            origin=[self._model_extent[0], self._model_extent[2], self._model_extent[4]],
            xticker={'ticks': numpy.linspace(self._model_extent[0], self._model_extent[1], 5)},
            yticker={'ticks': numpy.linspace(self._model_extent[2], self._model_extent[3], 5)},
            zticker={'ticks': numpy.linspace(self._model_extent[4], self._model_extent[5], 5),
                     'labels': [''] + [str(int(item)) for item in
                                       numpy.linspace(self._model_extent[4], self._model_extent[5], 5)[1:]]},
            fontsize=12,
            digits=1,
            grid_opacity=0.5,
            show_grid=True)
        pan.axes = axes
        widget = pn.Row(pn.Column(pan, pan.construct_colorbars()), pn.pane.Str(type(pl.ren_win)))  # , width=500))

        self.vtk_model = widget
        return self.vtk_model

    # Panel widgets
    def show_widgets(self):
        _ = self.show_actual_model()
        tabs = pn.Tabs(('Models', self.widget_model_selector()),
                       ('Geological map', self.widget_geological_map()),
                       ('Section traces', self.widget_section_traces()),
                       ('Cross_sections', self.widget_cross_sections()),
                       ('Boreholes', self.widget_boreholes()),
                       ('3D Gempy Model', self.widget_3d_model())
                       )
        return tabs

    def widget_3d_model(self):
        self._widget_show_3d_model = pn.widgets.Button(name="Show 3D Gempy Model", button_type="success",
                                                       disabled=True)
        # TODO: Fix this
        self._widget_show_3d_model.param.watch(self._callback_show_3d_model, 'clicks', onlychanged=False)
        self._widget_show_3d_model_pyvista = pn.widgets.Button(name="Show 3D Gempy Model pyvista",
                                                               button_type="warning")
        self._widget_show_3d_model_pyvista.param.watch(self._callback_show_3d_model_pyvista, 'clicks',
                                                       onlychanged=False)

        self._widget_parameters_3d_model = pn.widgets.CheckBoxGroup(name='Select properties to show of gempy model',
                                                                    options=list(self._param_3d_model.keys()),
                                                                    value=[active for active
                                                                           in self._param_3d_model.keys()
                                                                           if self._param_3d_model[active] == True],
                                                                    inline=False)

        self._widget_parameters_3d_model.param.watch(self._callback_param_3d_model, 'value', onlychanged=False)
        self._widget_vertical_exageration = pn.widgets.Spinner(name='Vertical Exaggeration',value=self._ve, step=0.1)
        self._widget_vertical_exageration.param.watch(self._callback_vertical_exageration, 'value',
                                                      onlychanged=False)

        widgets = pn.Column('### Show 3D Gempy Model',
                            self._widget_show_3d_model,
                            self._widget_show_3d_model_pyvista,
                            '<b>Select properties to show of gempy model</b>',
                            self._widget_parameters_3d_model,
                            self._widget_vertical_exageration)
        return widgets

    def widget_boreholes(self):
        self._widget_show_boreholes = pn.widgets.Button(name="Show Boreholes panel", button_type="success")
        self._widget_show_boreholes.param.watch(self._callback_show_boreholes, 'clicks',
                                                onlychanged=False)

        self._widget_show_boreholes_pyvista = pn.widgets.Button(name="Show Boreholes pyvista", button_type="warning")
        self._widget_show_boreholes_pyvista.param.watch(self._callback_show_boreholes_pyvista, 'clicks',
                                                        onlychanged=False)
        self._w_borehole_name = pn.widgets.TextInput(name='Borehole name', value='BH_1')
        self._w_x = pn.widgets.TextInput(name='x:', value='10.0', width=60)
        self._w_y = pn.widgets.TextInput(name='y:', value='20.0', width=60)

        self._widget_add_bh = pn.widgets.Button(name="Add borehole", button_type="success")
        self._widget_add_bh.param.watch(self._callback_add_bh, 'clicks',
                                        onlychanged=False)

        self._w_remove_borehole_name = pn.widgets.AutocompleteInput(name='Remove borehole name',
                                                                    options=list(self.borehole_dict.keys()))
        self._widget_remove_bh = pn.widgets.Button(name="Remove borehole", button_type="success")
        self._widget_remove_bh.param.watch(self._callback_remove_bh, 'clicks',
                                           onlychanged=False)

        self._widget_boreholes_available = pn.widgets.RadioBoxGroup(name='Available boreholes',
                                                                     options=list(self.borehole_dict.keys()),
                                                                     inline=False,
                                                                    disabled=True
                                                                     )

        widgets = pn.Column('### Creation of boreholes',
                            self._widget_show_boreholes,
                            self._widget_show_boreholes_pyvista,
                            '<b>add new borehole </b>',
                            pn.WidgetBox(self._w_borehole_name,
                                         pn.Row(self._w_x, self._w_y)),
                            self._widget_add_bh,
                            '<b>Remove borehole</b>',
                            self._w_remove_borehole_name,
                            self._widget_remove_bh,
                            '<b>Loaded boreholes</b>',
                            self._widget_boreholes_available,
                            )
        # TODO: add method to include more boreholes

        return widgets
    
    def widget_geological_map(self):
        self._widget_update_geo_map = pn.widgets.Button(name="Update Geological map", button_type="success")
        self._widget_update_geo_map.param.watch(self._callback_geo_map, 'clicks',
                                                onlychanged=False)
        widget = pn.Column("### Geological Map",
                           self._widget_update_geo_map, self.panel_geo_map)
        # TODO: add save geological map here. Maybe include vector map
        return widget

    def widget_section_traces(self):
        self._widget_update_section_traces = pn.widgets.Button(name="Update Section Traces", button_type="success")
        self._widget_update_section_traces.param.watch(self._callback_section_traces, 'clicks',
                                                onlychanged=False)
        widget = pn.Column("### Section Traces",
                           self._widget_update_section_traces, self.panel_section_traces)
        # TODO: add widgets to add or remove cross_sections
        return widget

    def widget_cross_sections(self):
        self._widget_select_cross_section = pn.widgets.RadioBoxGroup(name='Available Cross sections',
                                                                     options=list(self.section_dict.keys()),
                                                                     inline=False
                                                                     )
        
        self._widget_select_cross_section.param.watch(self._callback_selection_plot2d, 'value', onlychanged=False)

        self._widget_update_cross_section = pn.widgets.Button(name="Update Cross Section", button_type="success")
        self._widget_update_cross_section.param.watch(self._callback_cross_section, 'clicks', onlychanged=False)

        self._w_section_name = pn.widgets.TextInput(name="Name cross section:", value='CS_1')
        self._w_p1_x = pn.widgets.TextInput(name='x:', value= '10.0', width=60)
        self._w_p1_y = pn.widgets.TextInput(name='y:', value= '20.0', width=60)

        self._w_p2_x = pn.widgets.TextInput(name='x:', value='200.0', width=60)
        self._w_p2_y = pn.widgets.TextInput(name='y:', value='400.0', width=60)

        self._widget_add_cs = pn.widgets.Button(name="Add cross section", button_type="success")
        self._widget_add_cs .param.watch(self._callback_add_cs, 'clicks', onlychanged=False)

        self._w_remove_name = pn.widgets.AutocompleteInput(name='Cross section name',
                                                           options=list(self.section_dict.keys()))

        self._widget_remove_cs = pn.widgets.Button(name="Remove cross section", button_type="success")
        self._widget_remove_cs.param.watch(self._callback_remove_cs, 'clicks', onlychanged=False)

        widgets = pn.Column('### Creation of 2D Plots',
                            self._widget_update_cross_section,
                            '<b>add new cross section</b>',
                            pn.WidgetBox(self._w_section_name,
                                         pn.Row(pn.WidgetBox('From',
                                                             self._w_p1_x,
                                                             self._w_p1_y,
                                                             horizontal=True),
                                                pn.WidgetBox('To',
                                                             self._w_p2_x,
                                                             self._w_p2_y,
                                                             horizontal=True))),
                            self._widget_add_cs,
                            '<b>Remove cross section</b>',
                            self._w_remove_name,
                            self._widget_remove_cs,
                            '<b>Select cross section to display</b>',
                            self._widget_select_cross_section,
                            )

        panel = pn.Row(widgets, self.panel_plot_2d)
        return panel

    def widget_model_selector(self):
        self._widget_model_selector = pn.widgets.RadioButtonGroup(name='Model selector',
                                                                  options=list(self.model_dict.keys()),
                                                                  value=self.geo_model.meta.project_name,
                                                                  button_type='success')
        self._widget_model_selector.param.watch(self._callback_selection, 'value', onlychanged=False)

        panel = pn.Column("### Model Selector widgets",
                            self._widget_model_selector,
                            self.panel_actual_model)

        return panel

    def _callback_add_cs(self, event):
        name = self._w_section_name.value
        p1 = (float(self._w_p1_x.value), float(self._w_p1_y.value))
        p2 = (float(self._w_p2_x.value), float(self._w_p2_y.value))
        self.set_section_dict(p1, p2, name)
        self._widget_select_cross_section.options = list(self.section_dict.keys())
        self._widget_remove_cs.options = list(self.section_dict.keys())

    def _callback_remove_cs(self, event):  # TODO: Not working properly
        self.remove_section_dict(self._w_remove_name.value)
        self._widget_select_cross_section.options = list(self.section_dict.keys())

    def _callback_add_bh(self, event):
        name = self._w_borehole_name.value
        xy = (float(self._w_x.value), float(self._w_x.value))
        self.set_borehole_dict(xy, name)
        self._widget_boreholes_available.options = list(self.borehole_dict.keys())
        self._widget_remove_bh.options = list(self.borehole_dict.keys())

    def _callback_remove_bh(self, event):  # TODO: Not working properly
        self.remove_section_dict(self._w_remove_borehole_name.value)
        self._widget_boreholes_available.options = list(self.borehole_dict.keys())
        self._w_remove_borehole_name.options = list(self.section_dict.keys())

    def _callback_param_3d_model(self, event):
        for key in self._param_3d_model.keys():
            if key in event.new:
                self._param_3d_model[key] = True
            else:
                self._param_3d_model[key] = False

    def _callback_show_3d_model(self, event):
        self.lock.acquire()
        vtk = self.show_3d_model_panel()
        vtk.show()
        self.lock.release()

    def _callback_show_3d_model_pyvista(self, event):
        self.lock.acquire()
        geo = self.plot_3d_model()
        geo.p.show()
        self.lock.release()

    def _callback_show_boreholes_pyvista(self, event):
        self.lock.acquire()
        p = self.plot_boreholes(notebook=False)
        p.show()
        self.lock.release()

    def _callback_section_traces(self, event):
        self.lock.acquire()
        _ = self.show_section_traces()
        self.lock.release()

    def _callback_geo_map(self, event):
        self.lock.acquire()
        _ = self.show_geological_map()
        self.lock.release()

    def _callback_cross_section(self, event):
        self.lock.acquire()
        _ = self.show_cross_section(self._widget_select_cross_section.value)
        self.lock.release()

    def _callback_selection(self, event):
        """
        callback function for the widget to update the self.
        :return:
        """
        self.lock.acquire()
        geo_model = self.model_dict[event.new]
        self.change_model(geo_model)
        self.lock.release()

    def _callback_show_boreholes(self, event):
        self._get_polygon_data()
        vtk = self.show_boreholes_panel()
        vtk.show()

    def _callback_vertical_exageration(self, event):
        self._ve = event.new

    def _callback_selection_plot2d(self, event):
        _ = self.show_cross_section(event.new)



================================================
FILE: sandbox/modules/gempy/plot.py
================================================
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib
from gempy.plot.visualization_2d import Plot2D

lith = None
hill = None

def plot_gempy_topography(ax,
                          geo_model,
                          extent,
                          show_lith: bool = True,
                          show_boundary: bool = True,
                          show_hillshade: bool = True,
                          show_contour: bool = False,
                          **kwargs):
    """
    Use the native plotting function class of gempy to plot the lithology, boundaries and hillshading.
    Args:
        ax: axes of sandbox to paint in
        geo_model: geo_model from gempy
        extent:
        show_lith: default True
        show_boundary: default True
        show_hillshade: default True
        show_contour: default False (using native sandbox contours)
    Returns:

    """
    cmap = mcolors.ListedColormap(list(geo_model._surfaces.df['color']))
    delete_ax(ax)
    p = Plot2D(geo_model)
    p.fig = ax.figure
    p.add_section(ax=ax, section_name="topography")
    if show_lith:
        p.plot_lith(ax, section_name="topography")
    if show_boundary:
        p.plot_contacts(ax, only_faults=True, section_name="topography")

    if show_hillshade or show_contour:
        p.plot_topography(ax,
                          contour=show_contour,
                          # fill_contour=True,
                          hillshade=show_hillshade,
                          # cmap= cmap,
                          section_name="topography")
    ax.set_axis_off()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    # ax.set_title("")
    return ax, cmap


def plot_gempy(ax,
               geo_model,
               extent,
               show_lith: bool = True,
               show_boundary: bool = True,
               show_hillshade: bool = True,
               show_contour: bool = False,
               show_only_faults: bool = False,
               **kwargs):
    """
    Use the native plotting function class of gempy to plot the lithology, boundaries and hillshading.
    Args:
        ax: axes of sandbox to paint in
        geo_model: geo_model from gempy
        extent:
        show_lith: default True
        show_boundary: default True
        show_hillshade: default True
        show_contour: default False (using native sandbox contours)
        show_only_faults: plot only the fault lines
    Returns:

    """
    cmap = mcolors.ListedColormap(list(geo_model._surfaces.df['color']))
    norm = mcolors.Normalize(vmin=0.5, vmax=len(cmap.colors) + 0.5)
    # color_dir = dict(zip(self.model._surfaces.df['surface'], self.model._surfaces.df['color']))
    extent_val = extent[:4]  # [*ax.get_xlim(), *ax.get_ylim()]
    delete_ax(ax)
    if show_lith:
        # Todo: use instead native cmap module of sandbox
        plot_lith(ax, geo_model, extent_val, cmap, norm)
    if show_boundary:
        plot_contacts(ax, geo_model, extent_val, cmap, only_faults=show_only_faults)
    if show_hillshade or show_contour:
        plot_topography(ax,
                        geo_model,
                        extent_val,
                        show_hillshade=show_hillshade,
                        show_contour=show_contour,
                        **kwargs)
    ax.set_axis_off()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax.set_xlim(extent_val[0], extent_val[1])
    ax.set_ylim(extent_val[2], extent_val[3])
    return ax, cmap


def plot_lith(ax, geo_model, extent_val, cmap, norm):
    """

    Args:
        ax: sandbox axes
        geo_model: gempy geo_model
        extent_val: extent x and y of the model
        cmap:
        norm:

    Returns:

    """
    image = geo_model.solutions.geological_map[0].reshape(
        geo_model._grid.topography.values_2d[:, :, 2].shape)
    global lith
    lith = ax.imshow(image, origin='lower', zorder=-10, extent=extent_val, cmap=cmap, norm=norm, aspect='auto')


def plot_contacts(ax, geo_model, extent_val, cmap, only_faults=False):
    """

    Args:
        ax:
        geo_model:
        extent_val:
        cmap:
        only_faults:

    Returns:

    """
    zorder = 100
    if only_faults:
        contour_idx = list(geo_model._faults.df[geo_model._faults.df['isFault'] == True].index)
    else:
        contour_idx = list(geo_model._surfaces.df.index)

    shape = geo_model._grid.topography.resolution

    scalar_fields = geo_model.solutions.geological_map[1]
    c_id = 0  # color id startpoint

    for e, block in enumerate(scalar_fields):
        level = geo_model.solutions.scalar_field_at_surface_points[e][np.where(
            geo_model.solutions.scalar_field_at_surface_points[e] != 0)]

        c_id2 = c_id + len(level)  # color id endpoint
        ax.contour(block.reshape(shape), 0, levels=np.sort(level),
                   colors=cmap.colors[c_id:c_id2][::-1],
                   linestyles='solid', origin='lower',
                   extent=extent_val, zorder=zorder - (e + len(level))
                   )
        c_id = c_id2


def plot_topography(ax, geo_model, extent_val, **kwargs):
    """

    Args:
        ax:
        geo_model:
        extent_val:
        **kwargs:

    Returns:

    """
    hillshade = kwargs.pop('show_hillshade', True)
    contour = kwargs.pop('show_contour', False)
    fill_contour = kwargs.pop('show_fill_contour', False)
    azdeg = kwargs.pop('azdeg', 0)
    altdeg = kwargs.pop('altdeg', 0)
    cmap = kwargs.pop('cmap', 'terrain')
    super = kwargs.pop('super_res', False)
    colorbar = kwargs.pop("show_colorbar", False)

    topo = geo_model._grid.topography
    if super:
        import skimage
        topo_super_res = skimage.transform.resize(
            topo.values_2d,
            (1600, 1600),
            order=3,
            mode='edge',
            anti_aliasing=True, preserve_range=False)
        values = topo_super_res[..., 2]
    else:
        values = topo.values_2d[..., 2]

    if contour is True:
        CS = ax.contour(values, extent=extent_val,
                        colors='k', linestyles='solid', origin='lower')
        ax.clabel(CS, inline=1, fontsize=10, fmt='%d')
    if fill_contour is True:
        CS2 = ax.contourf(values, extent=extent_val, cmap=cmap)
        if colorbar:
            from gempy.plot.helpers import add_colorbar
            add_colorbar(axes=ax, label='elevation [m]', cs=CS2)

    if hillshade is True:
        from matplotlib.colors import LightSource
        # Note: 180 degrees are subtracted because visualization in Sandbox is upside-down
        ls = LightSource(azdeg=azdeg - 180, altdeg=altdeg)
        # TODO: Is is better to use ls.hillshade or ls.shade??
        hillshade_topography = ls.hillshade(values)
                                        # vert_exag=0.3,
                                        # blend_mode='overlay')
        global hill
        hill = ax.imshow(hillshade_topography,
                         cmap=plt.cm.gray,
                         origin='lower',
                         extent=extent_val,
                         alpha=0.4,
                         zorder=11,
                         aspect='auto')


def delete_ax(ax):
    """
    replace the ax.cla(). delete contour fill and images of hillshade and lithology
    Args:
        ax:
    Returns:
        ax
    """
    global lith, hill
    if lith is not None:
        lith.remove()
        lith = None
    if hill is not None:
        hill.remove()
        hill = None
    [fill.remove() for fill in reversed(ax.collections) if isinstance(fill, matplotlib.collections.PathCollection)]
    [coll.remove() for coll in reversed(ax.collections) if isinstance(coll, matplotlib.collections.LineCollection)]
    [text.remove() for text in reversed(ax.texts) if isinstance(text, matplotlib.text.Text)]
    return ax

def _plot_gempy(ax, geo_model):
    """
    DEPRECATED!!!
    Plot the geological map of the sandbox in the axes
    Args:
        ax: axes to the figure to plot
        geo_model: gempy model
    Returns:
        Painted axes

    """
    cmap = mcolors.ListedColormap(list(geo_model.surfaces.df['color']))
    ax = delete_ax(ax)
    ax = _add_faults(ax, geo_model, cmap)
    ax = _add_lith(ax, geo_model, cmap)
    return ax, cmap


def _add_faults(ax, geo_model, cmap):
    ax = _extract_boundaries(ax, geo_model, cmap, e_faults=True, e_lith=False)
    return ax


def _add_lith(ax, geo_model, cmap):
    ax = _extract_boundaries(ax, geo_model, cmap, e_faults=False, e_lith=True)
    return ax


def _extract_boundaries(ax, geo_model, cmap, e_faults=False, e_lith=False):
    faults = list(geo_model._faults.df[geo_model._faults.df['isFault'] == True].index)
    shape = geo_model._grid.topography.resolution
    a = geo_model.solutions.geological_map[1]
    extent = geo_model._grid.topography.extent
    zorder = 2
    counter = a.shape[0]

    if e_faults:
        counters = np.arange(0, len(faults), 1)
        c_id = 0  # color id startpoint
    elif e_lith:
        counters = np.arange(len(faults), counter, 1)
        c_id = len(faults)  # color id startpoint
    else:
        raise AttributeError

    for f_id in counters:
        block = a[f_id]
        level = geo_model.solutions.scalar_field_at_surface_points[f_id][np.where(
            geo_model.solutions.scalar_field_at_surface_points[f_id] != 0)]

        levels = np.insert(level, 0, block.max())
        c_id2 = c_id + len(level)
        if f_id == counters.max():
            levels = np.insert(levels, level.shape[0], block.min())
            c_id2 = c_id + len(levels)  # color id endpoint
        block = block.reshape(shape)
        zorder = zorder - (f_id + len(level))

        if f_id >= len(faults):
            fill = ax.contourf(block, 0, levels=np.sort(levels), colors=cmap.colors[c_id:c_id2][::-1],
                               linestyles='solid', origin='lower',
                               extent=extent, zorder=zorder)
        else:
            fau = ax.contour(block, 0, levels=np.sort(levels), colors=cmap.colors[c_id:c_id2][0],
                             linestyles='solid', origin='lower',
                             extent=extent, zorder=zorder)
        c_id += len(level)

    return ax



================================================
FILE: sandbox/modules/gempy/utils.py
================================================
import numpy
from sandbox import set_logger
logger = set_logger(__name__)


def get_scale(physical_extent: list, model_extent: list, sensor_extent: list, xy_isometric: bool = False):
    """
    Calculates the factors for the coordinates transformation kinect-extent
    Model is extended in one horizontal direction to fit  into box while the scale
    pixel_scale [modelunits/pixel]: XY scaling factor
    pixel_size [mm/pixel]
    scale in model units
    Args:
        physical_extent: [box_width, box_height]
        model_extent: [x_origin, xmax, yorigin, ymax, zmin, zmax]
        sensor_extent:  [0, sensor_width, 0. sensor_height, vmin, vmax]
        xy_isometric: True
    Returns:
        scale in model units, pixel_scale [modelunits/pixel], pixel_size [mm/pixel]
    """
    scale = [None, None, None]
    pixel_size = [None, None]
    pixel_scale = [None, None]

    pixel_scale[0] = float(model_extent[1] - model_extent[0]) / float(sensor_extent[1])
    pixel_scale[1] = float(model_extent[3] - model_extent[2]) / float(sensor_extent[3])

    pixel_size[0] = float(physical_extent[0]) / float(sensor_extent[1])
    pixel_size[1] = float(physical_extent[1]) / float(sensor_extent[3])

    # TODO: change the extent in place!! or create a new extent object that stores the extent after that modification.
    if xy_isometric:  # model is extended in one horizontal direction to fit  into box while the scale
        # in both directions is maintained
        logger.info("Aspect ratio of the model is fixed in XY")
        if pixel_scale[0] >= pixel_scale[1]:
            pixel_scale[1] = pixel_scale[0]
            logger.info("Model size is limited by X dimension")
        else:
            pixel_scale[0] = pixel_scale[1]
            logger.info("Model size is limited by Y dimension")

    scale[0] = pixel_scale[0] / pixel_size[0]
    scale[1] = pixel_scale[1] / pixel_size[1]
    # Vertical scaling
    scale[2] = float(model_extent[5] - model_extent[4]) / (sensor_extent[5] - sensor_extent[4])
    logger.info("scale in Model units/ mm (X,Y,Z): " + str(scale))
    return scale, pixel_scale, pixel_size


class Grid(object):
    """
    class for grid objects. a grid stores the 3D coordinate of each pixel recorded by the kinect in model coordinates
    """

    def __init__(self, physical_extent: list, model_extent: list, sensor_extent: list, scale=None):
        """

        Args:
            physical_extent: [box_width, box_height]
            model_extent: [x_origin, xmax, yorigin, ymax, zmin, zmax]
            sensor_extent:  [0, sensor_width, 0. sensor_height, sensor_min, sensor_max]
         Returns:
            None
        """
        if scale is None:
            self.scale, _, _ = get_scale(physical_extent, model_extent, sensor_extent)
        else:
            self.scale = scale

        self.sensor_extent = sensor_extent
        self.physical_extent = physical_extent
        self.model_extent = model_extent

        self.depth_grid = None
        self.empty_depth_grid = None
        self.create_empty_depth_grid()

    def create_empty_depth_grid(self):
        """
        Sets up XY grid (Z is empty, that is where the name is coming from)
        Returns:

        """
        width = numpy.linspace(self.model_extent[0], self.model_extent[1], self.sensor_extent[1])
        height = numpy.linspace(self.model_extent[2], self.model_extent[3], self.sensor_extent[3])
        xx, yy = numpy.meshgrid(width, height)
        self.empty_depth_grid = numpy.vstack([xx.ravel(), yy.ravel()]).T

        logger.info("the shown extent is [" + str(self.empty_depth_grid[0, 0]) + ", " +
              str(self.empty_depth_grid[-1, 0]) + ", " +
              str(self.empty_depth_grid[0, 1]) + ", " +
              str(self.empty_depth_grid[-1, 1]) + "] "
              )

    def scale_frame(self, frame):
        """Method to scale the frame"""
        if self.model_extent[-2] < 0:
            displace = self.model_extent[-2] * (-1) * (self.sensor_extent[-1] - self.sensor_extent[-2]) / (
                    self.model_extent[-1] - self.model_extent[-2])
            scaled_frame = frame - displace
            # now we set 2 regions. One above sea level and one below sea level. So now we can normalize these two
            # regions above 0
            scaled_frame[scaled_frame > 0] = scaled_frame[scaled_frame > 0] * (self.model_extent[-1] /
                                                                               (self.sensor_extent[-1]-displace))
            # below 0
            scaled_frame[scaled_frame < 0] = scaled_frame[scaled_frame < 0] * (self.model_extent[-2] /
                                                                               (self.sensor_extent[-2]-displace))
        else:
            scaled_frame = frame * self.scale[2]
            scaled_frame = scaled_frame + self.model_extent[-2]
        return scaled_frame

    def update_grid(self, scale_frame):
        """
        The frame that is passed here is cropped and clipped
        Appends the z (depth) coordinate to the empty depth grid.
        this has to be done every frame while the xy coordinates
        only change if the calibration or model extent is changed.
        For performance reasons these steps are therefore separated.

        Args:
            scale_frame: The frame that is passed here is cropped and clipped

        Returns:
        """
        flattened_depth = scale_frame.ravel()
        depth_grid = numpy.c_[self.empty_depth_grid, flattened_depth]

        self.depth_grid = depth_grid



================================================
FILE: sandbox/modules/gimli/__init__.py
================================================
from sandbox import set_logger
logger = set_logger(__name__)
try:
    from .geoelectrics import GeoelectricsModule
except:
    logger.warning("Geophysics module will not work. PyGimli dependencies not found")


if __name__ == '__main__':
    pass


================================================
FILE: sandbox/modules/gimli/geoelectrics.py
================================================
import matplotlib.pyplot as plt
from matplotlib.figure import Figure
import panel as pn
import numpy
import pygimli as pg
import pygimli.meshtools as mt
import pygimli.physics.ert as ert
from pygimli.viewer.mpl.meshview import drawStreamLines, drawStreams
from ..template import ModuleTemplate
from sandbox import set_logger
logger = set_logger(__name__)

import logging

pg.setLogLevel(logging.WARNING)  # to reduce logging output


class GeoelectricsModule(ModuleTemplate):
    """
    Module to show the potential fields of a geoelectric (DC resistivity) forward modelling and sesitivity analysis
    check "https://www.pygimli.org/_examples_auto/3_dc_and_ip/plot_04_ert_2_5d_potential.html#sphx-glr-examples-auto-3-dc-and-ip-plot-04-ert-2-5d-potential-py"
    for more information
    """

    def __init__(self, *args, extent: list = None, **kwargs):
        if extent is not None:
            self.extent = extent
        self.vmin = 5.  # ohm*m
        self.vmax = 1e5  # ohm*m
        self.mesh_fine = None
        self.mesh = None
        self.data_fine = None
        self.data = None
        self.scheme = None
        self.sim = None
        self.pot = None
        self.fop = None
        self.normsens = None
        self.electrode = None

        self.step = 7.5
        self.sensitivity_real_time = False
        self.view = "mesh"  # "potential"  "sensitivity""
        self.id = None
        self.real_time = False
        self.p_stream = False
        self.p_quiver = False
        self.frame = None
        self.df_markers = []
        self._figsize = (15, 8)
        self._recalculate_mesh = False

        # Widgets
        self._a_id = 0
        self._b_id = 3
        self._n_id = 1
        self._m_id = 2
        self.figure_mesh = Figure()
        self.panel_figure_mesh = pn.pane.Matplotlib(self.figure_mesh, tight=True)
        plt.close(self.figure_mesh)

        self.figure_field = Figure()
        self.panel_figure_field = pn.pane.Matplotlib(self.figure_field, tight=True)
        plt.close(self.figure_field)

        self.figure_sensitivity = Figure()
        self.panel_figure_sensitivity = pn.pane.Matplotlib(self.figure_sensitivity, tight=True)
        plt.close(self.figure_sensitivity)

        logger.info("GeoelectricsModule loaded successfully")

    def update(self, sb_params: dict):
        frame = sb_params.get('frame')
        extent = sb_params.get('extent')
        frame, extent = self.scale_data(frame, extent)
        ax = sb_params.get('ax')
        markers = sb_params.get('marker')
        self.lock = sb_params.get("lock_thread")
        if len(markers) > 0:
            self.df_markers = markers.loc[markers.is_inside_box]
            if len(self.df_markers) == 4 and self.id is not None:
                self.set_aruco_electrodes(self.df_markers)
                if self.real_time:
                    self.update_resistivity(frame, self.extent, self.step)
                    if self.sensitivity_real_time:
                        self.calculate_sensitivity()

        ax, activate_c = self.plot(ax)
        sb_params["frame"] = frame
        sb_params["extent"] = extent
        sb_params["active_contours"] = activate_c
        return sb_params

    def plot(self, ax):
        self.delete_image(ax)
        activate_c = True
        if self.p_stream and self.pot is not None:
            self.plot_stream_lines(ax)
            activate_c = False
        if self.p_quiver and self.pot is not None:
            self.plot_quiver(ax)
            activate_c = False
        if self.view == "potential" and self.pot is not None:
            self.plot_potential(ax)
            activate_c = False
        elif self.view == "sensitivity" and self.normsens is not None:
            self.plot_sensitivity(ax)
            activate_c = False
        return ax, activate_c

    def scale_data(self, frame, extent, vmax: float = None, vmin: float = None):
        """
        Find a better way to do the scaling of the data
        Args:
            frame: sandbox frame
            extent: sandbox extent
            vmin: minimum value of ohm*m
            vmax: maximum value of ohm*m
        Returns:
            modifyied sandbox frame and extent(vmin and vmax)
        """
        if vmin is None:
            vmin = self.vmin
        if vmax is None:
            vmax = self.vmax
        frame = frame * 1000 + 50
        extent[-1] = extent[-1] * 1000 + 50  # max_height
        extent[-2] = extent[-2] * 1000 + 50  # min_height
        self.frame = frame
        self.extent = extent
        return self.frame, self.extent

    def scale_linear(self, frame, extent, vmin: float = None, vmax: float = None):
        """
        DOES NOT WORK WITH THIS SCALING!!! Neds to be more extreme
        Modify the frame to get some realistic Ohm*m values
        # TODO: Normalize logaritmically? to have more extreme values
        Args:
            frame: sandbox frame
            extent: sandbox extent
            vmin: minimum value of ohm*m
            vmax: maximum value of ohm*m
        Returns:
            modifyied sandbox frame and extent(vmin and vmax)
        """
        if vmin is None:
            vmin = self.vmin
        if vmax is None:
            vmax = self.vmax

        frame = frame * (vmax - vmin) / (extent[-1] - extent[-2])
        frame = frame + vmin

        extent[-1] = vmax  # max_height
        extent[-2] = vmin  # min_height

        self.frame = frame
        self.extent = extent
        return self.frame, self.extent

    def delete_image(self, ax):
        # [coll.remove() for coll in reversed(ax.collections) if isinstance(coll, matplotlib.collections.PathCollection )]
        ax.cla()  # TODO: find a better way to do this
        ax.set_axis_off()
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)

    def plot_stream_lines(self, ax):
        drawStreamLines(ax, self.mesh, self.pot, color='Black', nx=100, ny=100, linewidth=1.0, zorder=50)

    def plot_quiver(self, ax):
        drawStreams(ax, self.mesh, pg.solver.grad(self.mesh, -self.pot), color='Black', quiver=True, zorder=49)

    def plot_potential(self, ax):
        pg.show(self.mesh, self.pot, ax=ax, cMap="RdBu_r", nLevs=11, colorBar=False, extent=self.extent[:4], zorder=20)

    def plot_sensitivity(self, ax):
        pg.show(self.mesh, self.normsens, cMap="RdGy_r", ax=ax, colorBar=False, nLevs=3, cMin=-1, cMax=1,
                extent=self.extent[:4], zorder=30)

    def set_id_aruco(self, ids: dict):
        """
        key of the dictionary must be the aruco id and the value is the postion from 0 to 3.
        i.e. id = {12: 0, 20: 1, 13: 2, 4: 3}
        Args:
            ids:

        Returns:
        """
        if isinstance(ids, dict):
            self.id = ids
        else:
            logger.warning("Data type not accepted. Only accept dictionary as parameter")

    def set_aruco_electrodes(self, df):
        """
        Convert the aruco data frame into
        Args:
            df: pandas dataframe containing the markers
            id: dictionary indicating the id number and the corresponding order
        Returns:

        """
        df = df[['box_x', 'box_y']].copy()
        markers = numpy.zeros((4, 2))
        try:
            for index in self.id.keys():
                markers[self.id[index], :] = df.loc[index]
            self.set_electrode_positions(markers)
        except:
            logger.warning("index " + str(index) + "  not found in aruco markers inside box, check your markers again")

    def update_resistivity(self, frame, extent, step):
        if self.mesh is None:
            _ = self.create_mesh(frame, step, extent)
        if self._recalculate_mesh:
            _ = self.create_mesh(frame, step, extent)
        _ = self.create_data_containerERT()
        _ = self.calculate_current_flow()

    def create_mesh(self, frame, step=7.5, extent=None):
        """
        create a grid mesh and populate the mesh with the frame data
        Args:
            frame:
            step:
            extent:
        Returns:

        """
        if extent is None:
            y, x = frame.shape
        else:
            x = extent[1]
            y = extent[3]

        self.mesh_fine = mt.createGrid(numpy.arange(0, x, step=1),
                                       numpy.arange(0, y, step=1))
        self.data_fine = mt.nodeDataToCellData(self.mesh_fine, frame.ravel())

        self.mesh = mt.createGrid(numpy.arange(0, x + step, step=step),
                                  numpy.arange(0, y + step, step=step))
        self.data = pg.interpolate(srcMesh=self.mesh_fine, inVec=self.data_fine,
                                   destPos=self.mesh.cellCenters()).array()
        return self.mesh, self.data

    def show_mesh(self):
        """
        Visualize the original and coarser resolution of the frame to use
        Returns:
            plot

        """
        fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=self._figsize)
        # plt.close(fig)
        pg.show(self.mesh_fine, self.data_fine, ax=ax1, colorBar=True, label=r"Resistivity ($\Omega m$)",
                extent=self.extent[:4])
        pg.show(self.mesh, self.data, ax=ax2, colorBar=True, label=r"Resistivity ($\Omega m$)",
                extent=self.extent[:4])
        ax1.set_title("Original resolution")
        ax2.set_title("Coarser resolution")
        logger.info("Original %s" % self.mesh_fine)
        logger.info("Coarse %s" % self.mesh)
        logger.info("Size reduction by %.2f%%" % float(100 - self.mesh.cellCount() / self.mesh_fine.cellCount() * 100))
        return fig

    def set_electrode_positions(self, markers=numpy.array(([20, 130],
                                                           [160, 20],
                                                           [50, 60],
                                                           [150, 120]))
                                ):
        """
        Use the arucos or a numpy array to position the electrodes
        Args:
            markers: numpy array of shape (4,2)

        Returns:

        """
        self.electrode = markers

    def create_data_containerERT(self, measurements=numpy.array([[0, 1, 2, 3], ]),  # Dipole-Dipole
                                 scheme_type="abmn", verbose=False):
        """
        creates the scheme from the previous 4 aruco markers detected
        Args:
            measurements: Dipole-Dipole
            scheme_type: assign the type of electrode to the aruco
            verbose:

        Returns:

        """
        scheme = pg.DataContainerERT()
        scheme.setSensorPositions(self.electrode)
        for i, elec in enumerate(scheme_type):
            scheme[elec] = measurements[:, i]
        scheme["k"] = ert.createGeometricFactors(scheme, verbose=verbose)
        self.scheme = scheme
        return self.scheme

    def calculate_current_flow(self, time=False, verbose=False):
        """
        Perform the simulation based on the mesh, data and scheme
        Returns:
            RMatrix and RVector

        """
        if time:
            pg.tic()
        self.sim = ert.simulate(self.mesh, res=self.data, scheme=self.scheme, sr=False,
                                calcOnly=True, verbose=verbose, returnFields=True)
        if time:
            pg.toc("Current flow", box=True)
        self.pot = pg.utils.logDropTol(self.sim[0] - self.sim[1], 10)
        return self.sim, self.pot

    def show_streams(self, quiver=False):
        """
        Show the solution of the simulation and draw a stream plot perpendicular to the electric field
        Returns:

        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=self._figsize, sharey=True)
        #plt.close(fig)
        pg.show(self.mesh, self.data, ax=ax1, label="Resistivity ($\Omega m$)", extent=self.extent[:4])
        pg.show(self.mesh, self.pot, ax=ax2, nLevs=11, cMap="RdBu_r",
                label="Potential ($u$)", extent=self.extent[:4])

        for ax in ax1, ax2:
            ax.plot(self.electrode[0, 0], self.electrode[0, 1], "ro")  # Source
            ax.plot(self.electrode[1, 0], self.electrode[1, 1], "bo")  # Sink
            drawStreamLines(ax, self.mesh, self.pot, color='Black', nx=100, ny=100, linewidth=1.0)
            if quiver:
                drawStreams(ax, self.mesh, pg.solver.grad(self.mesh, -self.pot), color='Black', quiver=True)
        return fig

    def calculate_sensitivity(self, time=False):
        """
        Make a sensitivity analysis
        Returns:

        """
        if time:
            pg.tic()
        self.fop = ert.ERTModelling()
        self.fop.setData(self.scheme)
        self.fop.setMesh(self.mesh)
        self.fop.createJacobian(self.data)
        if time:
            pg.toc("Sensitivity calculation", box=True)
        sens = self.fop.jacobian()[0]  # first row = first measurement
        self.normsens = pg.utils.logDropTol(sens / self.mesh.cellSizes(), 5e-5)
        self.normsens /= numpy.max(self.normsens)
        return self.fop

    def show_sensitivity(self):
        """
        Show the sensitivity analysis
        Returns:

        """
        fig, ax = plt.subplots(figsize=self._figsize)
        #plt.close(fig)
        pg.show(self.mesh, self.normsens, cMap="RdGy_r", orientation="vertical", ax=ax,
                label="Normalized\nsensitivity", nLevs=3, cMin=-1, cMax=1, extent=self.extent[:4])
        for m in self.electrode:
            ax.plot(m[0], m[1], "ko")
        return fig

    def update_panel_mesh(self):
        fig, ax = plt.subplots()
        plt.close(fig)
        pg.show(self.mesh, self.data, ax=ax, colorBar=True, extent=self.extent[:4],
                orientation="vertical", label=r"Resistivity ($\Omega m$)")
        if self.electrode is not None:
            ax.plot(self.electrode[0, 0], self.electrode[0, 1], "ro")  # Source
            ax.plot(self.electrode[1, 0], self.electrode[1, 1], "bo")  # Sink
            if self.pot is not None:
                drawStreamLines(ax, self.mesh, self.pot, color='Black', nx=100, ny=100, linewidth=1.0)
        ax.set_title("Coarse Mesh")
        self.panel_figure_mesh.object = fig
        self.panel_figure_mesh.param.trigger("object")

    def update_panel_field(self):
        fig, ax = plt.subplots()
        plt.close(fig)
        pg.show(self.mesh, self.pot, ax=ax, nLevs=11, cMap="RdBu_r", extent=self.extent[:4],
                label="Potential ($u$)", orientation="vertical")
        if self.electrode is not None:
            ax.plot(self.electrode[0, 0], self.electrode[0, 1], "ro")  # Source
            ax.plot(self.electrode[1, 0], self.electrode[1, 1], "bo")  # Sink
            if self.pot is not None:
                drawStreamLines(ax, self.mesh, self.pot, color='Black', nx=100, ny=100, linewidth=1.0)
        ax.set_title("Current Flow")
        self.panel_figure_field.object = fig
        self.panel_figure_field.param.trigger("object")

    def update_panel_sensitivity(self):
        fig, ax = plt.subplots()
        plt.close(fig)
        pg.show(self.mesh, self.normsens, cMap="RdGy_r", orientation="vertical", ax=ax,
                label="Normalized\nsensitivity", nLevs=3, cMin=-1, cMax=1, extent=self.extent[:4])
        for m in self.electrode:
            ax.plot(m[0], m[1], "ko")
        ax.set_title("Sensitivity")
        self.panel_figure_sensitivity.object = fig
        self.panel_figure_sensitivity.param.trigger("object")

    def show_widgets(self):
        controller, real = self.widgets_controller()
        simulation = self.widgets_simulation()

        self._widget_progress = pn.widgets.Progress(name="Progress", active=True)
        self._widget_markdown_progress = pn.pane.Markdown("<p>Waiting</p><p>.</p>")

        panel = pn.Row(simulation,
                       pn.Column(self.panel_figure_mesh,
                                 self.panel_figure_field,
                                 self.panel_figure_sensitivity,
                                 self._widget_progress,
                                 self._widget_markdown_progress),
                       pn.Column(controller, real))
        return panel

    def widgets_controller(self):
        self._widget_visualize = pn.widgets.RadioBoxGroup(name='Show the following mode in the sandbox:',
                                                          options=["mesh", "potential", "sensitivity"],
                                                          value=self.view,
                                                          inline=False)
        self._widget_visualize.param.watch(self._callback_visualize, 'value', onlychanged=False)

        self._widget_p_stream = pn.widgets.Checkbox(name='Show current stream lines', value=self.p_stream)
        self._widget_p_stream.param.watch(self._callback_p_stream, 'value', onlychanged=False)

        self._widget_p_quiver = pn.widgets.Checkbox(name='Show vector field', value=self.p_quiver)
        self._widget_p_quiver.param.watch(self._callback_p_quiver, 'value', onlychanged=False)

        panel = pn.Column("###<b>Controllers</b>",
                          "<b>Visualization mode in the sandbox",
                          self._widget_visualize,
                          self._widget_p_stream,
                          self._widget_p_quiver
                          )
        self._widget_real_time = pn.widgets.Checkbox(name='Activate real time calculation',
                                                     value=self.real_time)
        self._widget_real_time.param.watch(self._callback_real_time, 'value', onlychanged=False)

        self._widget_recalculate_mesh = pn.widgets.Checkbox(name='Create mesh for every frame',
                                                            value=self._recalculate_mesh)
        self._widget_recalculate_mesh.param.watch(self._callback_recalculate, 'value', onlychanged=False)

        self._widget_recalculate_sensitivity = pn.widgets.Checkbox(name='Calculate sensitivity for every frame',
                                                                   value=self.sensitivity_real_time)
        self._widget_recalculate_sensitivity.param.watch(self._callback_recalculate_sensitivity, 'value',
                                                         onlychanged=False)
        self._widget_update_plots = pn.widgets.Button(name="Update all plots", button_type="success")
        self._widget_update_plots.param.watch(self._callback_update_plots, 'clicks', onlychanged=False)

        real = pn.WidgetBox("###<b>Update real time</b>",
                            self._widget_real_time,
                            self._widget_recalculate_mesh,
                            self._widget_recalculate_sensitivity,
                            "Remember that all 4 arucos must be detected and assigned to their respective electrodes. "
                            "Otherwise the real time calculation is stopped until it "
                            "can detect all electrodes",
                            self._widget_update_plots)
        return panel, real

    def widgets_simulation(self):
        self._widget_step = pn.widgets.Spinner(name="Coarsen the mesh by", value=self.step, step=0.1)
        self._widget_vmin = pn.widgets.Spinner(name="Minimum resistivity (ohm*m)", value=self.vmin, step=1)
        self._widget_vmax = pn.widgets.Spinner(name="Maximum resitivity (ohm*m)", value=self.vmax, step=1)

        self._widget_create_mesh = pn.widgets.Button(name="Create mesh", button_type="success")
        self._widget_create_mesh.param.watch(self._callback_create_mesh, 'clicks', onlychanged=False)
        s = "<p>Original None </p><p>.</p>" + \
            "<p>.</p> <p>Coarser None</p><p>.</p><p>.</p><p>Size reduction by None</p><p>.</p>"
        self._widget_markdown_mesh = pn.pane.Markdown(s)

        self._widget_a = pn.widgets.Spinner(name="Positive current electrode A", value=self._a_id, step=1)
        self._widget_b = pn.widgets.Spinner(name="Negative current electrode B", value=self._b_id, step=1)
        self._widget_m = pn.widgets.Spinner(name="Potential electrode M", value=self._m_id, step=1)
        self._widget_n = pn.widgets.Spinner(name="Potential electrode N", value=self._n_id, step=1)

        self._widget_set_electrodes = pn.widgets.Button(name="Set aruco electrodes", button_type="success")
        self._widget_set_electrodes.param.watch(self._callback_set_electrodes, 'clicks', onlychanged=False)

        s = "<p>Electrodes not set</p><p>.</p><p>.</p>"
        self._widget_markdown_electrodes = pn.pane.Markdown(s)

        self._widget_simulate = pn.widgets.Button(name="Simulate ert", button_type="success")
        self._widget_simulate.param.watch(self._callback_simulate, 'clicks', onlychanged=False)

        self._widget_sensitivity = pn.widgets.Button(name="Sensitivity analysis", button_type="success")
        self._widget_sensitivity.param.watch(self._callback_sensitivity, 'clicks', onlychanged=False)

        panel = pn.Column("###<b>Simulation</b>",
                          "<b>1) Create the mesh</b>",
                          self._widget_vmax,
                          self._widget_vmin,
                          self._widget_step,
                          self._widget_create_mesh,
                          self._widget_markdown_mesh,
                          "<b>2) Assign id aruco markers",
                          self._widget_a,
                          self._widget_b,
                          self._widget_m,
                          self._widget_n,
                          self._widget_set_electrodes,
                          self._widget_markdown_electrodes,
                          "<b>3) Calculate current-flow",
                          self._widget_simulate,
                          "<b>4) Calculate sensitivity",
                          self._widget_sensitivity
                          )

        return panel

    def _callback_update_plots(self, event):
        self.lock.acquire()
        self._widget_markdown_progress.object = "Updating mesh plot..."
        logger.info("Updating mesh plot...")
        self._widget_progress.value = 0
        self.update_panel_mesh()
        self._widget_markdown_progress.object = "Updating field plot..."
        logger.info("Updating field plot...")
        self._widget_progress.value = 40
        self.update_panel_field()
        self._widget_markdown_progress.object = "Updating sensitivity plot..."
        logger.info("Updating sensitivity plot...")
        self._widget_progress.value = 80
        self.update_panel_sensitivity()
        self._widget_markdown_progress.object = "Done"
        logger.info("Done")
        self._widget_progress.value = 100
        self.lock.release()

    def _callback_recalculate_sensitivity(self, event):
        self.sensitivity_real_time = event.new

    def _callback_recalculate(self, event):
        self._recalculate_mesh = event.new

    def _callback_real_time(self, event):
        self.real_time = event.new

    def _callback_visualize(self, event):
        self.view = event.new

    def _callback_p_stream(self, event):
        self.p_stream = event.new

    def _callback_p_quiver(self, event):
        self.p_quiver = event.new

    def _callback_create_mesh(self, event):
        self.lock.acquire()
        self._widget_markdown_progress.object = "Creating mesh..."
        logger.info("Creating mesh...")
        self._widget_progress.value = 0
        self.vmin = self._widget_vmin.value
        self.vmax = self._widget_vmax.value
        self.step = self._widget_step.value
        self.create_mesh(frame=self.frame, step=self.step)
        self._widget_progress.value = 50
        self._widget_markdown_progress.object = "Updating plot..."
        logger.info("Updating plot...")
        self.update_panel_mesh()
        self._widget_progress.value = 100
        s = """<p>Original %s </p> <p>Coarse %s </p> <p>Size reduction by %.2f%%</p>""" % \
            (str(self.mesh),
             str(self.mesh_fine),
             float(100 - self.mesh.cellCount() / self.mesh_fine.cellCount() * 100))
        self._widget_markdown_mesh.object = s
        logger.info(s)
        self._widget_markdown_progress.object = "Mesh ready"
        logger.info("Mesh ready")
        self.lock.release()

    def _callback_set_electrodes(self, event):
        self.lock.acquire()
        self._widget_markdown_progress.object = "Setting electrodes..."
        logger.info("Setting electrodes...")
        self._widget_progress.value = 0
        a = self._widget_a.value
        b = self._widget_b.value
        m = self._widget_m.value
        n = self._widget_n.value
        self.set_id_aruco({a: 0,
                           b: 1,
                           m: 2,
                           n: 3})
        self.set_aruco_electrodes(self.df_markers)
        self._widget_progress.value = 20
        if self.electrode is not None:
            self._widget_markdown_electrodes.object = "Ready electrodes: " + str(self.id)
            logger.info("Ready electrodes: " + str(self.id))
            self._widget_progress.value = 50
        else:
            self._widget_markdown_electrodes.object = "Error, check ids"
            logger.info("Error, check ids")
            self._widget_markdown_progress.object = "Error setting electrodes..."
            logger.info("Error setting electrodes...")
            self.lock.release()
            return
        self.create_data_containerERT()
        self._widget_progress.value = 80
        self._widget_markdown_progress.object = "Updating plot..."
        logger.info("Updating plot...")
        self.update_panel_mesh()
        self._widget_progress.value = 100
        self._widget_markdown_progress.object = "Electrodes ready"
        logger.info("Electrodes ready")
        self.lock.release()

    def _callback_simulate(self, event):
        self.lock.acquire()
        self._widget_progress.value = 0
        self._widget_markdown_progress.object = "Simulating..."
        logger.info("Simulating...")
        self.calculate_current_flow()
        self._widget_progress.value = 80
        self._widget_markdown_progress.object = "Updating plot 1..."
        logger.info("Updating plot 1...")
        self.update_panel_mesh()
        self._widget_progress.value = 90
        self._widget_markdown_progress.object = "Updating plot 2..."
        logger.info("Updating plot 2...")
        self.update_panel_field()
        self._widget_progress.value = 100
        self._widget_markdown_progress.object = "Simulation successful"
        logger.info("Simulation successful")
        self.lock.release()

    def _callback_sensitivity(self, event):
        self.lock.acquire()
        self._widget_progress.value = 0
        self._widget_markdown_progress.object = "Calculating sensitivity..."
        logger.info("Calculating sensitivity...")
        self.calculate_sensitivity()
        self._widget_progress.value = 80
        self._widget_markdown_progress.object = "Updating plot..."
        logger.info("Updating plot...")
        self.update_panel_sensitivity()
        self._widget_progress.value = 100
        self._widget_markdown_progress.object = "Sensitivity successful"
        logger.info("Sensitivity successful")
        self.lock.release()




================================================
FILE: sandbox/modules/pynoddy/__init__.py
================================================
from sandbox import set_logger
logger = set_logger(__name__)
try:
    from .pynoddy_module import PynoddyModule
except:
    logger.warning("Pynoddy module will not work. Dependencies not found")

if __name__ == '__main__':
    pass


================================================
FILE: sandbox/modules/pynoddy/pynoddy_module.py
================================================
import numpy as np
import pyvista
import skimage.transform
import matplotlib
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
from sandbox.modules.template import ModuleTemplate
from sandbox.modules.gempy.utils import Grid
from pynoddy.output import NoddyOutput
from sandbox import set_logger
logger = set_logger(__name__)


class PynoddyModule(ModuleTemplate):
    """https://github.com/cgre-aachen/pynoddy"""

    def __init__(self, output_model: NoddyOutput = None, extent: list = None, box: list = None):
        """

        Args:
            output_model:
            extent:
            box:
        """

        self.output_model = output_model
        self.sensor_extent = extent
        self.box_dimensions = box

        self.block_model = None
        self.model_extent = None
        self.model_resolution = None
        self.model_spacing = None
        self.grid = None

        self._block = None
        self._values_ix = None
        self.mask = None

        self.vertices_mapview = None

        self.set_NoddyOutput(self.output_model)

        self.hill = None
        self.lith = None
        self.lock = None

        logger.info("PynoddyModule loaded successfully")

    def set_NoddyOutput(self, n: NoddyOutput):
        """
        Args:
            n:

        Returns:
        """
        self.output_model = n
        self.model_extent = list(map(int, [0, n.extent_x, 0, n.extent_y, 0, n.extent_z]))
        logger.info("Model extent: %s" % self.model_extent)
        self.model_resolution = list(map(int, [n.nx, n.ny, n.nz]))
        logger.info("Model resolution: %s" % self.model_resolution)
        self.model_spacing = list(map(int, [n.delx, n.dely, n.delz]))
        logger.info("Size of each block: %s" % self.model_spacing)
        self.block_model = n.block
        self.grid = Grid(self.box_dimensions, self.model_extent, [0, self.model_resolution[0],
                                                                  0, self.model_resolution[1],
                                                                  self.sensor_extent[-2], self.sensor_extent[-1]])
        self.create_empty_block()

    def update(self, sb_params: dict):
        frame = sb_params.get("frame")
        extent = sb_params.get("extent")
        ax = sb_params.get("ax")
        self.lock = sb_params.get('lock_thread')

        scale_frame = self.scale_frame_to_model(frame)
        _ = self.grid.update_grid(scale_frame)

        empty2d = np.zeros((self.model_resolution[0], self.model_resolution[1], 3))
        for i in range(3):
            empty2d[:, :, i] = self.grid.depth_grid[:, i].reshape(self.model_resolution[:2])
        topo_level = empty2d[..., 2, np.newaxis]

        self.create_topography_mask(topo_level)
        self.set_block_solution_to_topography()
        self.plot(scale_frame, ax)

        sb_params['ax'] = ax
        sb_params['frame'] = scale_frame
        #sb_params['cmap'] = cmap
        #sb_params['marker'] = self.modelspace_arucos
        # This because we are currently plotting our own cmap and shading
        sb_params['active_cmap'] = False
        sb_params['active_shading'] = False
        sb_params['extent'] = self.model_extent
        # sb_params['del_contour'] = not self.show_boundary

        return sb_params

    def create_empty_block(self):
        dx = np.arange(self.model_extent[0], self.model_extent[1], self.model_spacing[0])
        dy = np.arange(self.model_extent[2], self.model_extent[3], self.model_spacing[1])
        dz = np.arange(self.model_extent[4], self.model_extent[5], self.model_spacing[2])

        g = np.meshgrid(dx, dy, dz, indexing="ij")
        values = np.vstack(tuple(map(np.ravel, g))).T.astype("float64")
        self._values_ix = values
        self._block = values[:, 2].reshape(self.model_resolution)

    def create_topography_mask(self, topo_level):
        self.mask = np.greater(topo_level, self._block)

    def set_block_solution_to_topography(self):
        """

        Returns:

        """
        cop = self.block_model.copy()
        mask = np.where(cop * self.mask == 0)
        cop[mask] = -1

        height, width, depth = cop.shape
        vertices = []
        for i in range(height):
            for j in range(width):
                pos = np.argmin(cop[i, j, :])
                vertices.append([i, j, self.block_model[i, j, pos]])
        self.vertices_mapview = np.asarray(vertices)

    def plot_3D(self, topography=True, notebook=True, **kwargs):
        if topography and self.mask is not None:
            new_block = self.block_model.copy() * self.mask
            new_block[np.where(new_block == 0)] = np.nan
        else:
            new_block = self.block_model.copy()
        cmap_type = kwargs.pop('cmap', 'YlOrRd')
        pyvista.plot(new_block, notebook=notebook, cmap = cmap_type, **kwargs)

    def plot_section(self, direction='y', position='center', topography=True, colorbar=True, **kwargs):
        """
         Create asecion block through the model
        Args:
            direction: 'x', 'y', 'z' : coordinate direction of section plot (default: 'y')
            position:  int or 'center' : cell position of section as integer value
            topography:
            colorbar:
            **kwargs:

        Returns:

        """
        aspect = kwargs.pop("aspect", "auto")
        cmap_type = kwargs.pop('cmap', 'YlOrRd')

        if 'ax' in kwargs:
            # append plot to existing axis
            ax = kwargs.pop('ax')
        else:
            figsize = kwargs.pop("figsize", (10, 6))
            fig, ax = plt.subplots(figsize=figsize)

        if 'x' in direction:
            xlabel = "y"
            ylabel = "z"
        elif 'y' in direction:
            xlabel = "x"
            ylabel = "z"
        elif 'z' in direction:
            xlabel = "x"
            ylabel = "y"

        if topography and self.mask is not None:
            data = self.block_model.copy() * self.mask
            data[np.where(data==0)] = np.nan
        else:
            data = self.block_model.copy()

        # plot section
        section_slice, cell_pos = self.output_model.get_section_voxels(direction, position, data=data)
        title = kwargs.pop("title", "Section in %s-direction, pos=%d" % (direction, cell_pos))

        im = ax.imshow(section_slice, interpolation='nearest', aspect=aspect, cmap=cmap_type, origin='lower', **kwargs)

        if colorbar:
            divider = make_axes_locatable(ax)
            cax = divider.append_axes("right", size="5%", pad=0.1)
            ax.figure.colorbar(im, cax=cax, ax=ax, label='Lithology')

        ax.set_title(title)
        ax.set_xlabel(xlabel)
        ax.set_ylabel(ylabel)
        return ax

    def delete_ax(self, ax):
        """
        replace the ax.cla(). delete contour fill and images of hillshade and lithology
        Args:
            ax:
        Returns:
            ax
        """
        if self.lith is not None:
            self.lith.remove()
            self.lith = None
        if self.hill is not None:
            self.hill.remove()
            self.hill = None

        [fill.remove() for fill in reversed(ax.collections) if isinstance(fill, matplotlib.collections.PathCollection)]
        [text.remove() for text in reversed(ax.texts) if isinstance(text, matplotlib.text.Text)]
        [coll.remove() for coll in reversed(ax.collections) if isinstance(coll, matplotlib.collections.LineCollection)]
        return ax

    def plot_mapview(self,
                     show_lith: bool = True,
                     # show_boundary: bool = True,
                     show_hillshade: bool = True,
                     show_contour: bool = False,
                     show_only_faults: bool = False,
                     **kwargs):

        cmap_type = kwargs.pop('cmap', 'YlOrRd')
        if 'ax' in kwargs:
            # append plot to existing axis
            ax = kwargs.pop('ax')
        else:
            figsize = kwargs.pop("figsize", (10, 6))
            fig, ax = plt.subplots(figsize=figsize)

        if show_lith:
            image = self.vertices_mapview[:, 2].reshape(self.model_resolution[:2])
            self.lith = ax.imshow(image,
                             origin='lower',
                             zorder=-10,
                             extent=self.model_extent[:4],
                             cmap=cmap_type,
                             #norm=norm,
                             aspect='auto')



        fill_contour = kwargs.pop('show_fill_contour', False)
        azdeg = kwargs.pop('azdeg', 0)
        altdeg = kwargs.pop('altdeg', 0)
        super = kwargs.pop('super_res', False)
        colorbar = kwargs.pop("show_colorbar", False)

        topo = self.grid.depth_grid[:, 2].reshape(self.model_resolution[:2])
        #if super:
        #    import skimage
        #    topo_super_res = skimage.transform.resize(
        #        topo,
        #        (1600, 1600),
        #        order=3,
        #        mode='edge',
        #        anti_aliasing=True, preserve_range=False)
        #    values = topo_super_res[..., 2]
        #else:
        #    values = topo.values_2d[..., 2]

        if show_contour is True:
            CS = ax.contour(topo, extent=self.model_extent[:4],
                            colors='k', linestyles='solid', origin='lower')
            ax.clabel(CS, inline=1, fontsize=10, fmt='%d')
        if fill_contour is True:
            CS2 = ax.contourf(topo, extent=self.model_extent[:4], cmap=cmap)
            if colorbar:
                from gempy.plot.helpers import add_colorbar
                add_colorbar(axes=ax, label='elevation [m]', cs=CS2)

        if show_hillshade:
            from matplotlib.colors import LightSource
            # Note: 180 degrees are subtracted because visualization in Sandbox is upside-down
            ls = LightSource(azdeg=azdeg - 180, altdeg=altdeg)
            # TODO: Is it better to use ls.hillshade or ls.shade??
            hillshade_topography = ls.hillshade(topo)
            # vert_exag=0.3,
            # blend_mode='overlay')
            self.hill = ax.imshow(hillshade_topography,
                             cmap=plt.cm.gray,
                             origin='lower',
                             extent=self.model_extent[:4],
                             alpha=0.4,
                             zorder=11,
                             aspect='auto')

    def plot(self, frame, ax):
        self.delete_ax(ax)
        self.plot_mapview(ax=ax)

    def scale_frame_to_model(self, topo):
        """
        Get the sandbox frame and rescale it to the model extents
        Args:
            topo:
        Returns:

        """
        grid_topo = skimage.transform.resize(topo,
                                             (self.model_resolution[:2]),
                                             mode='constant',
                                             anti_aliasing=False,
                                             preserve_range=True)
        scale_frame = self.grid.scale_frame(grid_topo)
        return scale_frame

    def show_widgets(self):
        pass



================================================
FILE: sandbox/modules/pytorch/__init__.py
================================================
from sandbox import set_logger
logger = set_logger(__name__)
try:
    from .landscape_generation import LandscapeGeneration
except:
    logger.warning("LandscapeGeneration module will not work. Dependencies not installed")


================================================
FILE: sandbox/modules/pytorch/landscape_generation.py
================================================
import os
import time
from warnings import warn
import matplotlib.pyplot as plt
import numpy
import traceback
from sandbox.modules.template import ModuleTemplate
from sandbox.modules import LoadSaveTopoModule
from sandbox import _test_data
import panel as pn
import platform
from sandbox import set_logger
logger = set_logger(__name__)
_platform = platform.system()

try:
    import torch
except ImportError as e:
    logger.error(e, exc_info=True)


class LandscapeGeneration(ModuleTemplate):
    """Class to generate landscapes using DEMs from the sandbox and a pre-trained model with the
    pytorch-CycleGAN-and-pix2pix library"""

    def __init__(self, extent: list = None, package_dir: str = None):
        self.depth_image = None
        self.LoadArea = LoadSaveTopoModule(extent=extent)
        self.show_landscape = False
        self.img = None
        self.DEM = None
        self._img = None
        self.lock = None
        self.last_modified = None
        self.package_dir = package_dir
        self.live_update = True
        # DEM = self.get_image_modify()
        # fig = self.save_image(DEM)
        # self.run_cmd(self.package_dir)
        self.name_trained_models = self._search_all_possible_models()
        if len(self.name_trained_models) == 0:
            logger.warning("No trained models found. "
                           "Please upload a model in the predefined folder and load the module again")
            self.name_model = "None"
        else:
            self.name_model = self.name_trained_models[0]
        # assert len(self.name_trained_models) > 0
        logger.info("LandscapeGeneration loaded successfully")

    def update(self, sb_params: dict):
        sb_params = self.LoadArea.update(sb_params)
        ax = sb_params.get('ax')
        self.lock = sb_params.get('lock_thread')
        change = sb_params.get('same_frame')
        # TODO: Include live update of the image
        # if not change and self.live_update:
        #    self.update_model()
        self.plot(ax)

        return sb_params

    def plot(self, ax):
        self.remove_image()
        if self.show_landscape:
            self.image_landscape(ax)

    def update_model(self):
        result_file = _test_data[
                          'landscape_generation'] + 'results\\train_1k\\test_latest\\images\\landscape_image_fake_B.png'
        DEM = self.get_image_modify()
        fig = self.save_image(DEM)
        self.run_cmd(self.package_dir)
        if self.last_modified is None:
            self.read_result()
        if self.last_modified != time.ctime(os.path.getmtime(result_file)):
            self.read_result()
        self.last_modified = time.ctime(os.path.getmtime(result_file))

        logger.info("model updated")

    def set_package_dir(self, package_dir):
        self.package_dir = package_dir

    def remove_image(self):
        """For each frame we need to clear the loaded image so if we change position size or the image
        itself then it will display the most actual one without occupying memory """
        if self._img is not None:
            self._img.remove()
            self._img = None

    def get_image_modify(self):
        """From the LoadSaveTopoModule acquire the dem. If a frame have not been yet loaded then capture a new frame.
        at today 27/08/2020 the image must be doubled for the method to work"""
        if self.LoadArea.absolute_topo is None:
            self.DEM, _ = self.LoadArea.extractTopo()
        else:
            self.DEM = self.LoadArea.absolute_topo
        imd_d = numpy.copy(self.DEM)
        DEM = numpy.c_[self.DEM, imd_d]
        return DEM

    def save_image(self, image: numpy.ndarray = None,
                   name: str = 'landscape_image.png',
                   pathname: str = _test_data['landscape_generation'] + 'saved_DEMs/test/'):
        """
        Takes the image and saves it as a .png 'image' in the 'patchname' folder with 'name' as name
        Args:
            image: Takes a numpy array to be saved as an image. If none then it gets a new image from
            self.get_image_modify
            name: name of the image. Must include the .png extension
            pathname: location of the image to be saved

        Returns:
            the figure that will be saved
        """
        if image is None:
            image = self.get_image_modify()
        self.lock.acquire()
        fig, ax = plt.subplots()

        ax.imshow(image, cmap='gist_earth', origin="lower")
        ax.set_axis_off()
        fig.savefig(pathname + name, bbox_inches='tight', pad_inches=0)
        plt.close()
        logger.info("saved succesfully in: " + pathname)
        self.lock.release()
        return fig

    def run_cmd(self,
                package_dir: str = None,
                dataroot_dir: str = _test_data['landscape_generation'] + 'saved_DEMs/',
                checkpoints_dir: str = _test_data['landscape_generation'] + 'checkpoints/',
                results_dir: str = _test_data['landscape_generation'] + 'results/',
                name_model: str = None,
                cmd_string=None,
                name_environment="sandbox-gempy"):
        """
        Construct the string that will be run in the command line command.
        Args:
            package_dir: The location of the pytorch-CycleGAN-and-pix2pix folder
            dataroot_dir: The location of the image
            checkpoints_dir: The location of the trained model
            results_dir: The location where the results will be saved
            name_model: Name of the trained model to be used
            cmd_string: If not None then it will run this string instead of the previous arguments
            name_environment: name of the conda environment to properly run the cmd
        Returns:

        """
        if package_dir is None:
            package_dir = self.package_dir
        if name_model is None:
            name_model = self.name_model
        to_string = 'python' + ' ' + os.path.abspath(package_dir) + '/test.py' + ' ' + \
                    '--dataroot' + ' ' + os.path.abspath(dataroot_dir) + ' ' + \
                    '--results_dir' + ' ' + os.path.abspath(results_dir) + ' ' + \
                    '--checkpoints_dir' + ' ' + os.path.abspath(checkpoints_dir) + ' ' + \
                    '--name' + ' ' + name_model + ' ' + \
                    '--model pix2pix --gpu_ids -1 --direction AtoB'

        if _platform == 'Windows':
            os.popen('call activate ' + name_environment).read()
        elif _platform == 'Linux':  # TODO: Not working for linux
            os.popen('source activate ' + name_environment).read()
        if cmd_string is None:
            os.popen(to_string).read()
        else:
            os.popen(cmd_string).read()
        logger.info('Landscape generated')
        return to_string

    def read_result(self, name: str = 'landscape_image.png',
                    result_dir: str = _test_data['landscape_generation'] + 'results'):
        """
        Read the result image from the self.run_cmd(*args) function. It reads the results from the
        'result_dir' that have name 'name'. Be sure to include the .png extension
        Args:
            name: name of image input (.png)
            result_dir: folder of results

        Returns:
        """
        result_dir = os.path.abspath(result_dir + os.sep + self.name_model + os.sep + 'test_latest' + os.sep + 'images')
        if os.path.isdir(result_dir):
            try:
                file = os.path.abspath(result_dir) + os.sep + name[:-4] + "_fake_B.png"
                self.img = plt.imread(file)
                if self.last_modified is None:
                    self.last_modified = time.ctime(os.path.getmtime(file))
                logger.info('Image loaded succesfully')
            except Exception as ex:
                logger.error(ex, exc_info=True)
        else:
            logger.warning("No image found in %s" % result_dir)

    def image_landscape(self, ax):
        """
        Show the loaded image in the sandbox
        Args:
            ax: axes of the sandbox

        Returns:

        """

        if self.DEM is not None:
            if self._img is None:
                self._img = ax.imshow(self.img, aspect='auto',
                                      extent=self.LoadArea.to_box_extent)
            else:
                self._img.set_data(self.img)
        else:
            logger.warning("No DEM image to show")

    def _search_all_possible_models(self):
        self.name_trained_models = os.listdir(_test_data["landscape_generation"] + "checkpoints")
        # self.name_trained_models.remove(".txt")
        return self.name_trained_models

    def show_widgets(self):
        self._create_widgets()
        panel = pn.Column("### Follow the following steps to use the module:",
                          "<b> 1) Select model to use for landscape generation </b>",
                          self._widget_name_trained_models,
                          "<b> 2) Acquire current frame </b>",
                          self.LoadArea._widget_snapshot,
                          "<b> 3) Save the frame previously acquired </b>",
                          self._widget_save_current_frame,
                          "<b> 4) run cmd ",
                          self._widget_run_cmd,
                          "<b> 5) Display the generated landscape in the sandbox",
                          self._widget_read_image,
                          self._widget_show_landscape
                          )
        tabs = pn.Tabs(("Landscape", panel),
                       ("LoadSaveTopo", self.LoadArea.show_widgets()))
        return tabs

    def _create_widgets(self):
        self._widget_name_trained_models = pn.widgets.RadioBoxGroup(name='Available Trained models',
                                                                    options=self.name_trained_models,
                                                                    value=self.name_model,
                                                                    inline=False)
        self._widget_name_trained_models.param.watch(self._callback_choose_trained_model, 'value',
                                                     onlychanged=False)

        self._widget_save_current_frame = pn.widgets.Button(name='Save frame', button_type="success")
        self._widget_save_current_frame.param.watch(self._callback_save_frame, 'clicks', onlychanged=False)

        self._widget_run_cmd = pn.widgets.Button(name='Run command line', button_type="success")
        self._widget_run_cmd.param.watch(self._callback_run_cmd, 'clicks', onlychanged=False)

        self._widget_read_image = pn.widgets.Button(name='Read landscape', button_type="success")
        self._widget_read_image.param.watch(self._callback_read_image, 'clicks', onlychanged=False)

        self._widget_show_landscape = pn.widgets.Checkbox(name='Show landscape', value=self.show_landscape)
        self._widget_show_landscape.param.watch(self._callback_show_landscape, 'value',
                                                onlychanged=False)

    def _callback_choose_trained_model(self, event):
        self.name_model = event.new

    def _callback_save_frame(self, event):
        _ = self.save_image()

    def _callback_run_cmd(self, event):
        _ = self.run_cmd()

    def _callback_read_image(self, event):
        plt.pause(0.1)
        self.read_result()

    def _callback_show_landscape(self, event):
        self.show_landscape = event.new



================================================
FILE: sandbox/projector/__init__.py
================================================
from .projector import Projector
from .contourlines import ContourLinesModule
from .cmap import CmapModule

if __name__ == '__main__':
    pass



================================================
FILE: sandbox/projector/cmap.py
================================================
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import copy
import panel as pn
import weakref
from sandbox.projector.shading import LightSource
from sandbox import set_logger
logger = set_logger(__name__)
pn.extension()


class CmapModule:
    """
    Class to manage changes in the colormap and plot in the desired projector figure
    """
    def __init__(self, cmap='gist_earth', norm=None, vmin=None, vmax=None, extent=None):
        """
        Initialize the colormap to plot using imshow()
        Args:
            cmap (str or plt.Colormap): Matplotlib colormap, given as name or instance.
            norm: Apply norm to imshow
            vmin (float): ...
            vmax (float): ...
            extent (list): ...
        """
        # z-range handling
        self.lock = None  # For locking the multithreading while using bokeh server
        self.extent = extent[:4]
        if vmin is not None:
            self.vmin = vmin
        else:
            self.vmin = extent[4]

        if vmax is not None:
            self.vmax = vmax
        else:
            self.vmax = extent[5]

        self.cmap = plt.cm.get_cmap(cmap)
        self._cmap = None
        self.norm = norm
        self.col = None
        self._col = None  # weakreference of self.col
        self.active = True

        # Relief shading
        self.relief_shading = True
        self.light_source = LightSource()
        self._light_simulation = False

        logger.info("CmapModule loaded successfully")

    def update(self, sb_params: dict):
        active = sb_params.get('active_cmap')
        active_shade = sb_params.get('active_shading')
        ax = sb_params.get('ax')
        data = sb_params.get('frame')
        cmap = sb_params.get('cmap')
        norm = sb_params.get('norm')
        extent = sb_params.get('extent')
        self.vmin = extent[-2]
        self.vmax = extent[-1]
        set_cbar = sb_params.get("set_colorbar")
        set_cbar(self.vmin, self.vmax, cmap, norm)

        if active_shade and self.relief_shading:
            if len(data.shape) > 2:  # 3 Then is an image already
                active_shade = False
            else:
                # Note: (Not really) 180 degrees are subtracted because visualization in Sandbox is upside-down
                ls = mcolors.LightSource(azdeg=self.light_source.azimuth, altdeg=self.light_source.altitude)
                data = ls.shade(data, cmap=self.cmap, vert_exag=self.light_source.ve, blend_mode='overlay')

        if active and self.active:
            if self._col is not None and self._col() not in ax.images:
                self.col = None
            if self.col is None:
                self.render_frame(data, ax, vmin=self.vmin, vmax=self.vmax, extent=extent[:4])
            else:
                self.set_data(data)
                self.set_cmap(cmap, 'k', 'k', 'k')
                self.set_norm(norm)
                self.set_extent(extent)
                sb_params['cmap'] = self.cmap
        elif active_shade and self.relief_shading:
            cmap = plt.cm.gray
            if self._col is not None and self._col() not in ax.images:
                self.col = None
            if self.col is None:
                self.render_frame(data, ax, vmin=self.vmin, vmax=self.vmax, extent=extent[:4])
            else:
                self.set_data(data)
                self.set_cmap(cmap, 'k', 'k', 'k')
                self.set_norm(norm)
                self.set_extent(extent)
        else:
            if self.col is not None:
                self.col.remove()
                self.col = None
            if self._col is not None and self._col() in ax.images:
                ax.images.remove(self._col)

        return sb_params

    def set_extent(self, extent):
        self.col.set_extent(extent[:4])

    def set_norm(self, norm):
        # if norm is None:
        #    norm = matplotlib.colors.Normalize(vmin=None, vmax=None, clip=False)
        self.norm = norm
        if self.norm is not None:
            self.col.set_norm(norm)

    def set_cmap(self, cmap, over=None, under=None, bad=None):
        """
        Methods to mask the values outside the extent
        Args:
            cmap: (matplotlib colormap): colormap to use
            over (e.g. str): Color used for values above the expected data range.
            under (e.g. str): Color used for values below the expected data range.
            bad (e.g. str): Color used for invalid or masked data values.

        Returns:
        """
        if isinstance(cmap, str):
            cmap = plt.cm.get_cmap(cmap)
        if self._cmap is not None and self._cmap.name != cmap.name:
            cmap = self._cmap
            self._cmap = None
        cmap = copy.copy(cmap)
        if over is not None:
            cmap.set_over(over, 1.0)
        if under is not None:
            cmap.set_under(under, 1.0)
        if bad is not None:
            cmap.set_bad(bad, 1.0)
        self.cmap = cmap
        self.col.set_cmap(cmap)
        return None

    def set_data(self, data):
        """
        Change the numpy array that is being plotted without the need to errase the imshow figure
        Args:
            data:
        Returns:
        """
        self.col.set_data(data)
        self.col.set_clim(vmin=self.vmin, vmax=self.vmax)
        return None

    def render_frame(self, data, ax, vmin=None, vmax=None, extent=None):
        """Renders a new image or actualizes the current one"""
        if vmin is None:
            vmin = self.vmin
        if vmax is None:
            vmax = self.vmax

        self.col = ax.imshow(data, vmin=vmin, vmax=vmax,
                             cmap=self.cmap, norm=self.norm,
                             origin='lower', aspect='auto', zorder=-500, extent=extent)
        self._col = weakref.ref(self.col)

        ax.set_axis_off()
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
        return None

    def delete_image(self):
        """Method to remove the image from the frame"""
        self.col.remove()
        return None

    def show_widgets(self):
        self._create_widgets()
        panel = pn.Column("###<b>Colormap </b>",
                          self._widget_plot_colormap,
                          self._widget_plot_cmap,
                          self._widget_lightsource())
        return panel

    def _create_widgets(self):
        self._widget_plot_cmap = pn.widgets.Select(name='Choose a colormap',
                                                   # use the following line to enable all colormaps
                                                   # options=plt.colormaps(),
                                                   # limit to only specified color maps
                                                   options=['gist_earth', 'terrain', 'ocean', 'seismic',
                                                            'RdBu', "RdBu_r", "Greys", "Greys_r",
                                                            'viridis', 'viridis_r', 'magma', 'magma_r',
                                                            ],
                                                   value=self.cmap.name)
        self._widget_plot_cmap.param.watch(self._callback_plot_cmap, 'value', onlychanged=False)

        self._widget_plot_colormap = pn.widgets.Checkbox(name='Show colormap', value=self.active)
        self._widget_plot_colormap.param.watch(self._callback_plot_colormap, 'value',
                                               onlychanged=False)

        return True

    def _widget_lightsource(self):
        self._widget_relief_shading = pn.widgets.Checkbox(name='Show relief shading',
                                                          value=self.relief_shading)
        self._widget_relief_shading.param.watch(self._callback_relief_shading, 'value',
                                                onlychanged=False)
        self._widget_azdeg = pn.widgets.FloatSlider(name='Azimuth',
                                                    value=self.light_source.azimuth,
                                                    start=0.0,
                                                    end=360.0)
        self._widget_azdeg.param.watch(self._callback_lightsource_azdeg, 'value')

        self._widget_altdeg = pn.widgets.FloatSlider(name='Altitude',
                                                     value=self.light_source.altitude,
                                                     start=0.0,
                                                     end=90.0)
        self._widget_altdeg.param.watch(self._callback_lightsource_altdeg, 'value')

        self._widget_ve = pn.widgets.Spinner(name="Vertical Exageration", value=self.light_source.ve,
                                             step=0.01)
        self._widget_ve.param.watch(self._callback_ve, 'value', onlychanged=False)
        self._widget_manual = pn.widgets.Checkbox(name='Manual configuration',
                                                 value=self.light_source.manual)
        self._widget_manual.param.watch(self._callback_manual, 'value',
                                                onlychanged=False)

        self._widget_address = pn.widgets.TextInput(name='Enter address (e.g. City, Country)',
                                                    value=self.light_source.address)
        self._widget_address.param.watch(self._callback_address, 'value', onlychanged=False)

        self._widget_markdown_city = pn.pane.Markdown(self.light_source.full_address, sizing_mode='scale_width')
        self._widget_markdown_date = pn.pane.Markdown(self.light_source.date.ctime(), sizing_mode='scale_width')
        self._widget_sun = pn.pane.Markdown("<p>Azimuth: %.4f </p>"\
                                            "<p>Altitude: %.4f </p>" % (self.light_source.azimuth,
                                                                        self.light_source.altitude),
                                            sizing_mode='scale_width')
        self._widget_markdown_lat_long = pn.pane.Markdown("<p>Latitude: %.4f </p>"\
                                                          "<p>Longitude: %.4f </p>" % (self.light_source.latitude_deg,
                                                                                       self.light_source.longitude_deg),
                                                          sizing_mode='scale_width')

        # self._widget_date_pick = pn.widgets.DatetimeInput(name='Select date', value=self.light_source.date)
        self._widget_date_pick = pn.widgets.DatePicker(name='Select date (UTC +0)', value=self.light_source.date.date())
        self._widget_date_pick.param.watch(self._callback_date_pick, 'value', onlychanged=False)

        self._widget_hour_pick = pn.widgets.IntSlider(name="Hour", value=self.light_source.date.hour,
                                                      start=0, end=23, width_policy='min')
        self._widget_hour_pick.param.watch(self._callback_hour_pick, 'value', onlychanged=False)

        self._widget_minute_pick = pn.widgets.IntSlider(name="Minute", value=self.light_source.date.minute,
                                                        start=0, end=59, width_policy='min')
        self._widget_minute_pick.param.watch(self._callback_minute_pick, 'value', onlychanged=False)

        self._widget_second_pick = pn.widgets.IntSlider(name="Second", value=self.light_source.date.second,
                                                        start=0, end=59, width_policy='min')
        self._widget_second_pick.param.watch(self._callback_second_pick, 'value', onlychanged=False)

        self._widget_days_simulation = pn.widgets.Checkbox(name='Start day simulation increasing by hour',
                                                 value=self.light_source.simulation)
        self._widget_days_simulation.param.watch(self._callback_day_simulation, 'value',
                                                onlychanged=False)

        widgets = pn.WidgetBox(self._widget_manual,
                               self._widget_azdeg,
                               self._widget_altdeg,
                               self._widget_ve
                               )
        widgets2 = pn.WidgetBox(self._widget_address,
                                self._widget_date_pick,
                                pn.Row(self._widget_hour_pick,
                                       self._widget_minute_pick,
                                       self._widget_second_pick,
                                       width_policy='min'),
                                self._widget_markdown_date,
                                self._widget_sun,
                                self._widget_markdown_lat_long,
                                self._widget_markdown_city)

        widget3 = pn.WidgetBox(self._widget_days_simulation,
                               # self._widget_markdown_date,
                               # self._widget_sun,
                               # self._widget_markdown_lat_long,
                               )

        tab = pn.Tabs(("Manual", widgets),
                      ("Geo-location", widgets2),
                      ("Day simulation", widget3))

        panel = pn.Column("<b> Lightsource </b> ", self._widget_relief_shading, tab)
        return panel

    def _trigger_info(self):
        self.light_source.manual = False
        self._widget_manual.value = False
        self._widget_sun.object = "<p>Azimuth: %.4f </p>" \
                                  "<p>Altitude: %.4f </p>" % (self.light_source.azimuth,
                                                              self.light_source.altitude)
        self._widget_markdown_lat_long.object = "<p>Latitude: %.4f</p>" \
                                                "<p>Longitude: %.4f</p>" % (self.light_source.latitude_deg,
                                                                            self.light_source.longitude_deg)
        self._widget_markdown_date.object = self.light_source.date.ctime()
        self._widget_markdown_city.object = self.light_source.full_address

    def _callback_day_simulation(self, event):
        self.light_source.simulation = event.new
        self._light_simulation = event.new

    def _callback_hour_pick(self, event):
        self.light_source.date = self.light_source.date.replace(hour=event.new)
        self._trigger_info()

    def _callback_minute_pick(self, event):
        self.light_source.date = self.light_source.date.replace(minute=event.new)
        self._trigger_info()

    def _callback_second_pick(self, event):
        self.light_source.date = self.light_source.date.replace(second=event.new)
        self._trigger_info()

    def _callback_date_pick(self, event):
        self.light_source.set_datetime(date=event.new)
        self._trigger_info()

    def _callback_address(self, event):
        self.light_source.set_address(event.new)
        self.light_source.set_latitude_longitude()
        self._trigger_info()


    def _callback_manual(self, event): self.light_source.manual = event.new

    def _callback_plot_colormap(self, event): self.active = event.new

    def _callback_plot_cmap(self, event): self._cmap = plt.cm.get_cmap(event.new)

    def _callback_relief_shading(self, event): self.relief_shading = event.new

    def _callback_ve(self, event): self.light_source.set_ve(event.new)

    def _callback_lightsource_altdeg(self, event): self.light_source.set_altitude(event.new)

    def _callback_lightsource_azdeg(self, event): self.light_source.set_azimuth(event.new)



================================================
FILE: sandbox/projector/contourlines.py
================================================
import numpy
import matplotlib
import panel as pn
from sandbox import set_logger
logger = set_logger(__name__)
pn.extension()


class ContourLinesModule:
    dpi = 100  # make sure that figures can be displayed pixel-precise

    def __init__(self, contours=True, contours_step=100,
                 contours_width=1.0, contours_color='k', contours_label=True,
                 contours_label_inline=True, contours_label_fontsize=15,
                 contours_label_format='%3.0f', minor_contours=True,
                 contours_step_minor=50, contours_width_minor=0.5,
                 extent=None, check_change=True, rtol=0.2, atol=0,
                 automatic_levels=False, threshold=200):
        """
            Module for the display and manipulation of contourlines

            Args:
                contours (bool): Flag that enables or disables contours plotting.
                    (default is True)
                contours_step (int): Size of step between contour lines in model units.
                    (default is 100)
                contours_width (float): Width of contour lines.
                    (default is 1.0)
                contours_color (e.g. str): Color of contour lines.
                    (default is 'k')
                contours_label (bool): Flag that enables labels on contour lines.
                    (default is False)
                contours_label_inline (bool): Partly replace underlying contour line or not.
                    (default is True)
                contours_label_fontsize (float or str): Size in points or relative size of contour label.
                    (default is 15)
                contours_label_format (string or dict): Format string for the contour label.
                    (default is %3.0f)
                minor_contours (bool): Flag that enables or disables minor contours plotting.
                    (default is True)
                contours_step_minor (int): Size of step between minor contour lines in model units.
                    (default is 50)
                contours_width_minor (float): Width of minor contour lines.
                    (default is 0.5)
                extent (list): extents of the sandbox to indicate the physical dimensions of it
                check_change (bool): Update the contour ines only when the frame changes
                rtol (float): relative tolerance for checking the change
                atol (float): absolute tolerance for checking the change
                automatic_levels (bool): When changing modules, the extent and data may change, therefore the levels
                    will not remain constant. A quick fix is to set the default levels of matplotlib and let it choose
                    automatically.
                threshold (int): Maximum amount of contour lines per plot. If more then set levels to automatic.
            """
        self.lock = None  # For locking the multithreading while using bokeh server
        self._active = False
        self.active_contours = True
        self.major = None
        self.minor = None
        self.label = None
        self.check_change = check_change
        self._rtol = rtol
        self._atol = atol
        self._threshold = threshold
        self.extent = extent
        self.vmin = self.extent[4]
        self.vmax = self.extent[5]
        self.previous_frame = None

        # flags
        self.contours = contours
        self.minor_contours = minor_contours
        self.automatic_contours = automatic_levels

        # contours setup
        self.contours_step = contours_step  # levels will be supplied via property function
        self.contours_width = contours_width
        self.contours_color = contours_color
        self.contours_label = contours_label
        self.contours_label_inline = contours_label_inline
        self.contours_label_fontsize = contours_label_fontsize
        self.contours_label_format = contours_label_format

        self.contours_step_minor = contours_step_minor
        self.contours_width_minor = contours_width_minor
        logger.info("ContourLinesModule loaded successfully")

    def update(self, sb_params: dict):
        active = sb_params.get('active_contours')
        active = bool(active * self.active_contours)
        ax = sb_params.get('ax')
        frame = sb_params.get('frame')
        if len(frame.shape) > 2:  # 3 Then is an image
            active = False

        if active:
            self._active = active

            if self.previous_frame is None:
                self.previous_frame = frame

            same_frame = sb_params['same_frame']
            if same_frame:
                frame = self.previous_frame
            else:
                self.previous_frame = frame

            extent = sb_params.get('extent')
            self.vmin = extent[-2]
            self.vmax = extent[-1]
            del_contour = sb_params.get('del_contour')  # making this we can now manage when to delete the contour lines
            # At any part of the thread. Used in GempyModule
            if del_contour:
                self.delete_contourns(ax)

            if self.contours:
                self.add_major_contours(frame, ax, extent[:4])
            if self.minor_contours:
                self.add_minor_contours(frame, ax, extent[:4])
            if self.contours_label and self.contours:
                self.add_label_contours(ax)
        else:
            if self._active:
                self.delete_contourns(ax)
            self._active = active

        return sb_params

    @staticmethod
    def delete_contourns(ax):
        [coll.remove() for coll in reversed(ax.collections) if isinstance(coll, matplotlib.collections.PathCollection)]
        [text.remove() for text in reversed(ax.texts) if isinstance(text, matplotlib.text.Text)]

    def plot_contour_lines(self, frame, ax):
        self.add_major_contours(frame, ax)
        self.add_minor_contours(frame, ax)
        self.add_label_contours(ax)

    def add_major_contours(self, data, ax, extent=None):
        """Renders contours to the current plot object.
        Uses the different attributes to style contour lines and contour labels.
        """
        self.major = ax.contour(data,
                                levels=self.contours_levels
                                if len(self.contours_levels) < self._threshold
                                and not self.automatic_contours else None,
                                linewidths=self.contours_width,
                                colors=self.contours_color,
                                extent=extent,
                                zorder=100
                                )

    def add_minor_contours(self, data, ax, extent=None):
        if len(self.contours_levels_minor) < self._threshold and not self.automatic_contours:
            self.minor = ax.contour(data,
                                    levels=self.contours_levels_minor,
                                    linewidths=self.contours_width_minor,
                                    colors=self.contours_color,
                                    extent=extent,
                                    zorder=99
                                    )

    def add_label_contours(self, ax):
        self.label = ax.clabel(self.major,
                               inline=self.contours_label_inline,
                               fontsize=self.contours_label_fontsize,
                               fmt=self.contours_label_format)

    @property
    def contours_levels(self):
        """Returns the current contour levels, being aware of changes in calibration."""

        return numpy.arange(self.vmin, self.vmax, self.contours_step)

    @property
    def contours_levels_minor(self):
        """Returns the current contour levels, being aware of changes in calibration."""

        return numpy.arange(self.vmin, self.vmax, self.contours_step_minor)

    def show_widgets(self):
        self._create_widgets()
        panel = pn.Column("###<b>Contour lines </b>",
                          self._widget_active_contours,
                          self._widget_automatic_contours,
                          "<b> Modify contour lines manually </b>",
                          pn.WidgetBox(self._widget_plot_contours,
                                       self._widget_plot_step_contours,
                                       self._widget_plot_minorcontours,
                                       self._widget_plot_step_minorcontours,
                                       self._widget_plot_contours_label,
                                       self._widget_plot_contours_label_fontsize
                                       )
                          )

        return panel

    def _create_widgets(self):
        self._widget_active_contours = pn.widgets.Checkbox(name='Active contours', value=self.active_contours)
        self._widget_active_contours.param.watch(self._callback_active_contours, 'value', onlychanged=False)

        self._widget_automatic_contours = pn.widgets.Checkbox(name='Automatic levels for contours',
                                                              value=self.automatic_contours)
        self._widget_automatic_contours.param.watch(self._callback_automatic_contours, 'value', onlychanged=False)

        self._widget_plot_contours = pn.widgets.Checkbox(name='Show major contours', value=self.contours)
        self._widget_plot_contours.param.watch(self._callback_plot_contours, 'value',
                                               onlychanged=False)

        self._widget_plot_minorcontours = pn.widgets.Checkbox(name='Show minor contours', value=self.minor_contours)
        self._widget_plot_minorcontours.param.watch(self._callback_plot_minorcontours, 'value',
                                                    onlychanged=False)
        self._widget_plot_step_contours = pn.widgets.Spinner(name='Choose a contour step', value=self.contours_step)
        self._widget_plot_step_contours.param.watch(self._callback_plot_step_contours, 'value', onlychanged=False)

        self._widget_plot_step_minorcontours = pn.widgets.Spinner(name='Choose a minor contour step',
                                                                  value=self.contours_step_minor)
        self._widget_plot_step_minorcontours.param.watch(self._callback_plot_step_minorcontours, 'value',
                                                         onlychanged=False)

        self._widget_plot_contours_label = pn.widgets.Checkbox(name='Show contours label',
                                                               value=self.contours_label)
        self._widget_plot_contours_label.param.watch(self._callback_plot_contours_label, 'value',
                                                     onlychanged=False)

        self._widget_plot_contours_label_fontsize = pn.widgets.Spinner(name='set a contour label fontsize',
                                                                       value=self.contours_label_fontsize)
        self._widget_plot_contours_label_fontsize.param.watch(self._callback_plot_contours_label_fontsize, 'value',
                                                              onlychanged=False)

    def _callback_automatic_contours(self, event):
        self.automatic_contours = event.new

    def _callback_active_contours(self, event):
        self.active_contours = event.new

    def _callback_plot_contours(self, event):
        self.contours = event.new

    def _callback_plot_minorcontours(self, event):
        self.minor_contours = event.new

    def _callback_plot_step_contours(self, event):
        self.contours_step = event.new

    def _callback_plot_step_minorcontours(self, event):
        self.contours_step_minor = event.new

    def _callback_plot_contours_label(self, event):
        self.contours_label = event.new

    def _callback_plot_contours_label_fontsize(self, event):
        self.contours_label_fontsize = event.new



================================================
FILE: sandbox/projector/projector.py
================================================
import os
import panel as pn
import matplotlib
from matplotlib.figure import Figure
from matplotlib.axes import Axes
import matplotlib.pyplot as plt
import json
from sandbox import _calibration_dir, set_logger
logger = set_logger(__name__)


class Projector(object):
    dpi = 100  # make sure that figures can be displayed pixel-precise

    css = '''
    body {
      margin:0px;
      background-color: #FFFFFF;
    }
    .panel {
      background-color: #000000;
      overflow: hidden;
    }
    .bk.frame {
      background-color: #FFFFFF;
      color: #FFFFFF;
    }
    .bk.legend {
      background-color: #16425B;
      color: #CCCCCC;
    }
    .bk.hot {
      background-color: #2896A5;
      color: #CCCCCC;
    }
    .bk.profile {
      background-color: #40C1C7;
      color: #CCCCCC;
    }
    .bk.colorbar {
      background-color: #2896A5;
      color: #CCCCCC;
    '''

    def __init__(self, calibprojector: str = None, use_panel: bool = True, p_width=1280, p_height=800,
                 show_colorbar: bool = False, position_colorbar: str = "vertical",
                 show_legend: bool = False, show_hot: bool = False,
                 show_profile: bool = False, ):
        """
        Args:
            calibprojector:
            use_panel: Automatically display
            p_width: x native resolution of the projector
            p_height: y native resolution of the projector
            show_colorbar:
            position_colorbar: "vertical" or "horizontal"
            show_legend:
            show_hot:
            show_profile
        """
        self.version = '2.2.p'
        self.ax = None
        self.figure = None
        self.json_filename = calibprojector

        # flags
        self.enable_legend = show_legend
        self.enable_hot = show_hot
        self.enable_colorbar = show_colorbar
        self.pos_colorbar = position_colorbar
        self._ratio = 10
        self.enable_profile = show_profile

        if calibprojector is None:
            self.p_width = p_width
            self.p_height = p_height
            self.p_frame_top = 50
            self.p_frame_left = 50
            self.p_frame_width = 700
            self.p_frame_height = 500
            # Colorbar
            self.col_top = 0
            self.col_left = 0 if self.pos_colorbar == "vertical" else self.p_frame_left
            self.col_width = self.p_frame_width if self.pos_colorbar == "horizontal" \
                                           else round(self.p_frame_width / self._ratio)
            self.col_height = self.p_frame_height if self.pos_colorbar == "vertical" \
                                           else round(self.p_frame_height / self._ratio)

            self.leg_width = round(self.p_frame_width/4)
            self.leg_height = round(self.p_frame_width/3)
            self.leg_top = 0
            self.leg_left = 0
        else:
            self.load_json(calibprojector)

        self._size_label_cbar = 15
        self._label = None

        # panel components (panes)
        self.panel = None
        self.frame = None
        self.legend = None
        self.hot = None
        self.profile = None
        self.colorbar = None
        self.sidebar = None
        # This is to solve issue #3. Give 0.01 ms to each Text from ax.arists to be plotted
        self._target_time = 0.00
        self._paused_time = None

        self.create_panel()
        if use_panel is True:
            self.start_server()

    @property
    def _dim_label_ax(self):
        return [0, 0, 2, 0.1] if self.pos_colorbar == "horizontal" else [0, 0, 0.1, 2]

    def create_panel(self):
        """ Initializes the matplotlib figure and empty axes according to projector calibration.

        The figure can be accessed by its attribute. It will be 'deactivated' to prevent random apperance in notebooks.
        """
        pn.extension(raw_css=[self.css])
        # Create a panel object and serve it within an external bokeh browser that will be opened in a separate window

        # In this special case, a "tight" layout would actually add again white space to the plt canvas,
        # which was already cropped by specifying limits to the axis

        self.figure = Figure(figsize=(self.p_frame_width / self.dpi, self.p_frame_height / self.dpi),
                             dpi=self.dpi)
        self.ax = Axes(self.figure, [0., 0., 1., 1.])
        self.figure.add_axes(self.ax)
        self.ax.set_axis_off()
        self.ax.get_xaxis().set_visible(False)
        self.ax.get_yaxis().set_visible(False)

        self.frame = pn.pane.Matplotlib(self.figure,
                                        width=self.p_frame_width,
                                        height=self.p_frame_height,
                                        margin=(self.p_frame_top, 0, 0, self.p_frame_left),
                                        tight=False,
                                        dpi=self.dpi,
                                        css_classes=['frame']
                                        )
        plt.close(self.figure)  # close figure to prevent inline display

        if self.enable_colorbar:
            self.create_colorbar()

        if self.enable_legend:
            self.create_legend()

        if self.enable_hot:
            self.create_hot()

        if self.enable_profile:
            self.create_profile()

        # Combine panel and deploy bokeh server
        if self.pos_colorbar == "vertical":
            self.sidebar = pn.Column(self.colorbar, self.legend, self.hot, self.profile,
                                     margin=(self.p_frame_top, 0, 0, 0),
                                     )

            self.panel = pn.Row(pn.Column(self.frame, None),
                                self.sidebar,
                                width=self.p_width,
                                height=self.p_height,
                                sizing_mode='fixed',
                                css_classes=['panel']
                                )
        elif self.pos_colorbar == "horizontal":
            self.sidebar = pn.Column(self.legend, self.hot, self.profile,
                                     margin=(self.p_frame_top, 0, 0, 0),
                                     )
            self.panel = pn.Row(pn.Column(self.frame, self.colorbar),
                                self.sidebar,
                                width=self.p_width,
                                height=self.p_height,
                                sizing_mode='fixed',
                                css_classes=['panel']
                                )
        else:
            raise AttributeError

        return True

    def create_colorbar(self):
        empty_fig_bg_cb = Figure()
        self.colorbar = pn.pane.Matplotlib(empty_fig_bg_cb,
                                           width= self.col_width,
                                           height= self.col_height,
                                           margin=(self.col_top, 0, 0, self.col_left),
                                           dpi=self.dpi*2,
                                           css_classes=['colorbar'],
                                           tight=True)

    def create_legend(self):
        empty_fig_bg_ld = Figure()
        self.legend = pn.pane.Matplotlib(empty_fig_bg_ld,
                                           width=self.leg_width,
                                           height=self.leg_height,
                                           margin=(self.leg_top, 0, 0, self.leg_left),
                                           dpi=self.dpi*2,
                                           css_classes=['legend'],
                                           tight=True)

    def create_hot(self):
        self.hot = pn.Column("### Hot area",
                             width=100,
                             height=100,
                             margin=(0, 0, 0, 0),
                             css_classes=['hot']
                             )

    def create_profile(self):
        self.profile = pn.Column("### Profile",
                                 width=100,
                                 height=100,
                                 margin=(0, 0, 0, 0),
                                 css_classes=['profile']
                                 )

    def set_colorbar(self, vmin: float, vmax: float, cmap="viridis", norm=None, label: str = None):
        """
        Create a colorbar and display the figure in the colorbar widget
        Args:
            vmin: Minimun value of the colorbar
            vmax: Maximum value of the colorbar
            cmap: Colormap of the colorbar
            norm: (optionl) Normalization, in case that not, this is internally managed
            label: Text to display as label in the colorbar
        Returns:

        """
        if self.colorbar is not None:
            if isinstance(cmap, str):
                cmap = plt.get_cmap(cmap)
            label = label if label is not None else self._label
            cb = Figure()
            ax = Axes(cb, self._dim_label_ax)
            cb.add_axes(ax)
            norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax) if norm is None else norm
            cb1 = matplotlib.colorbar.ColorbarBase(ax, cmap=cmap, norm=norm, orientation=self.pos_colorbar)
            cb1.set_label(label, size=self._size_label_cbar) if label is not None else None
            cb1.ax.tick_params(labelsize=self._size_label_cbar)
            self.colorbar.object = cb
            self.colorbar.param.trigger("object")

    def set_legend(self, handles=None, labels=None, *args):
        """
        Create a legend with the information of frame with the ax.get_legend_handles_labels().
        External handles and labels can be used
        Returns:

        """
        if self.legend is not None:
            ld = Figure()
            if handles is None and labels is None:
                if args == ():
                    ld.legend(*self.ax.get_legend_handles_labels())
                else:
                    ld.legend(*args)
            else:
                ld.legend(labels=labels,
                          handles=handles
                          )
            self.legend.object = ld
            self.legend.param.trigger("object")


    def write_text(self, text: str = "cgre-aachen / open_AR_Sandbox"):
        """
        Display a custom text to be displayed in the middle of the sandbox
        Args:
            text: message to display
        Returns:

        """
        self.ax.texts = []
        x = (self.ax.get_xlim()[1] - self.ax.get_xlim()[0])/2
        y = (self.ax.get_ylim()[1] - self.ax.get_ylim()[0])/2
        self.ax.annotate(text, (x, y), zorder=1000000, xycoords="data", fontsize=18, ha='center',
                         va='top', wrap=True)
        self.trigger()

    def _replace_figure_with_pyplot(self):
        """Deprecated!! workaround to fix bug of no dpi"""
        figure = plt.figure(figsize=(self.p_frame_width / self.dpi, self.p_frame_height / self.dpi),
                            dpi=self.dpi)
        ax = plt.Axes(figure, [0., 0., 1., 1.])
        figure.add_axes(ax)
        plt.close(figure)  # close figure to prevent inline display
        ax.set_axis_off()
        self.figure = figure
        self.ax = ax
        self.frame.object = figure
        self.trigger()

    def start_server(self):
        """
        Display the panel object in a new browser window
        Returns:

        """
        # Check for instances and close them?
        self.panel.show(threaded=False)  # , title="Sandbox frame!")#, port = 4242, use_reloader = False)
        # TODO: check how can check if the port exist/open and overwrite it
        logger.info('Projector initialized and server started.\n'
              'Please position the browser window accordingly and enter fullscreen!')
        return True

    def clear_axes(self):
        """
        Empty the axes of the current figure and trigger the update of the figure in the panel.
        Returns:

        """
        self.ax.cla()
        self.trigger()
        return True

    def _clock(self):
        """
        To to be sure that panel have enough time to display the figure he want. Solves issue #3
        """
        ctext = [isinstance(text, matplotlib.text.Text) for text in self.ax.texts]
        coll = [isinstance(coll, matplotlib.collections.PathCollection) for coll in self.ax.collections]
        if True in ctext or True in coll:
            sec = (len(coll)+len(ctext))*self._target_time  # Give 0.005 ms to each Text from contours to be plotted
            self._paused_time = sec
            plt.pause(sec)
        else:
            self._paused_time = None

    def trigger(self):
        """
        Update the panel figure if modified 
        Returns:

        """

        # self.figure.canvas.draw_idle()  # TODO: do we need this or not?
        self.frame.param.trigger('object')
        self._clock()
        return True

    def save_json(self, file: str = 'projector_calibration.json'):
        """
        Saves the current state of the projector in a .JSON calibration file
        Args:
            file: address to save the calibration

        Returns:

        """
        with open(file, "w") as calibration_json:
            data = {'version': self.version,
                    'p_width': self.p_width,
                    'p_height': self.p_height,
                    'p_frame_top': self.p_frame_top,
                    'p_frame_left': self.p_frame_left,
                    'p_frame_width': self.p_frame_width,
                    'p_frame_height': self.p_frame_height,
                    'col_top': self.col_top,
                    'col_left': self.col_left,
                    'col_width': self.col_width,
                    'col_height': self.col_height,
                    'pos_colorbar': self.pos_colorbar,
                    'leg_top': self.leg_top,
                    'leg_left': self.leg_left,
                    'leg_width': self.leg_width,
                    'leg_height': self.leg_height,
                    }
            json.dump(data, calibration_json)
        logger.info('JSON configuration file saved: %s' % str(file))
        return True

    def load_json(self, file: str):
        """
        Load a calibration file (.JSON format) and actualizes the panel parameters
        Args:
            file: address of the calibration to load

        Returns:

        """
        def json_load(dict_data):
            if dict_data['version'] == self.version:
                self.p_width = dict_data.get('p_width')
                self.p_height = dict_data.get('p_height')
                self.p_frame_top = dict_data.get('p_frame_top')
                self.p_frame_left = dict_data.get('p_frame_left')
                self.p_frame_width = dict_data.get('p_frame_width')
                self.p_frame_height = dict_data.get('p_frame_height')
                self.col_top = dict_data.get('col_top')
                self.col_left = dict_data.get('col_left')
                self.col_width = dict_data.get('col_width')
                self.col_height = dict_data.get('col_height')
                self.pos_colorbar = dict_data.get('pos_colorbar')
                self.leg_top = dict_data.get('leg_top')
                self.leg_left = dict_data.get('leg_left')
                self.leg_width = dict_data.get('leg_width')
                self.leg_height =dict_data.get('leg_height')

                logger.info("JSON configuration loaded for projector")
            else:
                logger.warning("JSON configuration incompatible." +
                      "\nPlease select a valid calibration file or start a new calibration!")
        if os.path.isfile(file):
            with open(file) as calibration_json:
                data = json.load(calibration_json)
                json_load(data)
        else:
            data = json.loads(file)
            json_load(data)
        return True

    def calibrate_projector(self):
        self._create_widgets()
        panel = pn.Column("### Projector dashboard arrangement",
                          self._widget_p_frame_top,
                          self._widget_p_frame_left,
                          self._widget_p_frame_width,
                          self._widget_p_frame_height,
                          '<b>Save file<b>',
                          self._widget_json_filename,
                          self._widget_json_save
                          )
        return panel

    def show_widgets_sidepanels(self):
        tabs = pn.Tabs(("Colorbar", self.show_widget_colorbar()),
                       ("Legend", self.show_widget_legend()))
        return tabs

    def show_widget_colorbar(self):
        self._create_widgets_colorbar()
        panel1 = pn.Column("### Colorbar",
                           self._widgets_show_colorbar,
                           self._widget_label,
                           self._widget_refresh_col
                          )
        panel2 = pn.Column(self._widget_colorbar_ori,
                           self._widget_top_colorbar,
                           self._widget_left_colorbar,
                           self._widget_width_colorbar,
                           self._widget_height_colorbar,
                           self._widget_col_background)
        return pn.Row(panel1, panel2)

    def show_widget_legend(self):
        self._create_widgets_legend()
        panel3 = pn.Column("### Legend",
                           self._widgets_show_legend,
                           self._widget_refresh_leg)
        panel4 = pn.Column(self._widget_top_legend,
                           self._widget_left_legend,
                           self._widget_width_legend,
                           self._widget_height_legend,
                           self._widget_leg_background)
        return pn.Row(panel3, panel4)

    def _create_widgets(self):
        # projector widgets and links
        self._widget_p_frame_top = pn.widgets.IntSlider(name='Main frame top margin',
                                                        value=self.p_frame_top,
                                                        start=0,
                                                        end=self.p_height - 20)
        self._widget_p_frame_top.link(self.frame, callbacks={'value': self._callback_p_frame_top})

        self._widget_p_frame_left = pn.widgets.IntSlider(name='Main frame left margin',
                                                         value=self.p_frame_left,
                                                         start=0,
                                                         end=self.p_width - 20)
        self._widget_p_frame_left.link(self.frame, callbacks={'value': self._callback_p_frame_left})

        self._widget_p_frame_width = pn.widgets.IntSlider(name='Main frame width',
                                                          value=self.p_frame_width,
                                                          start=10,
                                                          end=self.p_width)
        self._widget_p_frame_width.link(self.frame, callbacks={'value': self._callback_p_frame_width})

        self._widget_p_frame_height = pn.widgets.IntSlider(name='Main frame height',
                                                           value=self.p_frame_height,
                                                           start=10,
                                                           end=self.p_height)
        self._widget_p_frame_height.link(self.frame, callbacks={'value': self._callback_p_frame_height})

        self._widget_json_filename = pn.widgets.TextInput(name='Choose a calibration filename:')
        self._widget_json_filename.param.watch(self._callback_json_filename, 'value', onlychanged=False)
        self._widget_json_filename.value = _calibration_dir + 'my_projector_calibration.json'

        self._widget_json_save = pn.widgets.Button(name='Save calibration')
        self._widget_json_save.param.watch(self._callback_json_save, 'clicks', onlychanged=False)

        return True

    def _create_widgets_colorbar(self):
        self._widget_colorbar_ori = pn.widgets.Select(name='Orientation Colorbar',
                                                    options=["vertical", "horizontal"],
                                                   value=self.pos_colorbar)
        self._widget_colorbar_ori.param.watch(self._callback_colorbar_ori, 'value', onlychanged=False)

        self._widgets_show_colorbar = pn.widgets.Checkbox(name='Show colorbar',
                                                          value=self.enable_colorbar)
        self._widgets_show_colorbar.param.watch(self._callback_enable_colorbar, 'value',
                                                onlychanged=False)

        self._widget_top_colorbar = pn.widgets.IntSlider(name='Top space',
                                                        value=self.col_top,
                                                        start=0,
                                                        end=self.p_height - 20)
        self._widget_top_colorbar.param.watch(self._callback_top_colorbar, 'value', onlychanged=False)

        self._widget_left_colorbar = pn.widgets.IntSlider(name='Left space',
                                                         value=self.col_left,
                                                         start=0,
                                                         end=self.p_width - 20)
        self._widget_left_colorbar.param.watch(self._callback_left_colorbar, 'value', onlychanged=False)

        self._widget_width_colorbar = pn.widgets.IntSlider(name='Width Colorbar',
                                                          value=self.col_width,
                                                          start=1,
                                                          end=self.p_width)
        self._widget_width_colorbar.param.watch(self._callback_width_colorbar, 'value', onlychanged=False)

        self._widget_height_colorbar = pn.widgets.IntSlider(name='Height colorbar',
                                                           value=self.col_height,
                                                           start=1,
                                                           end=self.p_height)
        self._widget_height_colorbar.param.watch(self._callback_height_colorbar, 'value', onlychanged=False)

        self._widget_label = pn.widgets.TextInput(name='Label of colorbar')
        self._widget_label.param.watch(self._callback_label, 'value', onlychanged=False)

        self._widget_refresh_col = pn.widgets.Button(name="Refresh label",
                                                    button_type="success")
        self._widget_refresh_col.param.watch(self._callback_refresh, 'clicks',
                                            onlychanged=False)

        self._widget_col_background = pn.widgets.ColorPicker(name='Color background colorbar', value="#2896A5")
        self._widget_col_background.param.watch(self._callback_col_background, 'value', onlychanged=False)

    def _create_widgets_legend(self):
        self._widgets_show_legend = pn.widgets.Checkbox(name='Show legend',
                                                        value=self.enable_legend)
        self._widgets_show_legend.param.watch(self._callback_enable_legend, 'value',
                                                onlychanged=False)

        self._widget_top_legend = pn.widgets.IntSlider(name='Top space',
                                                        value=self.leg_top,
                                                        start=0,
                                                        end=self.p_height - 20)
        self._widget_top_legend.param.watch(self._callback_top_legend, 'value', onlychanged=False)

        self._widget_left_legend = pn.widgets.IntSlider(name='Left space',
                                                         value=self.leg_left,
                                                         start=0,
                                                         end=self.p_width - 20)
        self._widget_left_legend.param.watch(self._callback_left_legend, 'value', onlychanged=False)

        self._widget_width_legend = pn.widgets.IntSlider(name='Width Legend',
                                                          value=self.leg_width,
                                                          start=1,
                                                          end=self.p_width)
        self._widget_width_legend.param.watch(self._callback_width_legend, 'value', onlychanged=False)

        self._widget_height_legend = pn.widgets.IntSlider(name='Height Legend',
                                                           value=self.leg_height,
                                                           start=1,
                                                           end=self.p_height)
        self._widget_height_legend.param.watch(self._callback_height_legend, 'value', onlychanged=False)

        self._widget_refresh_leg = pn.widgets.Button(name="Refresh legend",
                                                    button_type="success")
        self._widget_refresh_leg.param.watch(self._callback_refresh_leg, 'clicks',
                                            onlychanged=False)

        self._widget_leg_background = pn.widgets.ColorPicker(name='Color background colorbar', value="#16425B")
        self._widget_leg_background.param.watch(self._callback_leg_background, 'value', onlychanged=False)

    def _callback_label(self, event):
        self._label = event.new if event.new != "" else None

    def _callback_refresh(self, event):
        self.set_colorbar(0, 1, label=self._label)

    def _callback_refresh_leg(self, event):
        self.set_legend()

    def _callback_enable_colorbar(self, event):
        self.enable_colorbar = event.new
        self.set_colorbar_widget()

    def _callback_enable_legend(self, event):
        self.enable_legend = event.new
        if self.enable_legend:
            self.create_legend()
            self.sidebar.insert(1, self.legend)
        else:
            if self.legend is not None:
                self.sidebar.remove(self.legend) if self.legend in self.sidebar else None

    def set_colorbar_widget(self):
        if self.colorbar is not None:
            for pa in self.panel:
                if self.colorbar in pa:
                    pa.remove(self.colorbar)
                    break
        if self.enable_colorbar:
            if self.pos_colorbar == "horizontal":
                self.create_colorbar()
                self.colorbar.margin = (0, 0, 0, self.p_frame_left)
                self.panel[0].insert(1, self.colorbar)
            elif self.pos_colorbar == "vertical":
                self.create_colorbar()
                self.sidebar.insert(0, self.colorbar)
            self._widget_height_colorbar.value = self.col_height = self.p_frame_height if self.pos_colorbar == "vertical" \
                else round(self.p_frame_height / self._ratio)
            self._widget_width_colorbar.value = self.col_width = self.p_frame_width if self.pos_colorbar == "horizontal" \
                                           else round(self.p_frame_width / self._ratio)
            self._widget_left_colorbar.value = self.col_left = 0 if self.pos_colorbar == "vertical" else self.p_frame_left
            self._widget_top_colorbar.value = self.col_top = 0

    def _callback_colorbar_ori(self, event):
        self.pos_colorbar = event.new
        self.set_colorbar_widget()

    def _callback_top_colorbar(self, event):
        # Margins need to be tuple
        mr = list(self.colorbar.margin)
        mr[0] = event.new
        self.colorbar.margin = tuple(mr)
        self.colorbar.param.trigger('object')

    def _callback_left_colorbar(self, event):
        # Margins need to be tuple
        mr = list(self.colorbar.margin)
        mr[-1] = event.new
        self.colorbar.margin = tuple(mr)
        self.colorbar.param.trigger('object')

    def _callback_width_colorbar(self, event):
        self.colorbar.width = event.new
        self.colorbar.param.trigger('object')

    def _callback_height_colorbar(self, event):
        self.colorbar.height = event.new
        self.colorbar.param.trigger('object')

    def _callback_top_legend(self, event):
        self.leg_top = event.new
        # Margins need to be tuple
        mr = list(self.legend.margin)
        mr[0] = event.new
        self.legend.margin = tuple(mr)
        self.legend.param.trigger('object')

    def _callback_left_legend(self, event):
        self.leg_left = event.new
        mr = list(self.legend.margin)
        mr[-1] = event.new
        self.legend.margin = tuple(mr)
        self.legend.param.trigger('object')

    def _callback_width_legend(self, event):
        self.leg_width = event.new
        self.legend.width = event.new
        self.legend.param.trigger('object')

    def _callback_height_legend(self, event):
        self.leg_height = event.new
        self.legend.height = event.new
        self.legend.param.trigger('object')

    def _callback_p_frame_top(self, target, event):
        self.p_frame_top = event.new
        m = target.margin
        n = event.new
        # just changing single indices does not trigger updating of pane
        target.margin = (n, m[1], m[2], m[3])

    def _callback_p_frame_left(self, target, event):
        self.p_frame_left = event.new
        m = target.margin
        n = event.new
        target.margin = (m[0], m[1], m[2], n)

    def _callback_p_frame_width(self, target, event):
        self.p_frame_width = event.new
        target.width = event.new
        target.param.trigger('object')

    def _callback_p_frame_height(self, target, event):
        self.p_frame_height = event.new
        target.height = event.new
        target.param.trigger('object')

    def _callback_json_filename(self, event):
        self.json_filename = event.new

    def _callback_json_save(self, event):
        if self.json_filename is not None:
            self.save_json(file=self.json_filename)

    def _callback_col_background(self, event):
        self.colorbar.background = event.new

    def _callback_leg_background(self, event):
        self.legend.background = event.new


================================================
FILE: sandbox/projector/shading.py
================================================
from pysolar.solar import get_altitude, get_azimuth
import datetime
import urllib.parse
import requests
from sandbox import set_logger
logger = set_logger(__name__)


class LightSource:
    """
    Get the altitude and azimuth of the sun for an specific latitude, longitude and time.
    """
    def __init__(self,
                 latitude: float = 50.779170300000004,
                 longitude: float = 6.068920799008829,
                 date: datetime.datetime = datetime.datetime.now(tz=datetime.timezone.utc)):
        """
        Args:
            latitude:
            longitude:
            date: datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])
        """
        self.latitude_deg = latitude
        self.longitude_deg = longitude
        self.date = date
        self.address = 'RWTH Aachen, Germany'
        self.manual = False
        self.simulation = False
        self._altitude = 45
        self._azimuth = 315
        self._ve = 0.25
        self._add_time = 1  # add 1 hour when simulation
        self.full_address = 'RWTH Aachen, Germany'
        logger.info("LightSource set to address %s at datetime %s" % (self.address, self.date.ctime()))

    @property
    def url(self):
        """
        Search address in web page: https://nominatim.openstreetmap.org/ui/search.html
        Returns:
            url address
        """
        return 'https://nominatim.openstreetmap.org/search/' + urllib.parse.quote(self.address) + '?format=json'

    @property
    def altitude(self):
        """ Get the altitude of the sun position based on the latitude, longitude and date"""
        if self.manual:
            return self._altitude
        if self.simulation:
            self.add_time()
        return get_altitude(self.latitude_deg, self.longitude_deg, self.date)

    @property
    def azimuth(self):
        """ Get the azimuth of the sun position based on the latitude, longitude and date"""
        if self.manual:
            return self._azimuth
        if self.simulation:
            self.add_time()
        return get_azimuth(self.latitude_deg, self.longitude_deg, self.date)

    def add_time(self):
        self.date = self.date + datetime.timedelta(hours=self._add_time)

    @property
    def ve(self):
        """
        Vertical exaggeration
        Returns:
        """
        return self._ve

    def set_ve(self, ve):
        """
        Set vertical exaggeration
        Args:
            ve: Vertical exaggeration

        Returns:

        """
        self._ve = ve

    def set_address(self, address: str = 'RWTH Aachen, Germany'):
        """
        Provide an address, city, or country to search for the latitude and longitude
        Args:
            address: e.g. 'Aachen', 'Germany', 'India', 'Colombia', 'RWTH Aachen University'
        Returns:

        """
        self.address = address

    def set_latitude_longitude(self):
        """
        Set the latitude and longitude based on the self.address
        Returns:
            set the self.latitude_deg and self.longitude_deg
        """
        try:
            response = requests.get(self.url).json()
            self.latitude_deg = float(response[0]["lat"])
            self.longitude_deg = float(response[0]["lon"])
            self.full_address = response[0]["display_name"]
        except:
            logger.warning("Address '%s' not found, change address" % self.address)

    def set_datetime(self, year=2021, month=3, day=19, hour=15, minute=13, second=1, date=None, time=None,
                     tzinfo=datetime.timezone.utc):
        """
        Set the datetime to acquire the sun position
        Args:
            year: int
            month: int [1-12]
            day: int [1-31]
            hour: int [0-23]
            minute: int [0-59]
            second: int [0-59]
            date: datetime.date
            time: datetime.time
            tzinfo: datetime.timezone

        Returns:

        """
        if date is not None or time is not None:
            self.date = datetime.datetime.combine(date if date is not None else self.date.date(),
                                                  time if time is not None else self.date.time(),
                                                  tzinfo=tzinfo)
        else:
            self.date = datetime.datetime(year, month, day, hour, minute, second, tzinfo=tzinfo)

    def set_altitude(self, altitude):
        """
        Set the altitude manually. self.manual must be True
        Args:
            altitude:

        Returns:

        """
        self._altitude = altitude

    def set_azimuth(self, azimuth):
        """
        Set the azimuth manually. self.manual must be True
        Args:
            azimuth:

        Returns:
        """
        self._azimuth = azimuth


================================================
FILE: sandbox/sensor/__init__.py
================================================
from .sensor_api import Sensor
from .calibration_sensor import CalibSensor

if __name__ == '__main__':
    pass



================================================
FILE: sandbox/sensor/calibration_sensor.py
================================================
import threading
import panel as pn
pn.extension()
from sandbox.sensor import Sensor
from sandbox.projector import Projector
from sandbox import _calibration_dir

import matplotlib.pyplot as plt
import matplotlib as mpl
from matplotlib.figure import Figure


class CalibSensor:  # TODO: include automatic
    """Module to calibrate the sensor"""
    def __init__(self,  calibprojector: str = None, name: str = 'kinectv2', **kwargs):
        # color map setup
        self.c_under = '#DBD053'
        self.c_over = '#DB3A34'
        # margin patches setup
        self.c_margin = '#084C61'
        self.margin_alpha = 0.5
        self.calibprojector = calibprojector
        self.sensor = Sensor(name=name, invert=False, clip_values=False, gauss_filter=False, **kwargs)
        self.projector = Projector(calibprojector=self.calibprojector, **kwargs)
        import copy
        self.cmap = copy.copy(mpl.cm.get_cmap("Greys_r"))
        self.cmap.set_over(self.c_over)
        self.cmap.set_under(self.c_under)
        self.cmap.set_bad('k')

        self._refresh_panel_frame()

        # fig = plt.figure()
        self.figure = Figure()
        self.ax_notebook_frame = plt.Axes(self.figure, [0., 0., 1., 1.])
        self.figure.add_axes(self.ax_notebook_frame)

        self.calib_notebook_frame = pn.pane.Matplotlib(self.figure, tight=False, height=300)
        plt.close()  # close figure to prevent inline display

        pn.state.add_periodic_callback(self.update_panel_frame, 5)
        # self.projector.panel.add_periodic_callback(self.update_panel_frame, 5)

        self.frame_raw = self.sensor.get_raw_frame()
        self.ax_notebook_frame.imshow(self.frame_raw, vmin=self.sensor.s_min, vmax=self.sensor.s_max, cmap=self.cmap,
                                      origin="lower", aspect="auto")
        self.calib_notebook_frame.param.trigger('object')
        self._create_widgets()


    def _refresh_panel_frame(self):
        self.projector.ax.cla()
        self.fig_frame = self.projector.ax.imshow(self.sensor.get_frame(),
                                                      vmin=self.sensor.s_min,
                                                      vmax=self.sensor.s_max,
                                                      cmap=self.cmap,
                                                  origin="lower",
                                                  aspect="auto")

    def update(self):
        self.update_panel_frame(self.projector.ax)
        self.update_notebook_frame(self.ax_panel_frame)

    def update_panel_frame(self):
        frame = self.sensor.get_frame()
        self.fig_frame.set_data(frame)
        # self.projector.ax.set_xlim(0, self.sensor.s_frame_width)
        # self.projector.ax.set_ylim(0, self.sensor.s_frame_height)
        self.fig_frame.set_clim(vmin=self.sensor.s_min, vmax=self.sensor.s_max)
        self.projector.trigger()


    def update_notebook_frame(self):
        """ Adds margin patches to the current plot object.
        This is only useful when an uncropped dataframe is passed.
        """

        self.ax_notebook_frame.cla()
        self.ax_notebook_frame.imshow(self.frame_raw, vmin=self.sensor.s_min, vmax=self.sensor.s_max, cmap=self.cmap,
                                      origin="lower", aspect="auto")

        rec_t = plt.Rectangle((0, self.sensor.s_height - self.sensor.s_top), self.sensor.s_width, self.sensor.s_top,
                              fc=self.c_margin, alpha=self.margin_alpha)
        rec_r = plt.Rectangle((self.sensor.s_width - self.sensor.s_right, 0), self.sensor.s_right, self.sensor.s_height,
                              fc=self.c_margin, alpha=self.margin_alpha)
        rec_b = plt.Rectangle((0, 0), self.sensor.s_width, self.sensor.s_bottom,
                              fc=self.c_margin, alpha=self.margin_alpha)
        rec_l = plt.Rectangle((0, 0), self.sensor.s_left, self.sensor.s_height,
                              fc=self.c_margin, alpha=self.margin_alpha)
        self.ax_notebook_frame.add_patch(rec_t)
        self.ax_notebook_frame.add_patch(rec_r)
        self.ax_notebook_frame.add_patch(rec_b)
        self.ax_notebook_frame.add_patch(rec_l)
        self.calib_notebook_frame.param.trigger('object')

    def calibrate_sensor(self):
        widgets = pn.WidgetBox('<b>Load a projector calibration file</b>',
                               self._widget_json_filename_load_projector,
                               self._widget_json_load_projector,
                               '<b>Distance from edges (pixel)</b>',
                               self._widget_s_top,
                               self._widget_s_right,
                               self._widget_s_bottom,
                               self._widget_s_left,
                               # self._widget_s_enable_auto_cropping,
                               # self._widget_s_automatic_cropping,
                               pn.layout.VSpacer(height=5),
                               '<b>Distance from sensor (mm)</b>',
                               self._widget_s_min,
                               self._widget_s_max,
                               self._widget_refresh_frame)
        box = pn.Column('<b>Physical dimensions of the sandbox</b>',
                        self._widget_box_width,
                        self._widget_box_height,
                        )
        save = pn.Column('<b>Save file</b>',
                         self._widget_json_filename,
                         self._widget_json_save
                         )

        rows = pn.Row(widgets, self.calib_notebook_frame)
        panel = pn.Column('## Sensor calibration', rows)
        tabs = pn.Tabs(('Calibration', panel),
                       ("Box dimensions", box),
                       ("Save files", save)
                       )
        return tabs

    def _create_widgets(self):
        # sensor widgets and links

        self._widget_s_top = pn.widgets.IntSlider(name='Sensor top margin',
                                                  bar_color=self.c_margin,
                                                  value=self.sensor.s_top,
                                                  start=1,
                                                  end=self.sensor.s_height)
        self._widget_s_top.param.watch(self._callback_s_top, 'value', onlychanged=False)

        self._widget_s_right = pn.widgets.IntSlider(name='Sensor right margin',
                                                    bar_color=self.c_margin,
                                                    value=self.sensor.s_right,
                                                    start=1,
                                                    end=self.sensor.s_width)
        self._widget_s_right.param.watch(self._callback_s_right, 'value', onlychanged=False)

        self._widget_s_bottom = pn.widgets.IntSlider(name='Sensor bottom margin',
                                                     bar_color=self.c_margin,
                                                     value=self.sensor.s_bottom,
                                                     start=1,
                                                     end=self.sensor.s_height)
        self._widget_s_bottom.param.watch(self._callback_s_bottom, 'value', onlychanged=False)

        self._widget_s_left = pn.widgets.IntSlider(name='Sensor left margin',
                                                   bar_color=self.c_margin,
                                                   value=self.sensor.s_left,
                                                   start=1,
                                                   end=self.sensor.s_width)
        self._widget_s_left.param.watch(self._callback_s_left, 'value', onlychanged=False)

        self._widget_s_min = pn.widgets.IntSlider(name='Vertical minimum',
                                                  bar_color=self.c_under,
                                                  value=self.sensor.s_min,
                                                  start=0,
                                                  end=2000)
        self._widget_s_min.param.watch(self._callback_s_min, 'value', onlychanged=False)

        self._widget_s_max = pn.widgets.IntSlider(name='Vertical maximum',
                                                  bar_color=self.c_over,
                                                  value=self.sensor.s_max,
                                                  start=0,
                                                  end=2000)
        self._widget_s_max.param.watch(self._callback_s_max, 'value', onlychanged=False)

        # Auto cropping widgets:

        # self._widget_s_enable_auto_cropping = pn.widgets.Checkbox(name='Enable Automatic Cropping', value=False)
        # self._widget_s_enable_auto_cropping.param.watch(self._callback_enable_auto_cropping, 'value',
        #                                                onlychanged=False)

        # self._widget_s_automatic_cropping = pn.widgets.Button(name="Crop", button_type="success")
        # self._widget_s_automatic_cropping.param.watch(self._callback_automatic_cropping, 'clicks',
        #                                              onlychanged=False)

        # box widgets:

        # self._widget_s_enable_auto_calibration = CheckboxGroup(labels=["Enable Automatic Sensor Calibration"],
        #                                                                  active=[1])
        self._widget_box_width = pn.widgets.IntSlider(name='width of sandbox in mm',
                                                      bar_color=self.c_margin,
                                                      value=int(self.sensor.box_width),
                                                      start=1,
                                                      end=2000)
        self._widget_box_width.param.watch(self._callback_box_width, 'value', onlychanged=False)

        # self._widget_s_automatic_calibration = pn.widgets.Toggle(name="Run", button_type="success")
        self._widget_box_height = pn.widgets.IntSlider(name='height of sandbox in mm',
                                                       bar_color=self.c_margin,
                                                       value=int(self.sensor.box_height),
                                                       start=1,
                                                       end=2000)
        self._widget_box_height.param.watch(self._callback_box_height, 'value', onlychanged=False)

        # refresh button

        self._widget_refresh_frame = pn.widgets.Button(name='Refresh sensor frame\n(3 sec. delay)!')
        self._widget_refresh_frame.param.watch(self._callback_refresh_frame, 'clicks', onlychanged=False)

        # save selection

        # Only for reading files --> Is there no location picker in panel widgets???
        # self._widget_json_location = pn.widgets.FileInput(name='JSON location')
        self._widget_json_filename = pn.widgets.TextInput(name='Choose a calibration filename:')
        self._widget_json_filename.param.watch(self._callback_json_filename, 'value', onlychanged=False)
        self._widget_json_filename.value = _calibration_dir + 'my_sensor_calibration.json'

        self._widget_json_save = pn.widgets.Button(name='Save calibration')
        self._widget_json_save.param.watch(self._callback_json_save, 'clicks', onlychanged=False)

        self._widget_json_filename_load_projector = pn.widgets.TextInput(name='Choose the projector calibration filename:')
        self._widget_json_filename_load_projector.param.watch(self._callback_json_filename_load_projector, 'value', onlychanged=False)
        self._widget_json_filename_load_projector.value = _calibration_dir + 'my_projector_calibration.json'

        self._widget_json_load_projector = pn.widgets.Button(name='Load calibration')
        self._widget_json_load_projector.param.watch(self._callback_json_load_projector, 'clicks', onlychanged=False)

        return True

        # sensor callbacks
    def _callback_s_top(self, event):
        self.sensor.s_top = event.new
        # change plot and trigger panel update
        self.update_notebook_frame()

    def _callback_s_right(self, event):
        self.sensor.s_right = event.new
        # self._refresh_panel_frame() #TODO: dirty workaround
        self.update_notebook_frame()

    def _callback_s_bottom(self, event):
        self.sensor.s_bottom = event.new
        self.update_notebook_frame()

    def _callback_s_left(self, event):
        self.sensor.s_left = event.new
        # self._refresh_panel_frame()  # TODO: dirty workaround
        self.update_notebook_frame()

    def _callback_s_min(self, event):
        self.sensor.s_min = event.new
        # self._refresh_panel_frame()  # TODO: dirty workaround
        self.update_notebook_frame()

    def _callback_s_max(self, event):
        self.sensor.s_max = event.new
        # self._refresh_panel_frame()  # TODO: dirty workaround
        self.update_notebook_frame()

    def _callback_refresh_frame(self, event):
        plt.pause(3)
        # only here, get a new frame before updating the plot
        self.frame_raw = self.sensor.get_raw_frame()
        self.update_notebook_frame()

    def _callback_json_filename(self, event):
        self.sensor.json_filename = event.new

    def _callback_json_save(self, event):
        if self.sensor.json_filename is not None:
            self.sensor.save_json(file=self.sensor.json_filename)

    def _callback_json_filename_load_projector(self, event):
        self.calibprojector = event.new

    def _callback_json_load_projector(self, event):
        if self.calibprojector is not None:
            self.projector = Projector(self.calibprojector)

    def _callback_box_width(self, event):
        self.sensor.box_width = float(event.new)

    def _callback_box_height(self, event):
        self.sensor.box_height = float(event.new)

    # TODO: Make sense to enable this automatic calibration?
    """def _callback_enable_auto_calibration(self, event):
        self.automatic_calibration = event.new
        if self.automatic_calibration == True:
            self.plot.render_frame(self.Aruco.p_arucoMarker(), vmin=0, vmax=256)
            self.projector.frame.object = self.plot.figure
        else:
            self.plot.create_empty_frame()
            self.projector.frame.object = self.plot.figure

    def _callback_automatic_calibration(self, event):
        if self.automatic_calibration == True:
            p_frame_left, p_frame_top, p_frame_width, p_frame_height = self.Aruco.move_image()
            self.calib.p_frame_left = p_frame_left
            self.calib.p_frame_top = p_frame_top
            self._widget_p_frame_left.value = self.calib.p_frame_left
            self._widget_p_frame_top.value = self.calib.p_frame_top
            self.calib.p_frame_width = p_frame_width
            self.calib.p_frame_height = p_frame_height
            self._widget_p_frame_width.value = self.calib.p_frame_width
            self._widget_p_frame_height.value = self.calib.p_frame_height
            self.plot.render_frame(self.Aruco.p_arucoMarker(), vmin=0, vmax=256)
            self.projector.frame.object = self.plot.figure
            self.update_calib_plot()


    def _callback_enable_auto_cropping(self, event):
        self.automatic_cropping = event.new


    def _callback_automatic_cropping(self, event):
        if self.automatic_cropping == True:
            self.pause()
            s_top, s_left, s_bottom, s_right = self.Aruco.crop_image_aruco()
            self.calib.s_top = s_top
            self.calib.s_bottom = s_bottom
            self.calib.s_left = s_left
            self.calib.s_right = s_right
            self._widget_s_top.value = self.calib.s_top
            self._widget_s_bottom.value = self.calib.s_bottom
            self._widget_s_left.value = self.calib.s_left
            self._widget_s_right.value = self.calib.s_right
            self.update_calib_plot()
            self.resume()"""


================================================
FILE: sandbox/sensor/dummy.py
================================================
import numpy
from scipy.spatial.distance import cdist  # for DummySensor
from scipy.interpolate import griddata  # for DummySensor
from sandbox import set_logger
logger = set_logger(__name__)


class DummySensor:

    def __init__(self, width=512, height=424, depth_limits=(0, 400), extent=None,
                 corners=True, points_n=4, points_distance=0.3,
                 alteration_strength=0.1, **kwargs):
        """

        Args:
            *args:
            extent: [0, width_frame, 0, height_frame, vmin_frame, vmax_frmae]
            corners:
            points_n:
            points_distance:
            alteration_strength:
            **kwargs:
               - random_seed

        """

        random_seed = kwargs.get('random_seed', 1234)
        self.seed = random_seed
        numpy.random.seed(seed=self.seed)

        self.name = 'dummy'
        self.depth_width = width
        self.depth_height = height
        if extent is None:
            self.depth_lim = depth_limits
            self._depth_width = width
            self._depth_height = height
        else:
            self._depth_width = extent[1]
            self._depth_height = extent[3]
            self.depth_lim = extent[-2:]

        self.corners = corners
        self.n = points_n
        # distance in percent of grid diagonal
        self.distance = numpy.sqrt(self._depth_width ** 2 + self._depth_height ** 2) * points_distance
        # alteration_strength: 0 to 1 (maximum 1 equals numpy.pi/2 on depth range)
        self.strength = alteration_strength

        self.grid = None
        self.positions = None
        self.os_values = None
        self.values = None

        # create grid, init values, and init interpolation
        self._create_grid()
        self._pick_positions()
        self._pick_values()
        self._interpolate()
        logger.info("DummySensor initialized.")

    def get_frame(self):
        """

        Returns:

        """
        self._alter_values()
        self._interpolate()
        self.depth[self.depth < 0] = 0  # TODO: Solve the problem of having negative values
        return self.depth

    def _oscillating_depth(self, random):
        r = (self.depth_lim[1] - self.depth_lim[0]) / 2
        return numpy.sin(random) * r + r + self.depth_lim[0]

    def _create_grid(self):
        # creates 2D grid for given resolution
        x, y = numpy.meshgrid(numpy.arange(0, self._depth_width, 1), numpy.arange(0, self._depth_height, 1))
        self.grid = numpy.stack((x.ravel(), y.ravel())).T
        return True

    def _pick_positions(self):
        """
        Param:
            grid: Set of possible points to pick from
            n: desired number of points (without corners counting), not guaranteed to be reached
            distance: distance or range between points
        :return:
        """

        numpy.random.seed(seed=self.seed)
        gl = self.grid.shape[0]
        gw = self.grid.shape[1]
        n = self.n

        if self.corners:
            n += 4
            points = numpy.zeros((n, gw))
            points[1, 0] = self.grid[:, 0].max()
            points[2, 1] = self.grid[:, 1].max()
            points[3, 0] = self.grid[:, 0].max()
            points[3, 1] = self.grid[:, 1].max()
            i = 4  # counter
        else:
            points = numpy.zeros((n, gw))
            # randomly pick initial point
            ipos = numpy.random.randint(0, gl)
            points[0, :2] = self.grid[ipos, :2]
            i = 1  # counter

        while i < n:
            # calculate all distances between remaining candidates and sim points
            dist = cdist(points[:i, :2], self.grid[:, :2])
            # choose candidates which are out of range
            mm = numpy.min(dist, axis=0)
            candidates = self.grid[mm > self.distance]
            # count candidates
            cl = candidates.shape[0]
            if cl < 1:
                break
            # randomly pick candidate and set next point
            pos = numpy.random.randint(0, cl)
            points[i, :2] = candidates[pos, :2]

            i += 1

        # just return valid points if early break occured
        self.positions = points[:i]

        return True

    def _pick_values(self):
        n = self.positions.shape[0]
        self.os_values = numpy.random.uniform(-numpy.pi, numpy.pi, n)
        self.values = self._oscillating_depth(self.os_values)

    def _alter_values(self):
        # maximum range in both directions the values should be altered

        os_range = self.strength * (numpy.pi / 2)
        for i, value in enumerate(self.os_values):
            self.os_values[i] = value + numpy.random.uniform(-os_range, os_range)
        self.values = self._oscillating_depth(self.os_values)

    def _interpolate(self):
        inter = griddata(self.positions[:, :2], self.values, self.grid[:, :2], method='cubic', fill_value=0)
        self.depth = inter.reshape(self._depth_height, self._depth_width)



================================================
FILE: sandbox/sensor/kinectV1.py
================================================
import numpy
from sandbox import set_logger
logger = set_logger(__name__)

try:
    import freenect  # wrapper for KinectV1
except ImportError:
    logger.warning('Freenect module not found, KinectV1 will not work', exc_info=True)


class KinectV1:

    def __init__(self):
        # hard coded class attributes for KinectV1's native resolution
        self.name = 'kinect_v1'
        self.depth_width = 320
        self.depth_height = 240
        self.color_width = 640
        self.color_height = 480

        self.id = 0
        self.device = None
        self.depth = None
        self.color = None
        logger.warning('Two kernels cannot access the Kinect at the same time. '
                       'This will lead to a sudden death of the kernel. '
                       'Be sure no other kernel is running before you initialize a KinectV1 object.')

        logger.info("looking for kinect...")
        ctx = freenect.init()
        self.device = freenect.open_device(ctx, self.id)
        print(self.id)
        freenect.close_device(self.device)  # TODO Test if this has to be done!
        # get the first Depth frame already (the first one takes much longer than the following)
        self.depth = self.get_frame()
        logger.info("KinectV1 initialized.")

    def get_frame(self):
        self.depth = freenect.sync_get_depth(index=self.id, format=freenect.DEPTH_MM)[0]
        self.depth = numpy.fliplr(self.depth)
        return self.depth

    def get_color(self):
        """
        Returns:

        """
        self.color = freenect.sync_get_video(index=self.id)[0]
        self.color = numpy.fliplr(self.color)
        return self.color



================================================
FILE: sandbox/sensor/kinectV2.py
================================================
import numpy
import platform
import threading
import os
from sandbox import set_logger
logger = set_logger(__name__)
_platform = platform.system()
try:
    if _platform == 'Windows':
        from pykinect2 import PyKinectV2  # Wrapper for KinectV2 Windows SDK
        from pykinect2 import PyKinectRuntime
    elif _platform == 'Linux':
        os.environ["LIBFREENECT2_LOGGER_LEVEL"] = "ERROR"
        from freenect2 import Device, FrameType



except ImportError:
    logger.warning('dependencies not found for KinectV2 to work. Check installation and try again', exc_info=True)


class KinectV2:
    """
    control class for the KinectV2 based on the Python wrappers of the official Microsoft SDK
    Init the kinect and provides a method that returns the scanned depth image as numpy array.
    Also we do gaussian blurring to get smoother surfaces.

    """
    def __init__(self):
        # hard coded class attributes for KinectV2's native resolution
        self.name = 'kinect_v2'
        self.depth_width = 512
        self.depth_height = 424
        self.color_width = 1920
        self.color_height = 1080

        self._init_device()

        self.depth = self.get_frame()
        self.color = self.get_color()
        logger.info("KinectV2 initialized.")

    def _init_device(self):
        """
        creates the self.device parameter to start the stream of frames
        Returns:

        """
        if _platform == 'Windows':
            self.device = PyKinectRuntime.PyKinectRuntime(PyKinectV2.FrameSourceTypes_Color |
                                                          PyKinectV2.FrameSourceTypes_Depth |
                                                          PyKinectV2.FrameSourceTypes_Infrared)

        elif _platform == 'Linux':
            # Threading
            self._lock = threading.Lock()
            self._thread = None
            self._thread_status = 'stopped'  # status: 'stopped', 'running'

            self.device = Device()
            self._color = numpy.zeros((self.color_height, self.color_width, 4))
            self._depth = numpy.zeros((self.depth_height, self.depth_width))
            self._ir = numpy.zeros((self.depth_height, self.depth_width))
            self._run()
            logger.info("Searching first frame")
            while True:
                if not numpy.all(self._depth == 0):
                    logger.info("First frame found")
                    break

        else:
            logger.error(_platform + "not implemented")
            raise NotImplementedError

    def _run(self):
        """
        Run the thread when _platform is linux
        """
        if self._thread_status != 'running':
            self._thread_status = 'running'
            self._thread = threading.Thread(target=self._open_kinect_frame_stream, daemon=True, )
            self._thread.start()
            logger.info('Acquiring frames...')
        else:
            logger.info('Already running.')

    def _stop(self):
        """
        Stop the thread when _platform is linux
        """
        if self._thread_status is not 'stopped':
            self._thread_status = 'stopped'  # set flag to end thread loop
            self._thread.join()  # wait for the thread to finish
            logger.info('Stopping frame acquisition.')
        else:
            logger.info('thread was not running.')

    def _open_kinect_frame_stream(self):
        """
        keep the stream open to adquire new frames when using linux
        """
        frames = {}
        with self.device.running():
            for type_, frame in self.device:
                frames[type_] = frame
                if FrameType.Color in frames:
                    self._color = frames[FrameType.Color].to_array()
                if FrameType.Depth in frames:
                    self._depth = frames[FrameType.Depth].to_array()
                if FrameType.Ir in frames:
                    self._ir = frames[FrameType.Ir].to_array()
                if self._thread_status != "running":
                    break

    def get_frame(self):
        """
        Args:
        Returns:
               2D Array of the shape(424, 512) containing the depth information of the latest frame in mm
        """
        if _platform == 'Windows':
            depth_flattened = self.device.get_last_depth_frame()
            self.depth = depth_flattened.reshape(
                (self.depth_height, self.depth_width))  # reshape the array to 2D with native resolution of the kinectV2
        elif _platform == 'Linux':
            # assert self._thread_status == "running"
            self.depth = self._depth
        return self.depth

    def get_ir_frame_raw(self):
        """
        Args:
        Returns:
               2D Array of the shape(424, 512) containing the raw infrared intensity in (uint16) of the last frame
        """
        if _platform == 'Windows':
            ir_flattened = self.device.get_last_infrared_frame()
            # reshape the array to 2D with native resolution of the kinectV2
            self.ir_frame_raw = numpy.flipud(ir_flattened.reshape((self.depth_height, self.depth_width)))
        elif _platform == 'Linux':
            # assert self._thread_status == "running"
            self.ir_frame_raw = self._ir
        return self.ir_frame_raw

    def get_ir_frame(self, min=0, max=6000):
        """

        Args:
            min: minimum intensity value mapped to uint8 (will become 0) default: 0
            max: maximum intensity value mapped to uint8 (will become 255) default: 6000
        Returns:
               2D Array of the shape(424, 512) containing the infrared intensity between min and max mapped to uint8 of the last frame

        """
        ir_frame_raw = self.get_ir_frame_raw()
        self.ir_frame = numpy.interp(ir_frame_raw, (min, max), (0, 255)).astype('uint8')
        return self.ir_frame

    def get_color(self):
        """

        Returns:

        """
        if _platform == 'Windows':
            color= numpy.array([self.device.get_last_color_frame()])

        elif _platform == 'Linux':
            # assert self._thread_status == "running"
            color = self._color

        resolution_camera = self.color_height * self.color_width  # resolution camera Kinect V2
        # Palette of colors in RGB / Cut of 4th column marked as intensity
        palette = numpy.reshape(color, (resolution_camera, 4))[:, [2, 1, 0]]
        position_palette = numpy.reshape(numpy.arange(0, len(palette), 1), (self.color_height, self.color_width))
        self.color = numpy.flipud(palette[position_palette])
        return self.color



================================================
FILE: sandbox/sensor/lidar_l515.py
================================================
import numpy as np
import threading
from sandbox import set_logger
logger = set_logger(__name__)

# %%
try:
    import pyrealsense2 as rs
except ImportError:
    logger.warning('dependencies not found for LiDAR L515 to work. Check installation and try again', exc_info=True)


# %%
class LiDAR:
    """
    control class for the LiDAR L515 based on the Python wrappers of the Intel RealSense.
    Init the LiDAR and provides a method that returns the scanned depth image as numpy array.
    Also we do gaussian blurring to get smoother surfaces.

    """

    def __init__(self):
        # hard coded class attributes for KinectV2's native resolution
        self.name = 'lidar'
        self.depth_width = 640
        self.depth_height = 480
        self.color_width = 960
        self.color_height = 540

        self._init_device()

        self.depth = self.get_frame()
        self.color = self.get_color()
        logger.info("LiDAR initialized.")

    def _init_device(self):
        """
        Open the pipeline for adquiring frames
        Returns:

        """

        # Threading
        self._lock = threading.Lock()
        self._thread = None
        self._thread_status = 'stopped'  # status: 'stopped', 'running'

        self.pipeline = rs.pipeline()
        self.config = rs.config()

        # Get device product line for setting a supporting resolution
        pipeline_wrapper = rs.pipeline_wrapper(self.pipeline)
        pipeline_profile = self.config.resolve(pipeline_wrapper)
        device = pipeline_profile.get_device()
        device_product_line = str(device.get_info(rs.camera_info.product_line))

        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        self.config.enable_stream(rs.stream.infrared, 640, 480, rs.format.y8, 30)
        if device_product_line == 'L500':
            self.config.enable_stream(rs.stream.color, 960, 540, rs.format.rgb8, 30)
        else:
            self.config.enable_stream(rs.stream.color, 640, 480, rs.format.rgb8, 30)

        # Start streaming
        self.profile = self.pipeline.start(self.config)

        self.depth_scale = self.profile.get_device().first_depth_sensor().get_depth_scale()

        self._color = np.zeros((self.color_height, self.color_width, 3))
        self._depth = np.zeros((self.depth_height, self.depth_width))
        self._ir = np.zeros((self.depth_height, self.depth_width))
        self._run()
        logger.info("Searching first frame")
        while True:
            if not np.all(self._depth == 0):
                logger.info("First frame found")
                break

    def _run(self):
        """
        Run the thread when _platform is linux
        """
        if self._thread_status != 'running':
            self._thread_status = 'running'
            self._thread = threading.Thread(target=self._update_frames, daemon=True, )
            self._thread.start()
            logger.info('Acquiring frames...')
        else:
            logger.info('Already running.')

    def _stop(self):
        """
        Stop the thread
        """
        if self._thread_status is not 'stopped':
            self._thread_status = 'stopped'  # set flag to end thread loop
            self._thread.join()  # wait for the thread to finish
            logger.info('Stopping frame acquisition.')
        else:
            logger.info('thread was not running.')

    def _update_frames(self):
        """
        keep the stream open to acquire new frames
        """
        while True:
            # Wait for a coherent pair of frames: depth and color
            frames = self.pipeline.wait_for_frames()
            depth_frame = frames.get_depth_frame()
            infrared_frame = frames.get_infrared_frame()
            color_frame = frames.get_color_frame()
            if not depth_frame or not color_frame or not infrared_frame:
                continue

            # Convert images to numpy arrays
            self._depth = np.asanyarray(depth_frame.get_data())
            self._color = np.asanyarray(color_frame.get_data())
            self._ir = np.asanyarray(infrared_frame.get_data())

            if self._thread_status != "running":
                break

    def get_frame(self):
        """
        Get depth frame
        Args:
        Returns:
               2D Array of the shape(480, 640) containing the depth information of the latest frame in mm
        """
        self.depth = self._depth * self.depth_scale * 1000 # depth scale to meter and 1000 to mm
        return self.depth

    def get_ir_frame_raw(self):
        """
        Args:
        Returns:
               2D Array of the shape(480, 640) containing the raw infrared intensity in (uint16) of the last frame
        """
        return self._ir

    def get_ir_frame(self, vmin=0, vmax=6000):
        """

        Args:
            min: minimum intensity value mapped to uint8 (will become 0) default: 0
            max: maximum intensity value mapped to uint8 (will become 255) default: 6000
        Returns:
               2D Array of the shape(480, 640) containing the infrared intensity between min and max mapped to uint8
               of the last frame
        """
        ir_frame_raw = self.get_ir_frame_raw()
        self.ir_frame = np.interp(ir_frame_raw, (vmin, vmax), (0, 255)).astype('uint8')
        return self.ir_frame

    def get_color(self):
        """
        Get the RGB image
        Returns:

        """
        self.color = self._color
        return self.color



================================================
FILE: sandbox/sensor/sensor_api.py
================================================
import os
import numpy
import scipy
import scipy.ndimage
from warnings import warn
import json
from sandbox import set_logger
logger = set_logger(__name__)

class Sensor:
    """
    Wrapping API-class
    """
    def __init__(self, calibsensor: str = None, name: str = 'kinect_v2', crop_values: bool = True,
                 clip_values: bool = True, gauss_filter: bool = True,
                 n_frames: int = 3, gauss_sigma: int = 3, invert: bool = True, **kwargs):
        """
        Sensor Api class to manage the different sensor for the frame adquisition
        Args:
            calibsensor: file path for the .json calibration file of the sensor
            name: type of sensor to use. Current ['kinect_v1', 'kinect_v2', 'lidar', 'dummy']. Predefined is 'kinect_v2'
            crop_values: to crop the frame according to the calibration file
            clip_values: clip the values to the maximum and minimum extent
            gauss_filter: apply a gaussian filter to the data
            n_frames: number of frames to get the average. Avoids anomalies
            gauss_sigma: How strong the filter is
            inverted: The data is measured from the sensor outwards. \
                        This will normalize the data according to the maximun value of the sensor
            **kwargs:
        """
        self.json_filename = calibsensor
        self.version = '2.1.s'
        if calibsensor is None:
            self.s_name = name
            self.s_top = 10
            self.s_right = 10
            self.s_bottom = 10
            self.s_left = 10
            self.s_min = 700
            self.s_max = 1500
            self.s_width = 512
            self.s_height = 424
            self.box_width = 1000
            self.box_height = 800
        else:
            self.load_json(calibsensor)

        if name == 'kinect_v1':
            from .kinectV1 import KinectV1
            try:
                import freenect
                self.Sensor = KinectV1()
            except ImportError:
                logger.warning('Kinect v1 dependencies are not installed', exc_info=True)
                raise ImportError('Kinect v1 dependencies are not installed')
        elif name == 'kinect_v2':
            from .kinectV2 import KinectV2, _platform
            try:
                if _platform == 'Windows':
                    import pykinect2
                elif _platform == 'Linux':
                    import freenect2
                self.Sensor = KinectV2()
            except ImportError:
                logger.warning('Kinect v2 dependencies are not installed', exc_info=True)
                raise ImportError('Kinect v2 dependencies are not installed')
        elif name == 'lidar':
            from .lidar_l515 import LiDAR
            try:
                import pyrealsense2
                self.Sensor = LiDAR()
            except ImportError:
                logger.warning('LiDAR dependencies are not installed', exc_info=True)
                raise ImportError('LiDAR dependencies are not installed')

        elif name == 'dummy':
            from .dummy import DummySensor
            self.Sensor = DummySensor(extent=self.extent, **kwargs)
        else:
            from .dummy import DummySensor
            logger.warning("Unrecognized sensor name. Activating dummy sensor")
            self.Sensor = DummySensor(extent=self.extent, **kwargs)

        # filter parameters
        self.filter = gauss_filter
        self.n_frames = n_frames
        self.sigma_gauss = gauss_sigma
        self.invert = invert

        self.s_name = self.Sensor.name
        self.s_width = self.Sensor.depth_width
        self.s_height = self.Sensor.depth_height
        self.depth = None
        self.crop = crop_values
        self.clip = clip_values
        self.get_frame()

    def get_raw_frame(self, gauss_filter: bool = True) -> numpy.ndarray:
        """Grab a new height numpy array

        With the Dummy sensor it will sample noise
        """
        # collect last n frames in a stack
        depth_array = self.Sensor.get_frame()
        for i in range(self.n_frames - 1):
            depth_array = numpy.dstack([depth_array, self.Sensor.get_frame()])
        # calculate mean values ignoring zeros by masking them
        depth_array_masked = numpy.ma.masked_where(depth_array == 0, depth_array)  # needed for V2?
        depth = numpy.ma.mean(depth_array_masked, axis=2)
        if gauss_filter:
            # apply gaussian filter
            depth = scipy.ndimage.filters.gaussian_filter(depth, self.sigma_gauss)
        else:
            depth = depth.data

        return depth

    def get_inverted_frame(self, frame):
        """
        Get the current frame and invert the values to get the normalized height,
        being the maximum value of the calibrated sensor data 0.
        Args:
            frame: Sensor frame to invert
        Returns:
            inverted frame
        """
        return self.s_max - frame

    # computed parameters for easy access
    @property
    def s_frame_width(self): return self.s_width - self.s_left - self.s_right

    @property
    def s_frame_height(self): return self.s_height - self.s_top - self.s_bottom

    def load_json(self, file: str):
        """
         Load a calibration file (.JSON format) and actualizes the panel parameters
         Args:
             file: address of the calibration to load

         Returns:

         """

        def json_load(dict_data):
            if dict_data['version'] == self.version:
                self.s_name = dict_data['s_name']
                self.s_top = dict_data['s_top']
                self.s_right = dict_data['s_right']
                self.s_bottom = dict_data['s_bottom']
                self.s_left = dict_data['s_left']
                self.s_min = dict_data['s_min']
                self.s_max = dict_data['s_max']
                self.s_width = dict_data["s_frame_width"] + dict_data['s_right'] + dict_data['s_left']
                self.s_height = dict_data["s_frame_height"] + dict_data['s_top'] + dict_data['s_bottom']
                self.box_width = dict_data['box_width']
                self.box_height = dict_data['box_height']
                logger.info("JSON configuration loaded for sensor.")
            else:
                logger.warning("JSON configuration incompatible."
                               "\nPlease select a valid calibration file or start a new calibration!")

        if os.path.isfile(file):
            with open(file) as calibration_json:
                data = json.load(calibration_json)
                json_load(data)
        else:
            data = json.loads(file)
            json_load(data)
        return True

    def save_json(self, file: str = 'sensor_calibration.json'):
        """
        Saves the current state of the sensor in a .JSON calibration file
        Args:
            file: address to save the calibration

        Returns:

        """
        with open(file, "w") as calibration_json:
            data = {"version": self.version,
                    "s_name": self.s_name,
                    "s_top": self.s_top,
                    "s_right": self.s_right,
                    "s_bottom": self.s_bottom,
                    "s_left": self.s_left,
                    "s_frame_width": self.s_frame_width,
                    "s_frame_height": self.s_frame_height,
                    "s_min": self.s_min,
                    "s_max": self.s_max,
                    "box_width": self.box_width,
                    "box_height": self.box_height}
            json.dump(data, calibration_json)
        logger.info('JSON configuration file saved: %s' % str(file))

    def crop_frame(self, frame: numpy.ndarray) -> numpy.ndarray:
        """ Crops the data frame according to the horizontal margins set up in the calibration
        """

        # TODO: Does not work yet for s_top = 0 and s_right = 0, which currently returns an empty frame!
        # TODO: Workaround: do not allow zeroes in calibration widget and use default value = 1
        # TODO: File numpy issue?
        crop = frame[self.s_bottom:-self.s_top, self.s_left:-self.s_right]
        return crop

    def crop_frame_workaround(self, frame: numpy.ndarray) -> numpy.ndarray:
        # bullet proof working example
        if self.s_top == 0 and self.s_right == 0:
            crop = frame[self.s_bottom:, self.s_left:]
        elif self.s_top == 0:
            crop = frame[self.s_bottom:, self.s_left:-self.s_right]
        elif self.s_right == 0:
            crop = frame[self.s_bottom:-self.s_top, self.s_left:]
        else:
            crop = frame[self.s_bottom:-self.s_top, self.s_left:-self.s_right]
        return crop

    def depth_mask(self, frame: numpy.ndarray) -> numpy.ndarray:
        """ Creates a boolean mask with True for all values within the set sensor range and False for every pixel
        above and below. If you also want to use clipping, make sure to use the mask before.
        """
        # TODO: depth mask is masking everything. returning empty
        mask = numpy.ma.getmask(numpy.ma.masked_outside(frame, self.s_min, self.s_max))
        return mask

    def clip_frame(self, frame: numpy.ndarray) -> numpy.ndarray:
        """ Clips all values outside of the sensor range to the set s_min and s_max values.
        If you want to create a mask make sure to call depth_mask before performing the clip.
        ???"""

        clip = numpy.clip(frame, self.s_min-1, self.s_max+1)
        return clip

    def get_frame(self) -> numpy.ndarray:
        frame = self.get_raw_frame(self.filter)
        if self.Sensor.name == "dummy":
            self.depth = frame
            return self.depth
        if self.crop:
            frame = self.crop_frame(frame)
        if self.clip:
            # frame = self.depth_mask(frame) #TODO: When is this needed?
            frame = self.clip_frame(frame)
        if self.invert:
            frame = self.get_inverted_frame(frame)
        self.depth = frame
        return self.depth

    @property
    def vmax(self):
        """return the maximum extent of the sensor according to the calibration file """
        return numpy.abs(self.s_max - self.s_min)

    @property
    def extent(self):
        """returns the extent in pixels used for the modules to indicate the dimensions of the plot in the sandbox
        [0, width_pixels, 0, height_pixels, 0, distance from maximum point of the sensor to the minimun
        point(total height in mm)] """
        return [0, self.s_frame_width, 0, self.s_frame_height, 0, self.vmax]

    @property
    def physical_dimensions(self):
        """returns the physical extent of the sandbox in mm. Used for scaling gempy models"""
        return [self.box_width, self.box_height]



================================================
FILE: sandbox/utils/__init__.py
================================================



================================================
FILE: sandbox/utils/download_sample_datasets.py
================================================
# %%
import os, sys
sys.path.append('.')
import pooch
from sandbox import _test_data, set_logger
from pooch import HTTPDownloader
download = HTTPDownloader(progressbar=True)
logger = set_logger(__name__)

#
# %%
parent_url = "https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC?path=%2F"
tests_url = "https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FTests&files="
tests = ["arucos.pkl",
         "frame1.npz",
         "frame2.npz",
         "frame3.npz",
         "frame4.npz"]

topomodule_url = "https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FTopoModule%2Fsaved_DEMs&files="
topomodule_files = ["1.npz",
                    "2.npz",
                    "3.npz",
                    "4.npz",
                    "DEM1.npz",
                    "DEM10.npz",
                    "DEM11.npz",
                    "DEM2.npz",
                    "DEM3.npz",
                    "DEM4.npz",
                    "DEM5.npz",
                    "DEM6.npz",
                    "DEM7.npz",
                    "DEM8.npz",
                    "DEM9.npz",
                    "Landslide_test_1.npz",
                    "bennisson_raster_DEM_04.npy",
                    "savedTopography.npz",
                    "test.npz"]

landslides_dems_url = "https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/" \
                      "download?path=%2FLanslideSimulation%2Fsaved_DEMs&files="
landslides_dems = ["Topography_0.npz",
                   "Topography_1.npz",
                   "Topography_2.npz",
                   "Topography_3.npz",
                   "Topography_4.npz"]
landslides_areas_url = "https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/" \
                       "download?path=%2FLanslideSimulation%2Fsaved_ReleaseAreas&files="
landslides_areas = ["ReleaseArea_0_1.npy",
                    "ReleaseArea_1_1.npy",
                    "ReleaseArea_1_2.npy",
                    "ReleaseArea_1_3.npy",
                    "ReleaseArea_2_1.npy",
                    "ReleaseArea_2_2.npy",
                    "ReleaseArea_2_3.npy",
                    "ReleaseArea_3_1.npy",
                    "ReleaseArea_3_2.npy",
                    "ReleaseArea_3_3.npy",
                    "ReleaseArea_4_1.npy",
                    "ReleaseArea_4_2.npy",
                    "ReleaseArea_4_3.npy",
                    ]
landslides_results_url = "https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/" \
                         "download?path=%2FLanslideSimulation%2Fsimulation_data&files="
landslides_results = ["Sim_Topo0_Rel01_results4sandbox.npz",
                      "Sim_Topo1_Rel11_results4sandbox.npz",
                      "Sim_Topo1_Rel12_results4sandbox.npz",
                      "Sim_Topo1_Rel13_results4sandbox.npz",
                      "Sim_Topo2_Rel21_results4sandbox.npz",
                      "Sim_Topo2_Rel22_results4sandbox.npz",
                      "Sim_Topo2_Rel23_results4sandbox.npz",
                      "Sim_Topo3_Rel31_results4sandbox.npz",
                      "Sim_Topo3_Rel32_results4sandbox.npz",
                      "Sim_Topo3_Rel33_results4sandbox.npz",
                      "Sim_Topo4_Rel41_results4sandbox.npz",
                      "Sim_Topo4_Rel42_results4sandbox.npz",
                      "Sim_Topo4_Rel43_results4sandbox.npz",
                      ]

landscape_models = ["Aletsch_1k",
                    "Aletsch_5k",
                    "AletschWin_3k",
                    "AletschWin_10k",
                    "Allgaeu_5k",
                    "AllgaeuSum_10k",
                    "AlpsSum1_1k",
                    "AlpsSum1_5k",
                    "AlpsSum1_10k",
                    "AlpsSum_3k",
                    "BernSum_5k",
                    "BernSum_10k",
                    "BernWin_5k",
                    "BernWin_10k"]
landscape_urls = ["https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FLandscapeGeneration"
                  + "%2F" + i + "&files=" for i in landscape_models]

landscape_data = ["latest_net_D.pth",
                  "latest_net_G.pth",
                  "loss_log.txt",
                  "test_opt.txt",
                  "train_opt.txt"]

# Benisson model
gempy_benisson_url = "https://rwth-aachen.sciebo.de/s/oKxBxb1oGW2ZsoC/download?path=%2FGempy%2FBenisson_model&files="
gempy_benisson = ["Benisson_04_elev_contours.dbf",
                  "Benisson_04_elev_contours.prj",
                  "Benisson_04_elev_contours.shp",
                  "Benisson_04_elev_contours.shx",
                  "Benisson_Map_04.png",
                  "extent.dbf",
                  "extent.prj",
                  "extent.shp",
                  "extent.shx",
                  "interfaces_point.dbf",
                  "interfaces_point.prj",
                  "interfaces_point.shp",
                  "interfaces_point.shx",
                  "orientation.dbf",
                  "orientation.prj",
                  "orientation.shp",
                  "orientation.shx"
                  ]

gempy_example_models_url = "https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/jan_models/"
gempy_example_models = ["model1_orientations.csv",
                        "model1_surface_points.csv",
                        "model2_orientations.csv",
                        "model2_surface_points.csv",
                        "model3_orientations.csv",
                        "model3_surface_points.csv",
                        "model4_orientations.csv",
                        "model4_surface_points.csv",
                        "model5_orientations.csv",
                        "model5_surface_points.csv",
                        "model6_orientations.csv",
                        "model6_surface_points.csv",
                        "model7_orientations.csv",
                        "model7_surface_points.csv"
                        ]
gempy_example_models_url2 = "https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/lisa_models/"
gempy_example_models2 = ["foliations7.csv",
                         "interfaces7.csv",
                         ]


def create_pooch(base_url, files, target):
    """
    Create POOCH class to fetch files from a website
    Args:
        base_url: Base URL for the remote data source.
        files: A record of the files that are managed by this Pooch.
        target: The path to the local data storage folder
    Returns:
        POOCH class
    """
    pc = pooch.create(base_url=base_url,
                      path=target,
                      registry={i: None for i in files})  # None because the Hash is always changing.. Sciebo problem?
    logger.info("Pooch created for url: %s" % base_url)
    return pc


def download_test_data():
    """
    Download all data for testing
    Returns:

    """
    try:
        pooch_data = create_pooch(tests_url, tests, _test_data.get("test"))
        for file in tests:
            pooch_data.fetch(file, downloader=download)
        logger.info("Data for testing downloaded")
    except Exception as e:
        logger.error(e, exc_info=True)


def download_topography_data():
    """
    Download all available DEMs to SaveTopoModule
    Returns:

    """
    try:
        pooch_topo = create_pooch(topomodule_url, topomodule_files, _test_data.get("topo"))
        for file in topomodule_files:
            pooch_topo.fetch(file, downloader=download)
        logger.info("Data for topography downloaded")
    except Exception as e:
        logger.error(e, exc_info=True)

def download_landslides_data():
    """Download all available to display the landslide simulations """
    try:
        pooch_landslides_dem = create_pooch(landslides_dems_url, landslides_dems, _test_data.get("landslide_topo"))
        pooch_landslides_area = create_pooch(landslides_areas_url, landslides_areas, _test_data.get("landslide_release"))
        pooch_landslides_sim = create_pooch(landslides_results_url, landslides_results,
                                            _test_data.get("landslide_simulation"))

        for file in landslides_dems:
            pooch_landslides_dem.fetch(file, downloader=download)
        for file in landslides_areas:
            pooch_landslides_area.fetch(file, downloader=download)
        for file in landslides_results:
            pooch_landslides_sim.fetch(file, downloader=download)
        logger.info("Data for landslides downloaded")
    except Exception as e:
        logger.error(e, exc_info=True)


def download_benisson_model():
    """Dowload data for construction of Benisson model with gempy"""
    try:
        pooch_gempy = create_pooch(gempy_benisson_url, gempy_benisson, _test_data.get("gempy_data"))
        for file in gempy_benisson:
            pooch_gempy.fetch(file, downloader=download)
        logger.info("Data for benisson model downloaded")
    except Exception as e:
        logger.error(e, exc_info=True)

def download_example_gempy_model():
    """Dowload data for construction of example models with gempy"""
    try:
        pooch_gempy_example = create_pooch(gempy_example_models_url, gempy_example_models, _test_data.get("gempy_example_data"))
        pooch_gempy_example2 = create_pooch(gempy_example_models_url2, gempy_example_models2, _test_data.get("gempy_example_data"))
        for file in gempy_example_models:
            pooch_gempy_example.fetch(file, downloader=download)
        for file in gempy_example_models2:
            pooch_gempy_example2.fetch(file, downloader=download)
        logger.info("Data for gempy example models downloaded")
    except Exception as e:
        logger.error(e, exc_info=True)

def download_landscape_name(name_model: str):
    """Download an specific trained model"""
    try:
        if name_model not in landscape_models:
            logger.warning("\n Model with name '%s' not available for download. "
                            "\n Available models are %s" % (name_model, str(landscape_models)))
            return False

        loc_dir = _test_data.get("landscape_generation") + "checkpoints" + os.sep + name_model
        if not os.path.isdir(loc_dir):
            os.mkdir(loc_dir)

        pos = [i for i in range(len(landscape_models)) if name_model == landscape_models[i]][0]
        pooch_landscape = create_pooch(landscape_urls[pos], landscape_data, loc_dir)

        for file in landscape_data:
            pooch_landscape.fetch(file, downloader=download)
        logger.info("Model %s downloaded for landscape generation" % name_model)

    except Exception as e:
        logger.error(e, exc_info=True)

def download_landscape_all():
    """Download all trained models available"""
    for name_model in landscape_models:
        download_landscape_name(name_model)


#%%
if __name__ == '__main__':
    if input("Do you want to download the genpy data for the example models? (12 kB) [y/n]") == "y":
        download_example_gempy_model()

    if input("Do you want to download the Test data? (25.4 MB) [y/n]") == "y":
        download_test_data()

    if input("Do you want to download some DEMs to the SaveLoadModule? (24 MB) [y/n]") == "y":
        download_topography_data()

    if input("Do you want to download the Landslide data to the LandslideModule? (114 MB) [y/n]") == "y":
        download_landslides_data()

    if input("Do you want to download the Gempy data for the Benisson Model? (1.2 MB) [y/n]") == "y":
        download_benisson_model()

    if input("Do you want to download all the Trained models for the LandscapeGeneration module? (3 GB) [y/n]") == \
            "y":
        if input("Are you sure? All of them? It is 3 GB of data [y/n]") == "y":
            download_landscape_all()
    while True:
        if input("Do you want to download an specific Trained model? [y/n]") == "y":
            print("Available models: %s" % landscape_models)
            model = input("Name of model to download:")
            download_landscape_name(model)
        else:
            break



================================================
FILE: sandbox/utils/logger.py
================================================
from sandbox import _package_dir
import sys
import logging
import logging.config
from typing import Optional, Dict
from colorama import Fore, Back, Style

# Record the logger of all the packages for debugging and error handling
verbose = False
if verbose:
    logging.basicConfig(filename=_package_dir+"/../main.log",
                        filemode='w',
                        level=logging.INFO,
                        format='%(asctime)s | %(name)s | %(levelname)s | %(message)s',
                        #datefmt='%Y/%m/%d %I:%M:%S %p'
                        )

class ColoredFormatter(logging.Formatter):
    """Colored log formatter."""

    def __init__(self, *args, colors: Optional[Dict[str, str]] = None, **kwargs) -> None:
        """Initialize the formatter with specified format strings."""

        super().__init__(*args, **kwargs)

        self.colors = colors if colors else {}

    def format(self, record) -> str:
        """Format the specified record as text."""

        record.color = self.colors.get(record.levelname, '')
        record.reset = Style.RESET_ALL

        return super().format(record)


formatter = ColoredFormatter(
    '{color}{name:10}: {levelname}{reset} | {message}',
    style='{',
    # datefmt='%Y-%m-%d %H:%M:%S',
    colors={
        'DEBUG': Fore.CYAN,
        'INFO': Fore.GREEN,
        'WARNING': Fore.YELLOW,
        'ERROR': Fore.RED,
        'CRITICAL': Fore.RED + Back.WHITE + Style.BRIGHT,
    }
)

# Get the root formatter
logger = logging.getLogger("sandbox")
logger.setLevel(logging.DEBUG)

fh = logging.FileHandler(_package_dir+'.log', mode='w')
frm = logging.Formatter('%(asctime)s | %(name)-18s | %(levelname)-8s | %(message)s')
fh.setFormatter(frm)
fh.setLevel(logging.DEBUG)
logger.addHandler(fh)


# create console handler
console = logging.StreamHandler(sys.stdout)
console.setLevel(logging.DEBUG)
# create formatter and add it to the handlers
console.setFormatter(formatter)
# add the handlers to the logger
logger.addHandler(console)


def set_logger(name, level = logging.DEBUG):
    """
    Create a new handle in any destination
    Args:
        name: name of new handle
    Returns:
    """
    if name[:8] != "sandbox.":
        name = "sandbox."+name
    if not logging.getLogger(name).hasHandlers():
        logging.getLogger(name).addHandler(name)

    log = logging.getLogger(name)
    log.setLevel(level)
    return log

def set_level():
    pass



================================================
FILE: tests/__init__.py
================================================



================================================
FILE: tests/conftest.py
================================================
import matplotlib.pyplot as plt
import pytest
import numpy as np
import pandas as pd

@pytest.fixture()
def data_files():
    from sandbox import _test_data
    return _test_data

@pytest.fixture()
def sb_params(data_files):
    df = pd.read_pickle(data_files['test']+"arucos.pkl")
    file = np.load(data_files['topo'] + "DEM1.npz")
    frame = file['arr_0']
    frame = frame + np.abs(np.amin(frame))
    extent = [0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()]

    fig, ax = plt.subplots()
    return  {'frame': frame,
                      'ax': ax,
                        'fig': fig,
                      'set_colorbar': None, #self.projector.set_colorbar,
                      'set_legend': None, #self.projector.set_legend,
                      'extent': extent,
                      'box_dimensions': None, #self.sensor.physical_dimensions,
                      'marker': df,
                      'cmap': plt.cm.get_cmap('gist_earth'),
                      'norm': None,
                      'active_cmap': True,
                      'active_shading': True,
                      'active_contours': True,
                      'same_frame': False,
                      'lock_thread': None, #self.lock,
                      'trigger': None, #self.projector.trigger,
                      'del_contour': True, }







================================================
FILE: tests/test_download_sample_data.py
================================================
from sandbox.utils.download_sample_datasets import *
cache = pooch.os_cache("sandbox")

def test_download_test_data():
    pooch_data = create_pooch(tests_url, tests, cache)
    for file in tests:
        pooch_data.fetch(file, downloader=download)

def test_download_savetopo():
    pooch_topo = create_pooch(topomodule_url, topomodule_files, cache)
    for file in topomodule_files:
        pooch_topo.fetch(file, downloader=download)

def test_download_landslides():
    pooch_landslides_dem = create_pooch(landslides_dems_url, landslides_dems, cache)
    pooch_landslides_area = create_pooch(landslides_areas_url, landslides_areas, cache)
    pooch_landslides_sim = create_pooch(landslides_results_url, landslides_results, cache)

    for file in landslides_dems:
        pooch_landslides_dem.fetch(file, downloader=download)
    for file in landslides_areas:
        pooch_landslides_area.fetch(file, downloader=download)
    for file in landslides_results:
        pooch_landslides_sim.fetch(file, downloader=download)

def test_download_gempy():
    pooch_gempy = create_pooch(gempy_benisson_url, gempy_benisson, cache)
    for file in gempy_benisson:
        pooch_gempy.fetch(file, downloader=download)

def test_download_landscape():
    del landscape_data[1] # The most heavy file
    for name_model in landscape_models:

        pos = [i for i in range(len(landscape_models)) if name_model == landscape_models[i]][0]
        pooch_landscape = create_pooch(landscape_urls[pos], landscape_data, pooch.os_cache("sandbox/"+name_model))

        for file in landscape_data:
            pooch_landscape.fetch(file, downloader=download)


================================================
FILE: tests/test_main_thread.py
================================================
from sandbox import _test_data as test_data
from sandbox.main_thread import MainThread
from sandbox.projector import Projector
from sandbox.sensor import Sensor
import matplotlib.pyplot as plt
import numpy as np

file = np.load(test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
frame = frame + np.abs(frame.min())
extent = np.asarray([0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()])

projector = Projector(use_panel=False)
sensor = Sensor(name='dummy')

def test_init():
    smain = MainThread(sensor, projector)
    print(smain)

def test_update():
    projector_2 = Projector(use_panel=True)
    sensor_2 = Sensor(name='dummy')
    smain = MainThread(sensor_2, projector_2)
    smain.update()

def test_run(): #TODO: runs but does not show contour lines
    projector_2 = Projector(use_panel=True)
    sensor_2 = Sensor(name='dummy')
    smain = MainThread(sensor_2, projector_2)
    smain.run()

def test_thread_functions():
    smain = MainThread(sensor, projector)
    smain.run()
    print('run() working')
    smain.pause()
    print('pause() working')
    smain.resume()
    print('resume() working')
    smain.stop()
    print('stop() working')

def test_thread_kinectv2():
    from sandbox import _calibration_dir
    from sandbox.markers import MarkerDetection
    projector_2 = Projector(use_panel=True)
    sensor_2 = Sensor(name='kinect_v2', calibsensor=_calibration_dir+'my_sensor_calibration.json')
    aruco = MarkerDetection(sensor=sensor_2)
    smain = MainThread(sensor_2, projector_2, aruco)
    smain.sb_params['active_contours'] = True
    smain.sb_params['active_cmap'] = True
    smain.run()

def test_thread_module():
    from sandbox.modules import TopoModule, GradientModule
    proj = Projector(use_panel=True)
    sens = Sensor(name='kinect_v2', invert=True)
    smain = MainThread(sens, proj)

    topo = TopoModule(extent=sens.extent)
    grad = GradientModule(extent=sens.extent)

    smain.modules = [topo]
    smain.run()

def test_bug_no_dpi():
    from sandbox import _calibration_dir
    _calibprojector = _calibration_dir + "my_projector_calibration.json"
    _calibsensor = _calibration_dir + "my_sensor_calibration.json"
    from sandbox.sensor import Sensor
    sensor = Sensor(calibsensor=_calibsensor, name="kinect_v2")
    from sandbox.projector import Projector
    projector = Projector(calibprojector=_calibprojector)
    # Initialize the aruco detection
    from sandbox.markers import MarkerDetection
    aruco = MarkerDetection(sensor=sensor)
    from sandbox.main_thread import MainThread
    main = MainThread(sensor=sensor, projector=projector, aruco=aruco)
    # Start the thread
    main.run()
    #main.ARUCO_ACTIVE = False

def test_bug_no_dpi_no_aruco():
    #import matplotlib.text
    from sandbox import _calibration_dir
    _calibprojector = _calibration_dir + "my_projector_calibration.json"
    _calibsensor = _calibration_dir + "my_sensor_calibration.json"
    from sandbox.sensor import Sensor
    sensor = Sensor(calibsensor=_calibsensor, name="dummy")
    from sandbox.projector import Projector
    projector = Projector(calibprojector=_calibprojector, use_panel = False)
    # Initialize the aruco detection
    from sandbox.main_thread import MainThread
    main = MainThread(sensor=sensor, projector=projector)
    # Start the thread
    main.update()
    projector.trigger()

def test_with_gempy():
    from sandbox import _calibration_dir, _test_data
    file = np.load(_test_data['topo'] + "DEM1.npz")
    frame = file['arr_0']
    frame = frame + np.abs(frame.min())

    _calibprojector = _calibration_dir + "my_projector_calibration.json"
    _calibsensor = _calibration_dir + "my_sensor_calibration.json"
    from sandbox.sensor import Sensor
    sensor = Sensor(calibsensor=_calibsensor, name="dummy")
    from sandbox.projector import Projector
    projector = Projector(calibprojector=_calibprojector)
    # Initialize the aruco detection
    from sandbox.main_thread import MainThread
    mainT = MainThread(sensor=sensor, projector=projector)
    mainT.load_frame(frame)
    # Start the thread
    #mainT.run()
    from sandbox.modules.gempy import GemPyModule
    gpsb = GemPyModule(geo_model=None,
                       extent=sensor.extent,
                       box=sensor.physical_dimensions,
                       load_examples=True,
                       name_example=['Fault'])
    mainT.add_module(name='gempy', module=gpsb)
    mainT.update()

def test_check_frame():
    from sandbox import _calibration_dir
    _calibprojector = _calibration_dir + "my_projector_calibration.json"
    _calibsensor = _calibration_dir + "my_sensor_calibration.json"
    from sandbox.sensor import Sensor
    sensor = Sensor(calibsensor=_calibsensor, name="dummy")
    frame1 = sensor.get_frame()
    frame2 = sensor.get_frame()
    _rtol = 0.2
    _atol = 5
    cl = np.isclose(frame1, frame2,_rtol, _atol)
    frame1[np.logical_not(cl)] = frame2[np.logical_not(cl)]

def test_topo_module():
    from sandbox import _calibration_dir, _test_data
    file = np.load(_test_data['topo'] + "DEM1.npz")
    frame = file['arr_0']
    frame = frame + np.abs(frame.min())

    _calibprojector = _calibration_dir + "my_projector_calibration.json"
    _calibsensor = _calibration_dir + "my_sensor_calibration.json"
    from sandbox.sensor import Sensor
    sensor = Sensor(calibsensor=_calibsensor, name="dummy")
    from sandbox.projector import Projector
    projector = Projector(calibprojector=_calibprojector)
    # Initialize the aruco detection
    from sandbox.main_thread import MainThread
    mainT = MainThread(sensor=sensor, projector=projector)
    mainT.load_frame(frame)

    # Start the thread
    #mainT.run()
    from sandbox.modules import TopoModule
    module = TopoModule(extent = extent)
    mainT.add_module(name='Topo', module=module)
    module.sea = True
    module.sea_contour = True
    mainT.update()



================================================
FILE: tests/test_projector.py
================================================
from sandbox.projector import Projector
from sandbox import _test_data
calib_dir = _test_data['test'] + 'temp/'
import matplotlib.pyplot as plt
import numpy as np

file = np.load(_test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
extent = np.asarray([0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()])


def test_init_projector():
    projector = Projector(use_panel=False)
    assert projector.panel is not None

def test_save_load_calibration_projector():
    projector = Projector(use_panel=False)
    file = calib_dir + 'test_projector_calibration.json'
    projector.save_json(file=file)
    # now to test if it loads correctly the saved one
    projector2 = Projector(calibprojector = file, use_panel=False)

def test_open_panel_browser():
    projector = Projector(use_panel=False)
    projector.start_server()

def test_trigger():
    projector = Projector(use_panel=True)
    projector.ax.plot([10, 20, 30], [20, 39, 48])
    projector.trigger()

def test_delete_ax_image():
    projector = Projector(use_panel=False)
    projector.ax.plot([10, 20, 30], [20, 39, 48])
    projector.clear_axes()

def test_delete_points():
    projector = Projector(use_panel=False)
    line1 = projector.ax.plot([10, 20, 30], [20, 39, 48])
    projector.trigger()
    del line1
    projector.trigger()


def test_change_betweeen_axes():
    """Not the way to go"""
    fig_supl, ax_supl = plt.subplots()
    ax_supl.set_axis_off()
    ax_supl.pcolormesh(frame)
    fig_supl.show()

    fig, ax = plt.subplots()
    ax.set_axis_off()
    ax.plot([10, 50, 100], [10, 50, 100], 'k.')
    fig.show()

    ax.add_child_axes(ax_supl)
    fig.show()

    print(ax.child_axes)

    del ax.child_axes[0]
    fig.show()


def test_change_betweeen_axes2():
    """Show that cannot be done this way"""
    fig_supl, ax_supl = plt.subplots()
    ax_supl.set_axis_off()

    fig, ax = plt.subplots()
    ax.set_axis_off()

    ax_supl.cla()
    # ax.add_child_axes(ax_supl)
    fig.show()

    ax.pcolormesh(frame)
    fig.show()

    ax_supl.plot([10, 50, 100], [10, 50, 100], 'k.')
    fig.show()


def test_erase_axes_figure():
    figure, ax = plt.subplots()
    ax.set_axis_off()
    col = ax.pcolormesh(frame)
    figure.show()
    line, = ax.plot([10, 50, 100], [10, 50, 100], 'k.')
    figure.show()
    line.remove()
    figure.show()
    col.remove()
    figure.show()
    ax.plot([10,20],[10,201])
    figure.show()

def test_widgets_calibration():
    projector = Projector(use_panel=True)
    widget = projector.calibrate_projector()
    widget.show()

    projector2 = Projector(calibprojector=calib_dir + 'test_projector_calibration.json', use_panel=True)
    widget2 = projector2.calibrate_projector()
    widget2.show()




================================================
FILE: tests/test_modules/__init__.py
================================================



================================================
FILE: tests/test_modules/gempy_models_script.py
================================================
import gempy as gp
from sandbox.modules.gempy.gempy_module import *


create_model_dict(model_name = ["Fault"])




================================================
FILE: tests/test_modules/test_cmap.py
================================================
from sandbox import _test_data as test_data
from sandbox.projector import CmapModule
import numpy as np

file = np.load(test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
extent = np.asarray([0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()])

import matplotlib.pyplot as plt


def test_init():
    module = CmapModule(extent=extent)
    print(module)

def test_render_frame():
    module = CmapModule(extent=extent)
    fig, ax = plt.subplots()
    module.render_frame(frame, ax)
    fig.show()

def test_change_cmap():
    module = CmapModule(extent=extent)
    fig1, ax1 = plt.subplots()
    module.render_frame(frame, ax1)
    fig1.show()
    cmap = plt.cm.get_cmap('Accent_r')
    fig2, ax2 = plt.subplots()
    module.set_cmap(cmap)
    module.render_frame(frame, ax2)
    fig2.show()

def test_change_array():
    fig, ax = plt.subplots()
    col = ax.imshow(frame)
    fig.show()

    file = np.load(test_data['topo'] + "DEM2.npz")
    frame2 = file['arr_0']
    col.set_array(frame2)
    fig.show()

def test_change_cmap():
    fig, ax = plt.subplots()
    col = ax.imshow(frame)
    fig.show()

    cmap = plt.cm.get_cmap("hot")
    col.set_cmap(cmap)
    fig.show()

def test_delete_image():
    module = CmapModule(extent=extent)
    fig, ax = plt.subplots()
    module.render_frame(frame, ax)
    fig.show()

    module.delete_image()
    fig.show()

def test_update():
    module = CmapModule(extent=extent)
    fig, ax = plt.subplots()
    module.render_frame(frame, ax)
    sb_params = {'frame': frame,
                 'ax': ax,
                 'extent': extent,
                 'marker': [],
                 'cmap': plt.cm.get_cmap('viridis'),
                 'norm': None,
                 'active_cmap': True,
                 'active_contours': True}
    sb_params = module.update(sb_params)
    fig.show()

def test_widgets():
    module = CmapModule(extent=extent)
    widget = module.show_widgets()
    widget.show()



================================================
FILE: tests/test_modules/test_contour.py
================================================
from sandbox import _test_data as test_data

from sandbox.projector import ContourLinesModule

import numpy as np
file = np.load(test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
extent = np.asarray([0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()])

import matplotlib.pyplot as plt
import pytest
fig, ax = plt.subplots()
pytest.sb_params = {'frame': frame,
                 'ax': ax,
                 'extent': extent,
                 'marker': [],
                 'cmap': plt.cm.get_cmap('viridis'),
                 'norm': None,
                 'active_cmap': True,
                 'active_contours': True,
                    'same_frame':True}

def test_init():
    module = ContourLinesModule(extent=extent)
    print(module)


def test_generating_all():
    module = ContourLinesModule(extent=extent)

    fig, ax = plt.subplots()
    module.plot_contour_lines(frame, ax)
    fig.show()

def test_update_array():
    module = ContourLinesModule(extent=extent)
    fig, ax = plt.subplots()
    module.plot_contour_lines(frame, ax)
    fig.show()
    module.delete_contourns(ax)
    file = np.load(test_data['topo'] + "DEM2.npz")
    frame2 = file['arr_0']
    module.plot_contour_lines(frame2, ax)
    fig.show()

def test_delete_contours():
    module = ContourLinesModule(extent=extent)
    fig, ax = plt.subplots()
    module.plot_contour_lines(frame, ax)
    fig.show()
    module.delete_contourns(ax)
    fig.show()

def test_update():
    module = ContourLinesModule(extent=extent)
    fig, ax = plt.subplots()

    sb_params = module.update(pytest.sb_params)
    fig.show()

def test_create_widgets_plot():
    module = ContourLinesModule(extent=extent)
    widget = module.show_widgets()
    widget.show()





================================================
FILE: tests/test_modules/test_gempy.py
================================================
import os
import gempy as gp
os.environ["THEANO_FLAGS"] = "mode=FAST_RUN"
from sandbox import _test_data as test_data
from sandbox.modules import GemPyModule
from sandbox.modules.gempy.example_models import *
import matplotlib.pyplot as plt
import pytest
import numpy as np

file = np.load(file=test_data['topo'] + "DEM4.npz", allow_pickle=True)#, encoding='bytes', allow_pickle=False)
frame = (file['arr_0'] - np.max(file["arr_0"]))*-1
extent = [0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()]

fig, ax = plt.subplots()
pytest.sb_params = {'frame': frame,
                    'ax': ax,
                    'fig': fig,
                    'extent': extent,
                    'marker': [],
                    'cmap': plt.cm.get_cmap('viridis'),
                    'norm': None,
                    'active_cmap': True,
                    'active_contours': True}


def test_scale():
    from sandbox.modules.gempy.utils import get_scale
    sca = get_scale(physical_extent=[1000, 800],
                model_extent=[0, 1000, 0, 1000, 0, 2300],
                sensor_extent=extent)
    print(sca)


def test_grid():
    from sandbox.modules.gempy.utils import Grid
    grid = Grid(physical_extent=[1000, 800],
                model_extent=[0, 1000, 0, 1000, 0, 2300],
                sensor_extent=extent,
                scale=None)
    grid.update_grid(frame)
    print(grid.depth_grid)

def test_create_model():
    geo_model = create_example_model(name = 'Horizontal_layers')
    print(geo_model)

def test_create_model_predefined():
    model_dict = create_model_dict(all_models)
    print(model_dict)

def test_init_examples():
    module = GemPyModule(geo_model=None, extent=extent, box=[1000, 800], load_examples=True)
    print(module)
    print(module.model_dict.keys())

def test_load_geomodel_from_examples():
    module = GemPyModule(geo_model=None, extent=extent, box=[1000, 800],
                         load_examples=True, name_example=["Anticline", "Horizontal_layers"])
    print(module.geo_model)
    print(module.model_dict.keys())

def test_init():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model = geo_model, extent=extent, box=[1000, 800], load_examples=False)
    print(module)

def test_update():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model = geo_model, extent=extent, box=[1000, 800], load_examples=False)
    module.show_boundary = True
    module.show_lith = False
    module.show_hillshades = True
    module.show_contour = True
    module.show_fill_contour = True

    sb_params = module.update(pytest.sb_params)
    sb_params['fig'].show()

def test_change_model():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model = geo_model, extent=extent, box=[1000, 800], load_examples=False)
    sb_params = module.update(pytest.sb_params)
    sb_params['fig'].show()

    geo_model2 = create_example_model('Fault')
    module.change_model(geo_model2)
    sb_params = module.update(pytest.sb_params)
    sb_params['fig'].show()

def test_section_dictionaries_cross_section():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model=geo_model, extent=extent, box=[1000, 800], load_examples=False)
    module.setup(frame)
    module.set_section_dict((10, 10), (500, 500), "Section1")
    module.set_section_dict((100, 100), (500, 10), "Section2")
    module.show_actual_model()

    assert module.section_dict == {'Model: Horizontal_layers': ([0.0, 500.0], [1000.0, 500.0], [150, 100]),
                                   'Section1': ([10, 10], [500, 500], [150, 100]),
                                   'Section2': ([100, 100], [500, 10], [150, 100]),
                                   }

    module.remove_section_dict("Section2")

    assert module.section_dict == {'Model: Horizontal_layers': ([0.0, 500.0], [1000.0, 500.0], [150, 100]),
                                   'Section1': ([10, 10], [500, 500], [150, 100])}

def test_plot_cross_sections():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model=geo_model, extent=extent, box=[1000, 800], load_examples=False)
    sb_params = module.update(pytest.sb_params)
    sb_params['fig'].show()
    module.set_section_dict((10, 10), (500, 500), "Section1")
    module.set_section_dict((100, 100), (500, 10), "Section2")
    module.show_actual_model()
    module.show_section_traces()
    module.show_cross_section("Section1")
    module.show_cross_section("Section2")
    module.show_geological_map()

def test_borehole_dict():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model=geo_model, extent=extent, box=[1000, 800], load_examples=False)
    module.setup(frame)

    module.set_borehole_dict((10,20), "borehole1")
    module.set_borehole_dict((500, 500), "borehole2")

    print(module.borehole_dict)

    assert module.borehole_dict == {'borehole1': ([10, 20], [11, 20], [5, 5]),
                                   'borehole2': ([500, 500], [501, 500], [5, 5])}

    module.remove_borehole_dict("borehole2")

    print(module.borehole_dict)

    assert module.borehole_dict == {'borehole1': ([10, 20], [11, 20], [5, 5])}

def test_polygon_data_boreholes():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model=geo_model, extent=extent, box=[1000, 800], load_examples=False)
    module.setup(frame)

    module.set_borehole_dict((10, 20), "borehole1")
    module.set_borehole_dict((500, 500), "borehole2")

    module._get_polygon_data()

    print(module.borehole_tube, module.colors_bh)

def test_plot_boreholes():
    #geo_model = create_example_model('Fault')
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model=geo_model, extent=extent, box=[1000, 800], load_examples=False)
    module.setup(frame)

    module.set_borehole_dict((10, 20), "borehole1")
    module.set_borehole_dict((200, 500), "borehole2")
    module.set_borehole_dict((500, 500), "borehole3")
    module.set_borehole_dict((900, 500), "borehole4")
    module.set_borehole_dict((100, 100), "borehole5")
    module.set_borehole_dict((600, 700), "borehole6")
    module.set_borehole_dict((200, 150), "borehole7")
    module.set_borehole_dict((150, 200), "borehole8")

    module._get_polygon_data()

    p = module.plot_boreholes(notebook=False, background=False)
    p.show()

def test_compute_model_space_arucos():
    from sandbox.sensor import Sensor
    from sandbox.markers import MarkerDetection
    from sandbox import _calibration_dir, _test_data
    sensor = Sensor(calibsensor=_calibration_dir + 'sensorcalib.json', name='kinect_v2')
    aruco = MarkerDetection(sensor=sensor)
    color = np.load(_test_data['test'] + 'frame1.npz')['arr_1']
    module = GemPyModule(geo_model=None, extent=sensor.extent, box=[1000, 800], load_examples=True,
                         name_example=['Horizontal_layers'])
    module.setup(sensor.get_frame())
    df = aruco.update(frame=color)
    df_new = module._compute_modelspace_arucos(df)
    print(df_new)

def test_set_aruco_dict():
    from sandbox.sensor import Sensor
    from sandbox.markers import MarkerDetection
    from sandbox import _calibration_dir, _test_data
    sensor = Sensor(calibsensor=_calibration_dir + 'sensorcalib.json', name='kinect_v2')
    aruco = MarkerDetection(sensor=sensor)
    color = np.load(_test_data['test'] + 'frame1.npz')['arr_1']
    module = GemPyModule(geo_model=None, extent=sensor.extent, box=[1000, 800], load_examples=True,
                         name_example=['Horizontal_layers'])
    module.setup(sensor.get_frame())
    df = aruco.update(frame=color)
    df_new = module._compute_modelspace_arucos(df)
    module.set_aruco_dict(df_new)

    print(module.model_sections_dict)

def test_update_arucos():
    from sandbox.sensor import Sensor
    from sandbox.markers import MarkerDetection
    from sandbox import _calibration_dir, _test_data
    sensor = Sensor(calibsensor=_calibration_dir + 'sensorcalib.json', name='kinect_v2', invert=False)
    aruco = MarkerDetection(sensor=sensor)
    color = np.load(_test_data['test'] + 'frame1.npz')['arr_1']
    module = GemPyModule(geo_model=None, extent=sensor.extent, box=[1000, 800], load_examples=True,
                         name_example=['Horizontal_layers'])
    sb_params = pytest.sb_params
    sb_params['frame'] = sensor.get_frame()
    module.setup(sb_params['frame'])
    sb_params['marker']= aruco.update(frame=color)

    sb_params = module.update(sb_params)
    sb_params['fig'].show()
    aruco.plot_aruco(sb_params['ax'], sb_params['marker'])
    fig.show()

def test_show_plot_widgets():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model=geo_model, extent=extent, box=[1000, 800], load_examples=False)
    sb_params = module.update(pytest.sb_params)
    sb_params['fig'].show()
    module.set_section_dict((10, 10), (500, 500), "Section1")
    module.set_section_dict((100, 100), (500, 10), "Section2")
    module.show_actual_model()

    module.show_section_traces()

    module.show_cross_section("Section1")

    module.show_geological_map()

    module.panel_actual_model.show()
    module.panel_plot_2d.show()
    module.panel_section_traces.show()
    module.panel_geo_map.show()

def test_3d_model_plot():
    module = GemPyModule(geo_model=None, extent=extent, box=[1000, 800], load_examples=True,
                         name_example=['Horizontal_layers'])
    module.setup(frame)
    geo_3d = module.plot_3d_model()
    geo_3d.p.show()

def test_3d_model_plot_widget():
    module = GemPyModule(geo_model=None, extent=extent, box=[1000, 800], load_examples=True,
                         name_example=['Horizontal_layers'])
    module.setup(frame)
    #module._plotter_type = 'background'
    vtk = module.show_3d_model_panel()
    vtk.show()

def test_3d_widgets():
    module = GemPyModule(geo_model=None, extent=extent, box=[1000, 800], load_examples=True,
                         name_example=['Horizontal_layers'])
    module.setup(frame)
    widget = module.widget_3d_model()
    widget.show()

def test_update_borehole_panel():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model=geo_model, extent=extent, box=[1000, 800], load_examples=False)
    module.setup(frame)

    module.set_borehole_dict((10, 20), "borehole1")
    module.set_borehole_dict((200, 500), "borehole2")
    module.set_borehole_dict((500, 500), "borehole3")
    module.set_borehole_dict((900, 500), "borehole4")
    module.set_borehole_dict((100, 100), "borehole5")
    module.set_borehole_dict((600, 700), "borehole6")
    module.set_borehole_dict((200, 800), "borehole7")
    module.set_borehole_dict((800, 200), "borehole8")

    module._get_polygon_data()

    vtk = module.show_boreholes_panel()
    vtk.show()

def test_widgets():
    module = GemPyModule(geo_model=None, extent=extent, box=[1000, 800], load_examples=True)
    module.setup(frame)

    #fig, ax = plt.subplots()
    #depth, ax, size, cmap, norm, df = module.update(frame, ax, extent)
    module.setup(frame)

    module.set_section_dict((10, 10), (500, 500), "Section1")
    module.set_section_dict((100, 100), (500, 10), "Section2")

    module.set_borehole_dict((500, 500), "borehole3")
    module.set_borehole_dict((900, 500), "borehole4")

    widgets = module.show_widgets()

    widgets.show()

def test_cross_section_widgets():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model=geo_model, extent=extent, box=[1000, 800], load_examples=False)
    module.setup(frame)
    module.set_section_dict((10, 10), (500, 500), "Section1")
    module.set_section_dict((100, 100), (500, 10), "Section2")
    widget=module.widget_cross_sections()
    widget.show()

def test_borehole_widgets():
    geo_model = create_example_model('Horizontal_layers')
    module = GemPyModule(geo_model=geo_model, extent=extent, box=[1000, 800], load_examples=False)
    module.setup(frame)
    module.set_borehole_dict((500, 500), "borehole3")
    module.set_borehole_dict((900, 500), "borehole4")
    module._get_polygon_data()
    widget = module.widget_boreholes()
    widget.show()

def test_widgets_with_arucos():
    from sandbox.sensor import Sensor
    from sandbox.markers import MarkerDetection
    from sandbox import _calibration_dir, _test_data
    sensor = Sensor(calibsensor=_calibration_dir + 'sensorcalib.json', name='kinect_v2')
    aruco = MarkerDetection(sensor=sensor)
    color = np.load(_test_data['test'] + 'frame1.npz')['arr_1']
    geo_model = create_example_model(name='Anticline')
    module = GemPyModule(geo_model=geo_model, extent=sensor.extent, box=[1000, 800], load_examples=True,
                         name_example=['Horizontal_layers'])
    module.setup(sensor.get_frame())
    pytest.sb_params['marker'] = aruco.update(frame=color)
    sb_params = module.update(pytest.sb_params)
    sb_params['fig'].show()
    module.set_section_dict((10, 10), (500, 500), "Section1")
    module.set_section_dict((100, 100), (500, 10), "Section2")

    module.set_borehole_dict((500, 500), "borehole3")
    module.set_borehole_dict((900, 500), "borehole4")
    module._get_polygon_data()
    aruco.plot_aruco(sb_params['ax'], sb_params['marker'])
    sb_params['fig'].show()
    widgets = module.show_widgets()
    widgets.show()

def test_gempy_imshow_plotting():
    geo_model = create_example_model(name='Anticline')
    gp.compute_model(geo_model)
    gp.plot_2d(geo_model)

def test_complex_model():
    geo_model = gp.create_model('Geological_Model1')
    geo_model = gp.init_data(geo_model, extent=[0, 4000, 0, 2775, 200, 1500], resolution=[100, 10, 100])
    gp.set_interpolator(geo_model, theano_optimizer='fast_run', verbose=[])
    geo_model.add_features(['Fault2', 'Cycle2', 'Fault1', 'Cycle1'])
    geo_model.delete_features('Default series')
    geo_model.add_surfaces(['F2', 'H', 'G', 'F1', 'D', 'C', 'B', 'A'])
    gp.map_stack_to_surfaces(geo_model, {'Fault1': 'F1', 'Fault2': 'F2', 'Cycle2': ['G', 'H']})
    geo_model.set_is_fault(['Fault1', 'Fault2'])

    ###Cycle 1
    # surface B - before F1
    geo_model.add_surface_points(X=584, Y=285, Z=500, surface='B')
    geo_model.add_surface_points(X=494, Y=696, Z=500, surface='B')
    geo_model.add_surface_points(X=197, Y=1898, Z=500, surface='B')
    geo_model.add_surface_points(X=473, Y=2180, Z=400, surface='B')
    geo_model.add_surface_points(X=435, Y=2453, Z=400, surface='B')
    # surface C - before F1
    geo_model.add_surface_points(X=946, Y=188, Z=600, surface='C')
    geo_model.add_surface_points(X=853, Y=661, Z=600, surface='C')
    geo_model.add_surface_points(X=570, Y=1845, Z=600, surface='C')
    geo_model.add_surface_points(X=832, Y=2132, Z=500, surface='C')
    geo_model.add_surface_points(X=767, Y=2495, Z=500, surface='C')
    # Surface D - Before F1
    geo_model.add_surface_points(X=967, Y=1638, Z=800, surface='D')
    geo_model.add_surface_points(X=1095, Y=996, Z=800, surface='D')
    # Adding orientation to Cycle 1
    geo_model.add_orientations(X=832, Y=2132, Z=500, surface='C', orientation=[76, 17.88, 1])
    # surface B - After F1
    geo_model.add_surface_points(X=1447, Y=2554, Z=500, surface='B')
    geo_model.add_surface_points(X=1511, Y=2200, Z=500, surface='B')
    geo_model.add_surface_points(X=1549, Y=629, Z=600, surface='B')
    geo_model.add_surface_points(X=1630, Y=287, Z=600, surface='B')
    # surface C - After F1
    geo_model.add_surface_points(X=1891, Y=2063, Z=600, surface='C')
    geo_model.add_surface_points(X=1605, Y=1846, Z=700, surface='C')
    geo_model.add_surface_points(X=1306, Y=1641, Z=800, surface='C')
    geo_model.add_surface_points(X=1476, Y=979, Z=800, surface='C')
    geo_model.add_surface_points(X=1839, Y=962, Z=700, surface='C')
    geo_model.add_surface_points(X=2185, Y=893, Z=600, surface='C')
    geo_model.add_surface_points(X=2245, Y=547, Z=600, surface='C')
    # Surface D - After F1
    geo_model.add_surface_points(X=2809, Y=2567, Z=600, surface='D')
    geo_model.add_surface_points(X=2843, Y=2448, Z=600, surface='D')
    geo_model.add_surface_points(X=2873, Y=876, Z=700, surface='D')
    # Surface D - After F2
    geo_model.add_surface_points(X=3056, Y=2439, Z=650, surface='D')
    geo_model.add_surface_points(X=3151, Y=1292, Z=700, surface='D')

    ### Fault 1
    # Surface F1
    geo_model.add_surface_points(X=1203, Y=138, Z=600, surface='F1')
    geo_model.add_surface_points(X=1250, Y=1653, Z=800, surface='F1')
    # orientation to Fault 1
    geo_model.add_orientations(X=1280, Y=2525, Z=500, surface='F1', orientation=[272, 90, 1])

    ### Cycle 2
    # Surface G - Before F2
    geo_model.add_surface_points(X=1012, Y=1493, Z=900, surface='G')
    geo_model.add_surface_points(X=1002, Y=1224, Z=900, surface='G')
    geo_model.add_surface_points(X=1579, Y=1376, Z=850, surface='G')
    geo_model.add_surface_points(X=2489, Y=336, Z=750, surface='G')
    geo_model.add_surface_points(X=2814, Y=1848, Z=750, surface='G')
    # Surface H - Before F2
    geo_model.add_surface_points(X=2567, Y=129, Z=850, surface='H')
    geo_model.add_surface_points(X=3012, Y=726, Z=800, surface='H')
    # Orientation to cycle 2
    geo_model.add_orientations(X=1996, Y=47, Z=800, surface='G', orientation=[92, 5.54, 1])
    # Surface G - After F2
    geo_model.add_surface_points(X=3031, Y=2725, Z=800, surface='G')
    geo_model.add_surface_points(X=3281, Y=2314, Z=750, surface='G')
    geo_model.add_surface_points(X=3311, Y=1357, Z=750, surface='G')
    geo_model.add_surface_points(X=3336, Y=898, Z=750, surface='G')
    # Surface H - After F2
    geo_model.add_surface_points(X=3218, Y=1818, Z=890, surface='H')
    geo_model.add_surface_points(X=3934, Y=1207, Z=810, surface='H')
    geo_model.add_surface_points(X=3336, Y=704, Z=850, surface='H')

    ### Fault 2
    geo_model.add_surface_points(X=3232, Y=178, Z=1000, surface='F2')
    geo_model.add_surface_points(X=2912, Y=2653, Z=700, surface='F2')
    # Add orientation to Fault 2
    geo_model.add_orientations(X=3132, Y=951, Z=700, surface='F2', orientation=[85, 90, 1])

    gp.compute_model(geo_model, sort_surfaces=False)

    module = GemPyModule(geo_model = geo_model, extent=extent, box=[1000, 800], load_examples=False)
    module.show_boundary = True
    module.show_lith = True
    module.show_hillshades = True
    module.show_contour = True
    module.show_fill_contour = False

    sb_params = module.update(pytest.sb_params)
    sb_params['fig'].show()


================================================
FILE: tests/test_modules/test_geolectrics.py
================================================
from sandbox import _test_data
from sandbox.modules import GeoelectricsModule
import matplotlib.pyplot as plt
import pytest
import numpy as np
file = np.load(_test_data['topo'] + "DEM2.npz")
frame = (file['arr_0'] - file['arr_0'].min()) *1000+50
extent = [0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()]

fig, ax = plt.subplots()
pytest.sb_params = {'frame': frame,
                    'ax': ax,
                    'fig': fig,
                    'extent': extent,
                    'marker': [],
                    'cmap': plt.cm.get_cmap('viridis'),
                    'norm': None,
                    'active_cmap': True,
                    'active_contours': True}

def test_init():
    geo = GeoelectricsModule()

def test_create_mesh():
    geo = GeoelectricsModule()
    _ = geo.create_mesh(pytest.sb_params["frame"], step = 7.5)
    geo.show_mesh().show()

def test_create_data_containerERT():
    geo = GeoelectricsModule()
    _=geo.create_mesh(pytest.sb_params["frame"], step=7.5)
    markers = np.array(([20, 130],
                 [160, 20],
                 [50, 60],
                 [150, 120]))
    geo.set_electrode_positions(markers)
    measurements = np.array(([0, 1, 2, 3],))
    scheme_type = "abmn"
    _=geo.create_data_containerERT(measurements, scheme_type)
    print(geo.scheme)

def test_calculate_current_flow():
    geo = GeoelectricsModule()
    _=geo.create_mesh(pytest.sb_params["frame"], step=7.5)
    markers = np.array(([20, 130],
                        [160, 20],
                        [50, 60],
                        [150, 120]))
    geo.set_electrode_positions(markers)
    measurements = np.array(([0, 1, 2, 3],))
    scheme_type = "abmn"
    _=geo.create_data_containerERT(measurements, scheme_type)
    _=geo.calculate_current_flow()
    geo.show_streams().show()

def test_calculate_resistivity_sensitivity():
    geo = GeoelectricsModule()
    _=geo.create_mesh(pytest.sb_params["frame"], step=7.5)
    markers = np.array(([20, 130],
                        [160, 20],
                        [50, 60],
                        [150, 120]))
    geo.set_electrode_positions(markers)
    measurements = np.array(([0, 1, 2, 3],))
    scheme_type = "abmn"
    _=geo.create_data_containerERT(measurements, scheme_type)
    _=geo.calculate_current_flow()
    _=geo.calculate_sensitivity()
    geo.show_sensitivity().show()

def test_update_resistivity():
    geo = GeoelectricsModule()
    geo.set_electrode_positions()
    geo.update_resistivity(pytest.sb_params["frame"],
                           pytest.sb_params["extent"],
                           7.5)
    geo.calculate_sensitivity()
    geo.show_streams().show()
    geo.show_sensitivity().show()

def test_plot_sandbox():
    geo = GeoelectricsModule()
    geo.set_electrode_positions()
    geo.sensitivity = True
    frame_r = pytest.sb_params["frame"]
    geo.update_resistivity(frame_r,
                           pytest.sb_params["extent"],
                           7.5)
    geo.calculate_sensitivity()

    fig, ax = plt.subplots()

    geo.plot_mesh(ax, frame_r, pytest.sb_params["cmap"])
    fig.show()

    fig, ax = plt.subplots()
    geo.plot_potential(ax, pytest.sb_params["extent"])
    geo.plot_stream_lines(ax)
    fig.show()

    fig, ax = plt.subplots()
    geo.plot_sensitivity(ax, pytest.sb_params["extent"])
    fig.show()



================================================
FILE: tests/test_modules/test_gradients.py
================================================
from sandbox import _test_data as test_data
from sandbox.modules import GradientModule
import matplotlib.pyplot as plt
import pytest

import numpy as np
file = np.load(test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
extent = [0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()]

fig, ax = plt.subplots()
pytest.sb_params = {'frame': frame,
                    'ax': ax,
                    'fig': fig,
                    'extent': extent,
                    'marker': [],
                    'cmap': plt.cm.get_cmap('viridis'),
                    'norm': None,
                    'active_cmap': True,
                    'active_contours': True}

def test_init():
    module = GradientModule()
    print(module)

def test_update_dx():
    pytest.sb_params['ax'].cla()
    module = GradientModule(extent=extent)
    module.current_grad = module.grad_type[0]
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), origin='lower')
    fig.show()


def test_update_dy():
    pytest.sb_params['ax'].cla()
    pytest.sb_params['frame']=frame
    module = GradientModule(extent=extent)
    module.current_grad = module.grad_type[1]
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), origin='lower')
    fig.show()


def test_update_dxdy():
    pytest.sb_params['ax'].cla()
    module = GradientModule(extent=extent)
    module.current_grad = module.grad_type[2]
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), origin='lower')
    fig.show()


def test_update_laplace():
    pytest.sb_params['ax'].cla()
    module = GradientModule(extent=extent)
    module.current_grad = module.grad_type[3]
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), origin='lower')
    fig.show()


def test_update_vectorfield():
    pytest.sb_params['ax'].cla()
    module = GradientModule(extent=extent)
    module.current_grad = module.grad_type[5]
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), origin='lower')
    fig.show()

def test_update_stream():
    pytest.sb_params['ax'].cla()
    module = GradientModule(extent=extent)
    module.current_grad = module.grad_type[6]
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), origin='lower')
    fig.show()


def test_update_laplace_vectorfield():
    pytest.sb_params['ax'].cla()
    module = GradientModule(extent=extent)
    module.current_grad = module.grad_type[7]
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), origin='lower')
    fig.show()


def test_update_laplace_stream():
    pytest.sb_params['ax'].cla()
    module = GradientModule(extent=extent)
    module.current_grad = module.grad_type[8]
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), origin='lower')
    fig.show()


def test_update_lightsource():
    pytest.sb_params['ax'].cla()
    module = GradientModule(extent=extent)
    module.current_grad = module.grad_type[4]
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), origin='lower')
    fig.show()

def test_modify_lightsource():
    pytest.sb_params['ax'].cla()
    module = GradientModule(extent=extent)
    module.set_lightsource(90, 30, 0.5)
    module.current_grad = module.grad_type[4]
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), origin='lower')
    fig.show()

def test_widget():
    module = GradientModule(extent=extent)
    widgets = module.show_widgets()
    widgets.show()






================================================
FILE: tests/test_modules/test_landscapes.py
================================================
from sandbox import _test_data
from sandbox.modules import LandscapeGeneration
import matplotlib.pyplot as plt
import pytest

import numpy as np
file = np.load(_test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
extent = [0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()]

fig, ax = plt.subplots()
pytest.sb_params = {'frame': frame,
                    'ax': ax,
                    'fig': fig,
                    'extent': extent,
                    'marker': [],
                    'cmap': plt.cm.get_cmap('viridis'),
                    'norm': None,
                    'active_cmap': True,
                    'active_contours': True}

def test_init():
    module = LandscapeGeneration()
    print(module)

def test_run_cmd():
    import subprocess
    import os
    os.chdir('C:\\Users\\Admin\\PycharmProjects\\pytorch-CycleGAN-and-pix2pix')
    os.popen('python test.py --dataroot ./datasets/ --name train_1k --model pix2pix --gpu_ids -1 --direction AtoB')
    #list_files = subprocess.run(['ls', '-l'])
    #print(list_files)

def test_run_():
    import os, sys
    package_dir = 'C:\\Users\\Admin\\PycharmProjects\\pytorch-CycleGAN-and-pix2pix\\'
    sys.path.append(package_dir)

    import os
    from options.test_options import TestOptions, BaseOptions
    from data import create_dataset
    from models import create_model
    from util.visualizer import save_images
    from util import html
    opt = TestOptions()

    import argparse
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    #print(parser)
    #parser.convert_arg_line_to_args()

    bas = BaseOptions()
    parser = bas.initialize(parser)
    dataroot = _test_data['landscape_generation']

    for i in parser._actions:
        if i.dest == 'dataroot':
            i.default = dataroot
            i.required = False



    #parser.add_argument('--dataroot', default=data_dir)
    print(parser)


    opt, _ = parser.parse_args()
    print(opt)



================================================
FILE: tests/test_modules/test_landslides.py
================================================
from sandbox import _test_data as test_data
from sandbox.modules import LandslideSimulation
import matplotlib.pyplot as plt
import pytest
import numpy as np
file = np.load(test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
extent = [0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()]


def load_marker():
    import pandas as pd
    from sandbox import _test_data
    arucos = _test_data['test'] + "arucos.pkl"
    try:
        df = pd.read_pickle(arucos)
        print("Arucos loaded")
    except:
        df = pd.DataFrame()
        print("No arucos found")
    return df

fig, ax = plt.subplots()
pytest.sb_params = {'frame': frame,
                    'ax': ax,
                    'fig': fig,
                    'extent': extent,
                    'marker': load_marker(),
                    'cmap': plt.cm.get_cmap('gist_earth_r'),
                    'norm': None,
                    'active_cmap': True,
                    'active_contours': True}

def update(module):
    pytest.sb_params['ax'].cla()
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), norm=sb_params.get('norm'), origin='lower')
    fig.show()


def test_init():
    module = LandslideSimulation(extent=extent)
    print(module)

def test_update():
    module = LandslideSimulation(extent=extent)
    update(module)

def test_load_simulation():
    module = LandslideSimulation(extent=extent)
    module.load_simulation_data_npz(test_data['landslide_simulation']+'Sim_Topo1_Rel13_results4sandbox.npz')
    assert module.velocity_flow is not None and module.height_flow is not None

def test_load_release_area():
    module = LandslideSimulation(extent=extent)
    module.Load_Area.loadTopo(test_data['landslide_topo']+'Topography_3.npz')
    assert module.Load_Area.file_id == '3'

    module.load_release_area(test_data['landslide_release'])
    lst = ['ReleaseArea_3_1.npy', 'ReleaseArea_3_2.npy','ReleaseArea_3_2.npy']
    assert [i in lst for i in module.release_options]
    lst2 = ['1', '2', '3']
    assert [i in lst for i in module.release_id_all]

def test_show_box_release():
    module = LandslideSimulation(extent=extent)
    module.Load_Area.loadTopo(test_data['landslide_topo'] + 'Topography_3.npz')
    module.load_release_area(test_data['landslide_release'])
    module.modify_to_box_coordinates(id = '1')
    fig, ax = plt.subplots()
    ax.imshow(frame, vmin=extent[-2], vmax=extent[-1], cmap='gist_earth_r',origin='lower')
    module.show_box_release(ax, module.release_area)
    #TODO assert np.allclose(np.asarray([[74., 72.], [74., 84.],[86., 84.],[86., 72.]]), module.release_area)
    fig.show()

def test_plot_landslide():
    module = LandslideSimulation(extent=extent)
    module.load_simulation_data_npz(test_data['landslide_simulation'] + 'Sim_Topo1_Rel13_results4sandbox.npz')
    module.flow_selector = "Velocity"
    module.frame_selector = 10
    fig, ax = plt.subplots()
    ax.imshow(frame, vmin=extent[-2], vmax=extent[-1], cmap='gist_earth_r', origin='lower')
    module.plot_landslide_frame(ax)
    fig.show()

    module.flow_selector = "Height"
    ax.cla()
    ax.imshow(frame, vmin=extent[-2], vmax=extent[-1], cmap='gist_earth_r', origin='lower')
    module.plot_landslide_frame(ax)
    fig.show()

def test_panel_plot():
    module = LandslideSimulation(extent=extent)
    module.load_simulation_data_npz(test_data['landslide_simulation'] + 'Sim_Topo1_Rel13_results4sandbox.npz')
    module.frame_selector = 10
    module.plot_frame_panel()
    module.plot_flow_frame.show()

def test_show_widgets():
    module = LandslideSimulation(extent=extent)
    module.load_simulation_data_npz(test_data['landslide_simulation'] + 'Sim_Topo1_Rel13_results4sandbox.npz')
    module.flow_selector = "Velocity"
    module.frame_selector = 10
    landslide = module.show_widgets()
    landslide.show()






================================================
FILE: tests/test_modules/test_load_save_topo.py
================================================
from sandbox import _test_data as test_data
from sandbox.modules import LoadSaveTopoModule
import matplotlib.pyplot as plt
import pytest
import numpy as np

file = np.load(test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
extent = [0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()]


def load_marker():
    import pandas as pd
    from sandbox import _test_data
    arucos = _test_data['test'] + "arucos.pkl"
    try:
        df = pd.read_pickle(arucos)
        print("Arucos loaded")
    except:
        df = pd.DataFrame()
        print("No arucos found")
    return df

fig, ax = plt.subplots()
pytest.sb_params = {'frame': frame,
                    'ax': ax,
                    'fig': fig,
                    'extent': extent,
                    'marker': load_marker(),
                    'cmap': plt.cm.get_cmap('gist_earth_r'),
                    'norm': None,
                    'active_cmap': True,
                    'active_contours': True}

def update(module):
    pytest.sb_params['ax'].cla()
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), norm=sb_params.get('norm'), origin='lower')
    fig.show()


def test_init():
    module = LoadSaveTopoModule(extent=extent)
    print(module)

def test_update():
    pytest.sb_params['ax'].cla()
    module = LoadSaveTopoModule(extent=extent)
    module.box_width = 100
    module.box_height = 50
    update(module)

def test_plot_release_area():
    module = LoadSaveTopoModule(extent=extent)
    module.box_width = 100
    module.box_height = 50
    module.add_release_area_origin(x=20, y=40)
    module.add_release_area_origin(x=50, y=40)
    module.add_release_area_origin(x=100, y=90)
    update(module)

def test_extract_topo():
    module = LoadSaveTopoModule(extent=extent)
    module.frame = frame
    absolute_topo, relative_topo = module.extractTopo()
    print(absolute_topo)

def test_save_topo():
    module = LoadSaveTopoModule(extent=extent)
    module.frame = frame
    module.extractTopo()
    module.saveTopo(filename=test_data['test']+'temp/01_savedTopo.npz')

def test_load_topo():
    module = LoadSaveTopoModule(extent=extent)
    module.loadTopo(filename=test_data['test']+'temp/01_savedTopo.npz')
    assert module.absolute_topo is not None
    print(module.file_id)

def test_release_area():
    module = LoadSaveTopoModule(extent=extent)
    module.add_release_area_origin(x=20, y=40)
    module.save_release_area(filename=test_data['test']+'temp/01_releaseArea.npy')

def test_show_loaded_topo():
    module = LoadSaveTopoModule(extent=extent)
    fig, ax = plt.subplots()
    module.box_width = 100
    module.box_height = 50
    module.frame = frame
    module.extractTopo()
    module.showLoadedTopo(ax)
    ax.imshow(frame, vmin=extent[-2], vmax=extent[-1], cmap="gist_earth_r", origin='lower')
    fig.show()

def test_extract_difference():
    module = LoadSaveTopoModule(extent=extent)
    module.frame = frame
    module.loadTopo(filename=test_data['test']+'temp/01_savedTopo.npz')
    diff = module.extractDifference()
    print(diff)

def test_show_difference():
    module = LoadSaveTopoModule(extent=extent)
    fig, ax = plt.subplots()
    module.box_width = 100
    module.box_height = 50
    module.frame = frame
    module.extractTopo()
    module.box_origin = [10,10]
    module.showDifference(ax)
    ax.imshow(frame, vmin=extent[-2], vmax=extent[-1], cmap="gist_earth_r", origin='lower')
    fig.show()

def test_get_file_id():
    module = LoadSaveTopoModule(extent=extent)
    module._get_id(test_data['landslide_topo'] + 'Topography_1.npz')
    assert module.file_id == '1'

def test_snapshot_frame():
    module = LoadSaveTopoModule(extent=extent)
    module.box_width = 100
    module.box_height = 50
    module.frame = frame
    module.extractTopo()
    module.snapshotFrame()
    module.snapshot_frame.show()

def test_widgets():
    module = LoadSaveTopoModule(extent=extent)
    widgets = module.show_widgets()
    widgets.show()



================================================
FILE: tests/test_modules/test_pynoddy.py
================================================
import pytest
from sandbox.modules.pynoddy import PynoddyModule
import pynoddy
import importlib
#importlib.reload(pynoddy)
import pynoddy.output
import pynoddy.history
import sys, os
import subprocess
from sandbox import _test_data, _package_dir
repository_folder = os.path.abspath(_package_dir + '/../../pynoddy/') + os.sep  # Modify here
example_directory = os.path.abspath(repository_folder + 'examples/') + os.sep
history_file = 'simple_two_faults.his'  # Modify here
history = os.path.abspath(example_directory + history_file)
output_folder = os.path.abspath(_test_data['test'] + 'noddy') + os.sep
output = os.path.abspath(output_folder+'noddy_out')

noddy_exec = 'noddy.exe'


def test_simulation_noddy():
    pynoddy.compute_model(history, output, noddy_path=noddy_exec)


def test():
    p = subprocess.Popen(["echo", "Hello World!"], stdout=subprocess.PIPE)
    stdout, _ = p.communicate()

    assert stdout == b"Hello World!\n"


def test_nody_sandbox():
    noddy = PynoddyModule()
    noddy.update(sb_params)
    pass


================================================
FILE: tests/test_modules/test_seismic.py
================================================
from sandbox import _test_data
from sandbox.modules import SeismicModule
import matplotlib.pyplot as plt
import pytest
import numpy as np
import pandas as pd

df = pd.read_pickle(_test_data['test']+"arucos.pkl")
file = np.load(_test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
frame = frame + np.abs(np.amin(frame))
extent = [0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()]

fig, ax = plt.subplots()
pytest.sb_params = {'frame': frame,
                    'ax': ax,
                    'fig': fig,
                    'extent': extent,
                    'marker': df,
                    'cmap': plt.cm.get_cmap('viridis'),
                    'norm': None,
                    'active_cmap': True,
                    'active_contours': True}


def test_init():
    seis = SeismicModule()

def test_scale_frame():
    seis = SeismicModule()
    new_frame = seis.scale_linear(frame, 5, 2)
    assert np.amin(new_frame) == 2 and np.amax(new_frame) == 5

def test_smooth_topo():
    seis = SeismicModule()
    new_frame = seis.smooth_topo(frame, 10, 5)
    print(new_frame==frame)
    plt.imshow(frame, cmap="viridis", origin="lower")
    plt.show()

    plt.imshow(new_frame, cmap="viridis",  origin="lower")
    plt.show()

def test_create_velocity_model():
    seis = SeismicModule()
    plt.imshow(frame.T, cmap="viridis")
    plt.show()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=True)

    seis.create_velocity_model(None, norm=False, smooth=False, show_velocity=True)

def test_create_time_axis():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=False)
    time_range = seis.create_time_axis(t0=0, tn=1000)
    print(time_range)

def test_create_source_wavelet():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=False)
    seis.create_time_axis(t0=0, tn=1000)
    seis.create_source(name ="src", f0=0.025, source_coordinates=None, show_wavelet=True, show_model=True)
    seis.create_source(name ="src1", f0=0.025, source_coordinates=(700,200), show_wavelet=False, show_model=True)

def test_create_time_function():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=False)
    seis.create_time_axis(t0=0, tn=1000)
    seis.create_source(name ="src", f0=0.025, source_coordinates=None, show_wavelet=False, show_model=False)
    seis.create_time_function()

def test_solve_PDE():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=False)
    seis.create_time_axis(t0=0, tn=1000)
    seis.create_source(name ="src", f0=0.025, source_coordinates=None, show_wavelet=False, show_model=False)
    seis.create_time_function()
    seis.solve_PDE()

def test_inject_source():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=False)
    seis.create_time_axis(t0=0, tn=1000)
    seis.create_time_function()
    seis.solve_PDE()

    src = seis.create_source(name="src", f0=0.025, source_coordinates=None, show_wavelet=False, show_model=False)
    src0 = seis.create_source(name="src0", f0=0.025, source_coordinates=(300,200), show_wavelet=False, show_model=False)
    src1 = seis.create_source(name="src1", f0=0.025, source_coordinates=(300,1500), show_wavelet=False, show_model=False)

    seis.inject_source(src)
    seis.inject_source(src0)
    seis.inject_source(src1)

    seis.show_velocity(seis.model, source=seis.src, receiver=seis.rec)

def test_operator():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=False)
    seis.create_time_axis(t0=0, tn=1000)
    seis.create_time_function()
    seis.solve_PDE()

    src = seis.create_source(name="src", f0=0.025, source_coordinates=None, show_wavelet=False, show_model=False)
    seis.inject_source(src)
    seis.operator_and_solve()

def test_receivers():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=False)
    seis.create_time_axis(t0=0, tn=1000)
    seis.create_time_function()
    rec = seis.create_receivers(name='rec', n_receivers=100, depth_receivers=200, show_receivers=True )

def test_interpolate_receivers():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=False)
    seis.create_time_axis(t0=0, tn=1000)
    seis.create_time_function()
    rec=seis.create_receivers(name='rec', n_receivers=100, depth_receivers=200, show_receivers=True)
    seis.interpolate_receiver(rec)

def test_operator_receiver():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=False)
    seis.create_time_axis(t0=0, tn=1000)
    seis.create_time_function()
    seis.solve_PDE()

    rec=seis.create_receivers(name='rec', n_receivers=100, depth_receivers=20, show_receivers=False)
    seis.interpolate_receiver(rec)

    src = seis.create_source(name="src", f0=0.025, source_coordinates=None, show_wavelet=False, show_model=False)
    seis.inject_source(src)
    seis.operator_and_solve()

    seis.show_velocity(seis.model, source=src.coordinates.data,
                       receiver=rec.coordinates.data[::4, :])

def test_show_shot_record():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, show_velocity=False)
    #seis.create_velocity_model(None, norm=False, smooth=False, show_velocity=True)
    seis.create_time_axis(t0=0, tn=1000)
    seis.create_time_function()
    seis.solve_PDE()

    rec = seis.create_receivers(name='rec', n_receivers=100, depth_receivers=20, show_receivers=False)
    seis.interpolate_receiver(rec)

    src = seis.create_source(name="src", f0=0.01, source_coordinates=(500,20), show_wavelet=False, show_model=False)
    seis.inject_source(src)
    seis.operator_and_solve()
    seis.show_shotrecord(rec.data, seis.model, 0, 1000)

def test_show_wavefield():
    seis = SeismicModule()
    seis.create_velocity_model(frame, vmax=5, vmin=2, sigma_x=5, sigma_y=5, nbl=40, show_velocity=False)
    #seis.create_velocity_model(None, norm=False, smooth=False, show_velocity=False)
    seis.create_time_axis(t0=0, tn=1000)
    seis.create_time_function()
    seis.solve_PDE()

    rec=seis.create_receivers(name='rec', n_receivers=100, depth_receivers=20, show_receivers=False)
    seis.interpolate_receiver(rec)

    src = seis.create_source(name="src", f0=0.025, source_coordinates=(500, 400), show_wavelet=False, show_model=False)
    src1 = seis.create_source(name="src1", f0=0.025, source_coordinates=(800, 800), show_wavelet=False, show_model=False)
    seis.inject_source(src)
    seis.inject_source(src1)
    seis.operator_and_solve()

    seis.show_velocity(seis.model, source=seis.src_coordinates,
                       receiver=rec.coordinates.data)
    seis.show_wavefield(timeslice=10)
    seis.show_wavefield(timeslice=50)
    seis.show_wavefield(timeslice=100)
    seis.show_wavefield(timeslice=200)
    seis.show_wavefield(timeslice=300)
    seis.show_wavefield(timeslice=400)

    seis.show_wavefield(timeslice=5000)

def test_init_all_velocity_model():
    seis = SeismicModule()
    file = np.load(_test_data['test'] + "frame1.npz")
    frame = seis.crop_frame(origin=(20,20), width=200, height=180, frame=file['arr_0'])
    seis.init_model(vmin=2, vmax=4, frame=np.transpose(frame))
    plt.imshow(frame, origin="lower", cmap ="gist_earth")
    plt.show()
    seis.show_velocity(seis.model)

def test_insert_aruco_source():
    seis = SeismicModule()
    file = np.load(_test_data['test'] + "frame1.npz")
    frame = seis.crop_frame(origin=(10, 10), width=230, height=180, frame=file['arr_0'])
    seis.init_model(vmin=2, vmax=4, frame=np.transpose(frame))

    marker = pytest.sb_params['marker']
    seis.xy_aruco=marker.loc[marker.is_inside_box, ('box_x', 'box_y')].values
    seis.insert_aruco_source()

    seis.show_velocity(seis.model, source=seis.src_coordinates)
    print(seis.src_coordinates)

def test_run_aruco_source():
    seis = SeismicModule()
    file = np.load(_test_data['test'] + "frame1.npz")
    frame = seis.crop_frame(origin=(10, 10), width=230, height=180, frame=file['arr_0'])
    seis.init_model(vmin=2, vmax=4, frame=np.transpose(frame), nbl=40)

    marker = pytest.sb_params['marker']
    seis.xy_aruco=marker.loc[marker.is_inside_box, ('box_x', 'box_y')].values
    seis.insert_aruco_source()

    seis.show_velocity(seis.model, source=seis.src_coordinates)
    print(seis.src_coordinates)
    seis.operator_and_solve()

    seis.show_velocity(seis.model, source=seis.src_coordinates)
    seis.show_wavefield(timeslice=10)
    seis.show_wavefield(timeslice=50)
    seis.show_wavefield(timeslice=100)
    seis.show_wavefield(timeslice=200)
    seis.show_wavefield(timeslice=300)
    seis.show_wavefield(timeslice=400)
    seis.show_wavefield(timeslice=5000)

def test_panel_plotting():
    seis = SeismicModule()
    marker = pytest.sb_params['marker']
    seis.xy_aruco = marker.loc[marker.is_inside_box, ('box_x', 'box_y')].values
    file = np.load(_test_data['test'] + "frame1.npz")
    seis.frame = seis.crop_frame(origin=(30, 30), width=230, height=180, frame=file['arr_0'])
    seis.run_simulation()
    seis.timeslice = 50
    sb_params = seis.update(pytest.sb_params)
    fig = sb_params["fig"]
    fig.show()


================================================
FILE: tests/test_modules/test_topography.py
================================================
from sandbox import _test_data
from sandbox.modules import TopoModule
import matplotlib.pyplot as plt
import pytest
import numpy as np

def load_marker():
    import pandas as pd
    df = pd.DataFrame({"box_x": [25], "box_y": [120], "is_inside_box": [True]})
    #arucos = _test_data['test'] + "arucos.pkl"
    #try:
    #    df = pd.read_pickle(arucos)
    ##    print("Arucos loaded")
    #except:
    #    df = pd.DataFrame()
    #    print("No arucos found")

    return df

file = np.load(_test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
frame = frame + np.abs(frame.min())
extent = [0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()]

fig, ax = plt.subplots()
pytest.sb_params = {'frame': frame,
                    'ax': ax,
                    'fig': fig,
                    'extent': extent,
                    'marker': load_marker(),
                    'cmap': plt.cm.get_cmap('gist_earth_r'),
                    'norm': None,
                    'active_cmap': True,
                    'active_contours': True}


def test_init():
    module = TopoModule()
    print(module)


def test_update():
    pytest.sb_params['ax'].cla()
    module = TopoModule(extent=extent)
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), norm=sb_params.get('norm'), origin='lower')
    fig.show()


def test_update_no_sea():
    pytest.sb_params['ax'].cla()
    module = TopoModule(extent=extent)
    module.sea = False
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), norm=sb_params.get('norm'), origin='lower')
    fig.show()


def test_update_no_normalized():
    pytest.sb_params['ax'].cla()
    module = TopoModule(extent=extent)
    module.normalize = False
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), norm=sb_params.get('norm'), origin='lower')
    fig.show()


def test_widgets():
    module = TopoModule(extent=extent)
    widgets = module.show_widgets()
    widgets.show()


def test_add_countour():
    pytest.sb_params['ax'].cla()
    module = TopoModule(extent=extent)
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), #vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), norm=sb_params.get('norm'), origin='lower')
    fig.show()
    #pytest.sb_params['frame'] = frame
    module.sea = True
    module.sea_contour = True
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), #vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), norm=sb_params.get('norm'), origin='lower')
    fig.show()
    pytest.sb_params['ax'].cla()
    module.sea_contour = False
    #pytest.sb_params['frame'] = frame
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']
    ax.imshow(sb_params.get('frame'), #vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), norm=sb_params.get('norm'), origin='lower')
    fig.show()

def test_normalize_negative_height():
    module = TopoModule(extent=extent)
    plt.imshow(pytest.sb_params['frame'], origin="lower", cmap = "viridis")
    plt.colorbar()
    plt.show()
    n = -200
    new_frame_negative, new_extent_negative = module.normalize_topography(pytest.sb_params['frame'].copy(),
                                                                          pytest.sb_params['extent'].copy(),
                                                                          max_height=1000, min_height= n)
    assert new_frame_negative.min() == n
    plt.imshow(new_frame_negative, origin="lower", cmap="viridis")
    plt.colorbar()
    plt.show()
    p=200
    new_frame_positive, new_extent_positive = module.normalize_topography(pytest.sb_params['frame'].copy(),
                                                                          pytest.sb_params['extent'].copy(),
                                                                          max_height=1000, min_height=p)
    assert new_frame_positive.min() == p
    plt.imshow(new_frame_positive, origin="lower", cmap="viridis")
    plt.colorbar()
    plt.show()

    c = 0
    new_frame_positive, new_extent_positive = module.normalize_topography(pytest.sb_params['frame'].copy(),
                                                                          pytest.sb_params['extent'].copy(),
                                                                          max_height=1000, min_height=c)
    assert new_frame_positive.min() == c
    plt.imshow(new_frame_positive, origin="lower", cmap="viridis")
    plt.colorbar()
    plt.show()

def test_single_path():
    pytest.sb_params['ax'].cla()
    module = TopoModule(extent=extent)
    module.sea = True
    module.side_flooding = True
    sb_params = module.update(pytest.sb_params)
    ax = sb_params['ax']
    fig = sb_params['fig']

    ax.imshow(sb_params.get('frame'),  # vmin=sb_params.get('extent')[-2], vmax=sb_params.get('extent')[-1],
              cmap=sb_params.get('cmap'), norm=sb_params.get('norm'), origin='lower')
    ax.plot(module._marker_contour_val[0], module._marker_contour_val[1], 'r*')
    fig.show()


def test_solve_maze():
    # set We create a matrix with zeros of the same size
    # Put a 1 to the starting point
    # Everywhere around 1 we put 2 , if there is no wall
    # Everywhere around 2 we put 3 , if there is no wall
    # and so on…
    # once we put a number at the ending point, we stop. This number is actually the minimal path length
    a = frame#[:50, :50]
    m = np.zeros((a.shape))
    m[140,150] = 1
    # FUnction for just one step
    tolerance = 0#.5
    def make_step(k):
        fin = False
        for i in range(len(m)):
            for j in range(len(m[i])):
                if m[i][j] == k:
                    z = frame[i][j] + tolerance  # Current height check if is below
                    if i > 0 and m[i - 1][j] == 0 and frame[i - 1][j] <= z:  # down
                        m[i - 1][j] = k + 1
                        fin = True
                    if j > 0 and m[i][j - 1] == 0 and frame[i][j - 1] <= z:  # left
                        m[i][j - 1] = k + 1
                        fin = True
                    if i < len(m) - 1 and m[i + 1][j] == 0 and frame[i + 1][j] <= z:  # up
                        m[i + 1][j] = k + 1
                        fin = True
                    if j < len(m[i]) - 1 and m[i][j + 1] == 0 and frame[i][j + 1] <= z:  # right
                        m[i][j + 1] = k + 1
                        fin = True
        return fin
    k = 0
    work = True
    while work:
        k += 1
        work = make_step(k)
    #[make_step(i+1) for i in range(10)]
    m[m==0] = np.nan
    plt.imshow(a, cmap = "gist_earth")
    plt.imshow(m)
    plt.show()

def test_solve_maze_with_gradients():
    a = frame[:50, :50]
    m = np.zeros((a.shape))
    m[140, 150] = 1
    # FUnction for just one step
    tolerance = 0.5

    dx, dy = np.gradient(frame)



================================================
FILE: tests/test_sensor_markers/__init__.py
================================================



================================================
FILE: tests/test_sensor_markers/test_aruco.py
================================================
from sandbox.markers import ArucoMarkers, MarkerDetection
from sandbox.sensor import Sensor
from sandbox import _test_data, _calibration_dir
im_folder = _test_data['test']
import numpy as np
import matplotlib.pyplot as plt
frame = np.load(im_folder+'frame1.npz')
depth = frame['arr_0']
color = frame['arr_1']
try:
    sensor = Sensor(calibsensor= _calibration_dir + "sensorcalib.json", name='kinect_v2')
except:
    import warnings as warn
    warn("Testing will be performed without the sensor")
    sensor = None


def test_plot_image():
    depth = frame['arr_0']
    col = frame['arr_1']
    plt.imshow(depth)
    plt.show()
    plt.imshow(col)
    plt.show()

def test_aruco_detect():
    aruco = ArucoMarkers()
    corners, ids, rejected = aruco.aruco_detect(color)
    print(corners, ids, rejected)

def test_get_location_marker():
    aruco = ArucoMarkers()
    corners, _, _ = aruco.aruco_detect(color)
    x, y = aruco.get_location_marker(corners[0])
    print(x,y)

def test_find_markers_rgb():
    aruco = ArucoMarkers()
    rgb_markers = aruco.find_markers_rgb(color=color, amount=2)
    print(rgb_markers)

def test_find_markers_projector():
    aruco = ArucoMarkers()
    projector_markers, corner_middle = aruco.find_markers_projector(color=color, amount=2)
    print(corner_middle, projector_markers)

def test_create_aruco_marker():
    aruco = ArucoMarkers()
    aruco_array= aruco.create_aruco_marker(id=12, resolution=100, show=True, save=True, path=im_folder+'temp/')
    print(aruco_array)

def test_create_several_aruco_pdf():
    aruco = ArucoMarkers()
    fig = aruco.create_arucos_pdf(nx=5, ny=5, resolution=150, path=im_folder+'temp/')
    fig.show()

def test_update_arucos():
    aruco = ArucoMarkers(sensor=sensor)
    markers_in_frame = aruco.search_aruco(color)
    print(markers_in_frame)
    aruco.update_marker_dict()
    print(aruco.aruco_markers)
    aruco.transform_to_box_coordinates()
    print(aruco.aruco_markers)
    assert len(aruco.aruco_markers) == 2

def test_find_markers_IR():
    """Carefull. Most of the times doesn't work cause is stuck in infinite loop. If want to try, change the None with the number of arucos to detect"""
    aruco = ArucoMarkers(sensor=sensor)
    ir = aruco.find_markers_ir(amount=None)
    print(ir)

def test_create_coordinate_map():
    aruco = ArucoMarkers(sensor=sensor)
    map = aruco.create_CoordinateMap()
    print(map)

def test_marker_detection_class():
    """Work only with sensor active"""
    markers = MarkerDetection(sensor=sensor)
    fig, ax = plt.subplots()
    df = markers.update(frame=color)
    markers.plot_aruco(ax, df)
    fig.show()

def test_save_df():
    markers = MarkerDetection(sensor=sensor)
    df = markers.update(frame=color)
    df.to_pickle(im_folder+"temp/arucos.pkl")
    print(df)

def test_load_df():
    import pandas as pd
    df = pd.read_pickle(im_folder+"temp/arucos.pkl")
    print(df)

def test_widgets():
    markers = MarkerDetection(sensor=sensor)
    fig, ax = plt.subplots()
    df=markers.update(frame=color)
    markers.plot_aruco(ax, df)
    fig.show()
    widget = markers.widgets_aruco()
    widget.show()






================================================
FILE: tests/test_sensor_markers/test_aruco_linux.py
================================================
from sandbox.markers.aruco_linux import *
from sandbox.sensor import KinectV2


def test_registration():
    kinect = KinectV2()
    set_device(kinect)
    _ = registration()
    plot_all()

def test_distort():
    kinect = KinectV2()
    set_device_params(kinect)
    x, y = distort(100, 100)
    assert x == 99.17397057586149 and y == 99.43425492981704

def test_depth_to_color():
    kinect = KinectV2()
    set_device_params(kinect)
    rx, ry = depth_to_color(100, 100, 10000)
    assert rx == 505.6134745126878 and ry == 241.7240982502678

def test_depth_to_camera():
    kinect = KinectV2()
    set_device(kinect)
    undistorted_depth, registered_RGB, big_depth = registration()
    points = depth_to_camera(undistorted_depth)
    assert np.asarray(points).shape == (3, 424, 512)

def test_create_map():
    kinect = KinectV2()
    set_device(kinect)
    set_device_params(kinect)
    undistorted_depth, _, _ = registration()
    _ = depth_to_camera(undistorted_depth)
    df = create_CoordinateMap(kinect.get_frame())
    assert len(df) > 1000

def test_start_mapping():
    kinect = KinectV2()
    df = start_mapping(kinect)
    assert len(df) > 1000
    plot_all(df=df, index=18900)


================================================
FILE: tests/test_sensor_markers/test_aruco_windows.py
================================================
from sandbox.markers.aruco_windows import *
from sandbox.sensor import KinectV2

def test_create_map():
    kinect = KinectV2()
    set_device(kinect)
    df = create_CoordinateMap(kinect.get_frame())
    assert len(df) > 1000

def test_start_mapping():
    kinect = KinectV2()
    df = start_mapping(kinect)
    assert len(df) > 1000


================================================
FILE: tests/test_sensor_markers/test_calib_sensor.py
================================================
from sandbox import _test_data as test_data
from sandbox.sensor import CalibSensor

import numpy as np
file = np.load(test_data['topo'] + "DEM1.npz")
frame = file['arr_0']
extent = np.asarray([0, frame.shape[1], 0, frame.shape[0], frame.min(), frame.max()])

import matplotlib.pyplot as plt


def test_calibration():
    calib = CalibSensor(name = "dummy")

def test_create_widgets():
    calib = CalibSensor(name = "dummy", use_panel=False)
    calib._create_widgets()

def test_widgets():
    calib = CalibSensor(name="dummy", use_panel=False)
    widget = calib.calibrate_sensor()
    widget.show()



================================================
FILE: tests/test_sensor_markers/test_dummy.py
================================================
import numpy as np
from sandbox.markers import ArucoMarkers, MarkerDetection
from sandbox.markers.dummy_aruco import dummy_markers_in_frame
from sandbox import _test_data
file = np.load(_test_data['topo'] + "DEM1.npz")
frame = file['arr_0']


def test_detect_marker():
    dict_position = {1:[10,20],
          20:[30,20],
          2:[100,100],
          10:[40,50],
          5:[200,200],
          19:[1000,1000],
          99:[-10, 10]}

    df = dummy_markers_in_frame(dict_position, frame)
    print(df)
    assert df.loc[19, "is_inside_box"] == False

    xy = {}
    frm = np.empty((2,2))

    df = dummy_markers_in_frame(xy, frm)
    print(df)

def test_aruco_class():
    aruco = ArucoMarkers(sensor="dummy")
    assert aruco.kinect =="dummy"
    aruco.search_aruco(dict_position = {1:[10,20],2:[100,200]}, depth_frame=frame)
    print(aruco.markers_in_frame)

def test_marker_detection_class():
    aruco = MarkerDetection(sensor="dummy")
    df = aruco.update()
    print(df)
    aruco.set_aruco_position(dict_position = {1:[10,20],2:[100,50]}, frame=frame)
    df = aruco.update()
    print(df)
    aruco.set_aruco_position(dict_position={2:[100, 50], 4:[1000,1000]}, frame=frame)
    df = aruco.update()
    print(df)
    for i in range(10):
        df = aruco.update()
    print(df)






================================================
FILE: tests/test_sensor_markers/test_sensor.py
================================================
from sandbox import _test_data
calib_dir = _test_data['test'] + 'temp/'
from sandbox.sensor import Sensor
import numpy as np
import matplotlib.pyplot as plt
import platform
_platform = platform.system()

def test_init_kinect_v1():
    """ Test if detects the kinect 1"""

    sensor = Sensor(name='kinect_v1')
    print(sensor.get_frame(), sensor.get_frame().shape)
    assert sensor.get_frame().shape == (240, 320)

def test_init_kinect_v2():
    """Test if detects the kinect 2"""
    sensor = Sensor(name='kinect_v2', crop_values = False)
    # print(sensor.get_frame(), sensor.get_frame().shape)
    assert sensor.get_frame().shape == (424, 512)

def test_init_dummy():
    sensor = Sensor(name='dummy', random_seed=1234)
    print(sensor.depth[0, 0],
          sensor.depth[0, 0],
          sensor.depth[0, 0])
    #assert np.allclose(sensor.depth[0, 0], 1314.7485240531175)

def test_save_load_calibration_projector():
    sensor = Sensor(name='dummy')
    file = calib_dir + 'test_sensor_calibration.json'
    sensor.save_json(file=file)
    # now to test if it loads correctly the saved one
    sensor2 = Sensor(name='dummy', calibsensor=file)

def test_get_frame_croped_clipped():
    sensor = Sensor(name='dummy', crop_values=True, clip_values=True)
    frame = sensor.get_frame()
    print(frame.shape,  frame)
    assert frame.shape == (404, 492)

def test_extent_property():
    sensor = Sensor(name='dummy')
    print(sensor.extent)
    assert np.allclose(np.asarray([0, 492, 0, 404, 0, 800]), sensor.extent)

def test_get_frame():
    sensor = Sensor(name='kinect_v2', invert=False)
    print(sensor.get_frame())
    plt.imshow(sensor.depth, cmap='viridis', origin="lower")
    plt.show()

def test_init_kinectv2_linux():
    from sandbox.sensor.kinectV2 import KinectV2
    kinect = KinectV2()

def test_kinectv2_linux_frame():
    from sandbox.sensor.kinectV2 import KinectV2
    kinect = KinectV2()
    kinect.get_linux_frame(typ="all")

def test_get_depth_frame_lx():
    from sandbox.sensor.kinectV2 import KinectV2
    kinect = KinectV2()
    frame = kinect.get_frame()
    print(frame.shape)
    plt.imshow(frame, origin="lower", cmap="jet")
    plt.colorbar()
    plt.show()
    frame = kinect.get_frame()
    print(frame.shape)
    plt.imshow(frame, origin="lower", cmap="jet")
    plt.colorbar()
    plt.show()

def test_get_color_frame_lx():
    from sandbox.sensor.kinectV2 import KinectV2
    kinect = KinectV2()
    color = kinect.get_color()
    print(color.shape)
    print(color[0])
    plt.imshow(color, origin="lower")
    plt.show()
    color = kinect.get_color()
    plt.imshow(color, origin="lower")
    plt.show()

def test_get_IR_frame_lx():
    from sandbox.sensor.kinectV2 import KinectV2
    kinect = KinectV2()
    IR = kinect.get_ir_frame(min=0, max =6000)
    print(IR.shape)
    plt.imshow(IR, origin="lower")
    plt.colorbar()
    plt.show()
    IR = kinect.get_ir_frame(min=0, max=6000)
    print(IR.shape)
    plt.imshow(IR, origin="lower")
    plt.colorbar()
    plt.show()

def test_linux_2():
    if _platform == 'Windows':
        return
    from freenect2 import Device, FrameType

    # We use numpy to process the raw IR frame
    import numpy as np

    # We use the Pillow library for saving the captured image
    from PIL import Image

    # Open default device
    device = Device()

    # Start the device
    with device.running():
        # For each received frame...
        for type_, frame in device:
            # ...stop only when we get an IR frame
            if type_ is FrameType.Ir:
                break

    # Outside of the 'with' block, the device has been stopped again

    # The received IR frame is in the range 0 -> 65535. Normalise the
    # range to 0 -> 1 and take square root as a simple form of gamma
    # correction.
    ir_image = frame.to_array()
    ir_image /= ir_image.max()
    ir_image = np.sqrt(ir_image)

def test_linux_2_1():
    if _platform == 'Windows':
        return
    from freenect2 import Device, FrameType
    import numpy as np

    # Open the default device and capture a color and depth frame.
    device = Device()
    frames = {}
    with device.running():
        for type_, frame in device:
            frames[type_] = frame
            if FrameType.Color in frames and FrameType.Depth in frames:
                break

    # Use the factory calibration to undistort the depth frame and register the RGB
    # frame onto it.
    rgb, depth = frames[FrameType.Color], frames[FrameType.Depth]
    undistorted, registered, big_depth = device.registration.apply(
        rgb, depth, with_big_depth=True)

def test_thread_linux():
    from sandbox.sensor.kinectV2 import KinectV2
    kinect = KinectV2()

    kinect._run()
    import time
    time.sleep(1)
    print(kinect._depth)
    print(kinect._ir)
    print(kinect._color)

    kinect._stop()

    kinect._run()
    time.sleep(1)
    print(kinect._depth)
    print(kinect._ir)
    print(kinect._color)

    print("working", kinect.get_color())

def test_thread():
    from sandbox.sensor.kinectV2 import KinectV2
    kinect = KinectV2()
    kinect._run()
    rval = True
    import cv2
    while rval:
        cv2.imshow("color", kinect.get_color())
        cv2.imshow("depth", kinect.get_frame())
        cv2.imshow("ir", kinect.get_ir_frame())
        key = cv2.waitKey(20)
        if key == 27:  # exit on ESC
            break
    kinect._stop()

def test_thread_linux():
    from sandbox.sensor.kinectV2 import KinectV2
    kinect = KinectV2()
    kinect._run()
    kinect._stop()

