{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4490896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added DLL path: c:\\Users\\jason\\Desktop\\College\\Sem 4\\GeoBox\n",
      "\n",
      "SUCCESS! freenect imported.\n",
      "Kinect context initialized.\n",
      "Kinect device opened!\n",
      "LED set to Green.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the folder where this script (and the DLLs) are located\n",
    "current_folder = os.getcwd()\n",
    "\n",
    "# Tell Python: \"Trust DLLs found in this folder\"\n",
    "# This is REQUIRED for Python 3.8+ on Windows\n",
    "os.add_dll_directory(current_folder)\n",
    "\n",
    "print(f\"Added DLL path: {current_folder}\")\n",
    "\n",
    "# NOW we can import\n",
    "try:\n",
    "    import freenect\n",
    "    print(\"\\nSUCCESS! freenect imported.\")\n",
    "    \n",
    "    # Try to talk to the Kinect\n",
    "    ctx = freenect.init()\n",
    "    print(\"Kinect context initialized.\")\n",
    "    dev = freenect.open_device(ctx, 0)\n",
    "    print(\"Kinect device opened!\")\n",
    "    freenect.set_led(dev, freenect.LED_GREEN)\n",
    "    print(\"LED set to Green.\")\n",
    "    freenect.close_device(dev)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import freenect\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# --- SETTINGS ---\n",
    "\n",
    "# 1. Smoothing\n",
    "# Kernel size for the median blur (must be an odd number)\n",
    "MEDIAN_BLUR_KERNEL = 25 \n",
    "\n",
    "# 2. Topography\n",
    "# The \"height\" of each elevation step (smaller = more lines/colors)\n",
    "CONTOUR_STEP = 2\n",
    "# Colormap for the \"land\"\n",
    "LAND_COLORMAP = cv2.COLORMAP_JET # (blue-green-yellow-red)\n",
    "\n",
    "# 3. Water\n",
    "# Any pixel with a depth value *below* this will be water.\n",
    "# Tune this value (0-255) to match your sandbox's base level.\n",
    "SEA_LEVEL = 100\n",
    "# Color of the water (in BGR format)\n",
    "WATER_COLOR = [255, 0, 0] # Bright Blue\n",
    "\n",
    "# --- KINECT FUNCTIONS ---\n",
    "\n",
    "def get_depth():\n",
    "    \"\"\"\n",
    "    Gets 8-bit normalized (0-255) depth data from the Kinect.\n",
    "    Invalid pixels (occlusions) are set to 255.\n",
    "    \"\"\"\n",
    "    array, _ = freenect.sync_get_depth() \n",
    "    np.clip(array, 0, 1023, out=array)\n",
    "    array >>= 2\n",
    "    array = array.astype(np.uint8)\n",
    "    return array\n",
    "\n",
    "def get_video():\n",
    "    \"\"\"\n",
    "    Gets 8-bit BGR (OpenCV-ready) video data from the Kinect.\n",
    "    \"\"\"\n",
    "    array, _ = freenect.sync_get_video()\n",
    "    array = cv2.cvtColor(array, cv2.COLOR_RGB2BGR) \n",
    "    return array\n",
    "\n",
    "# --- MAIN PROGRAM ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        # --- 1. ACQUISITION ---\n",
    "        # Get raw depth for masking and RGB for display\n",
    "        depth_raw = get_depth()\n",
    "        rgb = get_video()\n",
    "        \n",
    "        # --- 2. SMOOTHING ---\n",
    "        # Apply a median blur to remove \"salt-and-pepper\" noise\n",
    "        depth_smooth = cv2.medianBlur(depth_raw, MEDIAN_BLUR_KERNEL)\n",
    "        \n",
    "        # --- 3. ANALYSIS & VISUALIZATION ---\n",
    "        \n",
    "        # A. Create discrete elevation \"steps\"\n",
    "        quantized_depth = (depth_smooth // CONTOUR_STEP) * CONTOUR_STEP\n",
    "        \n",
    "        # B. Apply colormap to the quantized \"land\"\n",
    "        depth_colormap = cv2.applyColorMap(quantized_depth, LAND_COLORMAP)\n",
    "        \n",
    "        # C. Find contour lines (the edges of the \"steps\")\n",
    "        edges = cv2.Canny(quantized_depth, 100, 200)\n",
    "\n",
    "        # D. Draw contours (black lines) onto the colormap\n",
    "        depth_colormap[edges == 255] = [0, 0, 0] \n",
    "        \n",
    "        # E. Add \"water\" by coloring all pixels below sea level\n",
    "        # We use the smoothed depth map for this check\n",
    "        depth_colormap[depth_smooth < SEA_LEVEL] = WATER_COLOR\n",
    "        \n",
    "        # --- 4. MASKING ---\n",
    "        \n",
    "        # Find all \"invalid\" pixels (occlusion shadows)\n",
    "        # (These are pixels where raw depth was 2047, which became 255)\n",
    "        invalid_mask = (depth_raw == 255)\n",
    "        \n",
    "        # Apply the mask to the final image\n",
    "        depth_colormap[invalid_mask] = [0, 0, 0]\n",
    "        \n",
    "        # --- 5. DISPLAY ---\n",
    "        \n",
    "        # Show the debug RGB stream\n",
    "        cv2.imshow('Kinect RGB (Debug)', rgb)\n",
    "        \n",
    "        # Show the final, processed AR Sandbox output\n",
    "        cv2.imshow('AR Sandbox Output', depth_colormap) \n",
    "        \n",
    "        # Wait for 1ms and check if the 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources and destroy windows\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoBox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
